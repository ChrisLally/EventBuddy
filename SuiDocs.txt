Developer Guides
The developer guides are meant to introduce you to the Move programming language and its implementation on the Sui network through examples, tasks, and conceptual content.

Get started
If you are completely new to Move, you should start with the aptly named Getting Started section. Topics in that section introduce you to the Sui monorepo, guide you through installing Sui binaries, and introduce you to some key core concepts of blockchain technology, particularly how they relate to Sui.

Go to Getting Started.

Your first dApp
If you prefer to jump right in to coding (after installing Sui, of course), then the Your First dApp is the place for you. These topics show you how to work with Move packages and get them published on-chain.

Go to Your First Sui dApp.

Sui 101
The Sui 101 section introduces the basics of Sui that help you create smart contracts. These topics assume you are familiar with Move and the Sui blockchain.

Go to Sui 101.

Cryptography
The Cryptography section demonstrates how to secure your smart contracts with cryptography to ensure authentication for access to sensitive data.

Go to Cryptography.

Advanced Topics
The Advanced Topics section includes guides for advanced solutions rather than advanced users (like migrating to GraphQL or asset tokenization). These topics assume you are familiar with Move and the Sui blockchain.

Go to Advanced Topics.

App Examples
The App Examples section is for anyone who learns best from reverse engineering code written by Sui and Move experts. These examples demonstrate concepts and tasks documented throughout this site and typically include detailed explanations through code comments and specific documentation. Check back often as the available examples continue to grow.

Go to App Examples.

Sui developer cheat sheet
The cheat sheet collects notes from Sui and Move developers into a single location. This document surfaces important information that might get lost in the quantity of content available. Use this often-updated page to see around corners when starting a Move project or to refresh your memory on important concepts to be mindful of.

Go to Sui Developer Cheat Sheet.

References
If you're familiar with both Move and Sui and just need some reference material to refresh your memory on that function you haven't used in a while, then the References section of the documentation should surface the information you need.

Go to References.

Getting Started
Sui is the first internet-scale programmable blockchain platform. That might read like marketing speak, but as you peruse the documentation to understand the technology, you will discover that Sui addresses many of the problems that hold blockchains back from mass adoption.

Before you can get started developing on Sui, you need to understand the code repository and install its binaries.

Install Sui
Use one of the following commands for Homebrew (MacOS, Linux, or Windows Subsystem for Linux) or Chocolatey (Windows) to install Sui.

Homebrew
Chocolatey
brew install sui

You can also install Sui from binaries or from source, as detailed in the Install Sui page.

Go to Install Sui.

After installing Sui
After you have Sui installed on your system, you can begin to connect with a network and publish smart contracts.

Connect to a Sui Network
Connect to a Local Network
Get Sui Address
Get SUI Coins
GraphQL queries
Use the GraphQL service for Sui RPC to interact with on-chain data.

Go to Query Sui RPC with GraphQL.

Move IDEs and plugins
The following table lists proven choices for IDEs with Move extensions. These IDEs and plugins are not required, but they provide a better experience for developing on Sui.

IDE	Move plugin	Description
Visual Studio Code	• Move extension
• Move syntax	The recommended free IDE for Move development from Microsoft.
IntelliJ IDEA	Move Language Plugin	A commercial IDE from JetBrains.
Emacs	move-mode	A free and open source text editor.
Github Codespaces	Move Syntax	A web-based IDE from GitHub.
INFO
Some plugins might not yet provide highlighting support for Move 2024.

Related links
After installing Sui and setting up your development environment, use the information in the following sections to continue your development journey.

App Examples: A mix of end-to-end examples that you can draw inspiration from in your own projects.
Sui 101: Topics that you should know when just starting out to develop on Sui.
Advanced Topics: Topics that you might not find beneficial until you start solving more complex problems.
Cryptography: Leverage cryptography functions to provide security for your smart contract actions.

Install Sui
The quickest way to install Sui is using the binaries delivered with every release. If you require more control over the install process, you can install from source. To take advantage of containerization, you can utilize the Docker images in the docker folder of the sui repository.

Supported operating systems
Sui supports the following operating systems:

Linux - Ubuntu version 20.04 (Bionic Beaver) or later
macOS - macOS Monterey or later
Microsoft Windows - Windows 10 and 11
Quick install using Homebrew or Chocolatey
Use one of the following commands for Homebrew (MacOS, Linux, or Windows Subsystem for Linux) or Chocolatey (Windows) to install Sui.

Homebrew
Chocolatey
brew install sui

INFO
If you use this method to install Sui, you are all set. The quick install is suitable for most use cases. The remaining installation methods are for those wanting more control over the installation process.

Download binaries from GitHub
Each Sui release provides a set of binaries for several operating systems. You can download these binaries from GitHub and use them to install Sui.

Linux
macOS
Windows
Go to https://github.com/MystenLabs/sui.

In the right pane, find the Releases section.

Sui releases in GitHub

Click the release tagged Latest to open the release's page.

In the Assets section of the release, select the .tgz compressed file that corresponds to your operating system.

Extract all files from the .tgz file into the preferred location on your system. These instructions assume you extract the files into a sui folder at the user root of your system. Replace references to this location in subsequent steps if you choose a different directory.

Navigate to the expanded folder. You should have the following extracted files:

Name	Description
move-analyzer	Language Server Protocol implementation.
sui	Main Sui binary.
sui-bridge	Sui native bridge.
sui-data-ingestion	Capture Full node data for indexer to store in a database.
sui-faucet	Local faucet to mint coins on local network.
sui-graphql-rpc	GraphQL service for Sui RPC.
sui-node	Run a local node.
sui-test-validator	Run test validators on a local network for development.
sui-tool	Provides utilities for Sui.
Add the folder containing the extracted files to your PATH variable. To do so, you can update your ~/.zshrc or ~/.bashrc to include the location of the Sui binaries. If using the suggested location, you type export PATH=$PATH:~/sui and press Enter.

Start a new terminal session or type source ~/.zshrc (or .bashrc) to load the new PATH value.

If running the binaries for the first time, you might receive an error from MacOS that prevents the binaries from running. If you receive this error, close the dialog and type xattr -d com.apple.quarantine ~/sui/* in your terminal and press Enter (be sure to adjust the path if different).

INFO
Running binaries other than sui might require installing prerequisites itemized in the following section.

Confirm the installation
To confirm that Sui installed correctly, type sui --version in your console or terminal and press Enter. The response should provide the Sui version installed. If the console or terminal responds with a command not found error, make sure the full path to your Sui binaries is included in your PATH variable.

Install from Cargo
Run the following command to install Sui binaries from the testnet branch:

cargo install --locked --git https://github.com/MystenLabs/sui.git --branch testnet sui

The install process can take a while to complete. You can monitor installation progress in the terminal. If you encounter an error, make sure to install the latest version of all prerequisites and then try the command again.

To update to the latest stable version of Rust:

rustup update stable

The command installs Sui components in the ~/.cargo/bin folder.

Upgrade from Cargo
If you previously installed the Sui binaries, you can update them to the most recent release with the same command you used to install them (changing testnet to the desired branch):

cargo install --locked --git https://github.com/MystenLabs/sui.git --branch testnet sui

Build from source
Follow the instructions in this topic to install the Rust crates (packages) required to interact with Sui networks, including the Sui CLI.

To install Sui from source, you first need to install its prerequisites for your operating system. After installing the supporting technologies, you can install Sui binaries from source.

You can also download the source code to have local access to files.

Prerequisites
Your system needs the following prerequisites available to successfully install Sui.

Rust and Cargo
Sui requires Rust and Cargo (Rust's package manager) on all supported operating systems. The suggested method to install Rust is with rustup using cURL.

Some other commands in the installation instructions also require cURL to run. If you can't run the cURL command to install Rust, see the instructions to install cURL for your operating system in the following section before you install Rust.

Use the following command to install Rust and Cargo on macOS or Linux:

curl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh

If you use Windows 11, see information about using the Rust installer on the Rust website. The installer checks for C++ build tools and prompts you to install them if necessary. Select the option that best defines your environment and follow the instructions in the install wizard.

For additional installation options, see Install Rust.

Sui uses the latest version of Cargo to build and manage dependencies. See the Cargo installation page on the Rust website for more information.

Use the following command to update Rust with rustup:

rustup update stable

Additional prerequisites by operating system
Select the appropriate tab to view the requirements for your system.

Linux
macOS
Windows
The prerequisites needed for the macOS operating system include:

Rust and Cargo
Homebrew
cURL
CMake
libpq
Git CLI
macOS includes a version of cURL you can use to install Homebrew. Use Homebrew to install other tools, including a newer version of cURL.

Homebrew
Use the following command to install Homebrew:

/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

INFO
If you used the commands in the Install using Homebrew section, you do not need to install anything else.

All macOS prerequisites
With Homebrew installed, you can install individual prerequisites from the following sections or install them all at once with this command:

brew install curl cmake libpq git

cURL
Use the following command to update the default cURL on macOS:

brew install curl

CMake
Use the following command to install CMake:

brew install cmake

To customize the installation, see Installing CMake on the CMake website.

libpq
Use the following command to install libpq:

brew install libpq

Git CLI
Use the following command to install Git:

brew install git

After installing Git, download and install the Git command line interface.

Using Sui from command line
With Sui installed, you can interact with Sui networks using the Sui CLI. For more details, see the Sui CLI reference.

Next steps
Now that you have Sui installed, it's time to start developing. Check out the following topics to start working with Sui:

Read about the Sui CLI, the most straightforward way to start exploring Sui networks.
Learn about the available networks and connect to one.
Get some coins on a development network.
Build your first dApp to start your on-chain journey.

Connect to a Sui Network
Sui has Mainnet, Devnet, and Testnet networks available. You can use one of the test networks, Devnet or Testnet, to experiment with the version of Sui running on that network. You can also spin up a local Sui network for local development.

The Sui Testnet and Devnet networks consist of four validator nodes operated by Mysten Labs. Clients send transactions and read requests via this endpoint: https://fullnode.<SUI-NETWORK-VERSION>.sui.io:443 using JSON-RPC.

You can request test SUI tokens through the Sui devnet-faucet and testnet-faucet Discord channels, depending on which version of the network you use. If connected to Localnet, use cURL to request tokens from your local faucet. The coins on these networks have no financial value. There is no faucet service for Mainnet.

See announcements about Sui in the #announcements Discord channel.

See the terms of service for using Sui networks.

INFO
Testnet and Devnet data persistence is not guaranteed. Devnet data is wiped regularly as part of scheduled software updates. The data on Testnet persists through the regular update process, but might be wiped when necessary. Testnet data wipes are announced ahead of time.

For more information about the release schedule of Sui networks, see Sui Network Release.

Sui CLI
Sui provides Sui command line interface (CLI) to interact with Sui networks:

Create and manage your private keys
Create example NFTs
Call and publish Move modules
Environment set up
First, Install Sui. After you install Sui, request SUI test tokens through Discord for the network you are using: Devnet or Testnet. If connected to Localnet, use cURL to request tokens from your local faucet.

To check whether Sui is already installed, run the following command:

which sui

If Sui is installed, the command returns the path to the Sui binary. If Sui is not installed, it returns sui not found.

See the Sui Releases page to view the changes in each Sui release.

Configure Sui client
If you previously ran sui genesis to create a local network, it created a Sui client configuration file (client.yaml) that connects to localhost at http://0.0.0.0:9000. See Connect to a custom RPC endpoint to update the client.yaml file.

To connect the Sui client to a network, run the following command:

sui client

If you receive the sui-client help output in the console, you already have a client.yaml file. See Connect to a custom RPC endpoint to add a new environment alias or to switch the currently active network.

The first time you start Sui client without having a client.yaml file, the console displays the following message:

Config file ["<PATH-TO-FILE>/client.yaml"] doesn't exist, do you want to connect to a Sui Full node server [y/N]?


Press y and then press Enter. The process then requests the RPC server URL:

Sui Full node server URL (Defaults to Sui Devnet if not specified) :

Press Enter to connect to Sui Devnet. To use a custom RPC server, Sui Testnet, or Sui Mainnet, enter the URL to the correct RPC endpoint and then press Enter.

If you enter a URL, the process prompts for an alias for the environment:

Environment alias for [<URL-ENTERED>] :

Type an alias name and press Enter.

Select key scheme to generate keypair (0 for ed25519, 1 for secp256k1, 2 for secp256r1):

Press 0, 1, or 2 to select a key scheme and the press Enter.

Sui returns a message similar to the following (depending on the key scheme you selected) that includes the address and 12-word recovery phrase for the address:

Generated new keypair for address with scheme "ed25519" [0xb9c83a8b40d3263c9ba40d551514fbac1f8c12e98a4005a0dac072d3549c2442]
Secret Recovery Phrase : [cap wheat many line human lazy few solid bored proud speed grocery]


Connect to a custom RPC endpoint
If you previously used sui genesis with the force option (-f or --force), your client.yaml file already includes two RPC endpoints: localnet at http://0.0.0.0:9000 and devnet at https://fullnode.devnet.sui.io:443. You can view the defined environments with the sui client envs command, and switch between them with the sui client switch command.

If you previously installed a Sui client that connected to a Sui network, or created a local network, you can modify your existing client.yaml file to change the configured RPC endpoint. The sui client commands that relate to environments read from and write to the client.yaml file.

To check currently available environment aliases, run the following command:

sui client envs

The command outputs the available environment aliases, with (active) denoting the currently active network.

localnet => http://0.0.0.0:9000 (active)
devnet => https://fullnode.devnet.sui.io:443

To add a new alias for a custom RPC endpoint, run the following command. Replace values in < > with values for your installation:

sui client new-env --alias <ALIAS> --rpc <RPC-SERVER-URL>

To switch the active network, run the following command:

sui client switch --env <ALIAS>

If you encounter an issue, delete the Sui configuration directory (~/.sui/sui_config) and reinstall the latest Sui binaries.

Connect to a Local Network
Use a Sui local network to test your dApps against the latest changes to Sui, and to prepare for the next Sui release to the Devnet or Testnet network. To set up a local network, Sui provides the sui-test-validator binary. The sui-test-validator starts a local network that includes a Sui Full node, a Sui validator, and a Sui faucet. You can use the included faucet to get test SUI to use on the local network.

If you haven't already, you need to install Sui on your system.

Start the local network
To start the local network, run the following command from your sui root folder.

RUST_LOG="off,sui_node=info" cargo run --bin sui-test-validator

The command starts the sui-test-validator. The RUST_LOG=off,sui_node=info turns off logging for all components except sui-node. If you want to see more detailed logs, you can remove RUST_LOG from the command.

Important: Each time you start the sui-test-validator, the network starts as a new network with no previous data. The local network is not persistent.

To customize your local Sui network, such as changing the port used, include additional parameters in the command to start sui-test-validator:

OPTIONS:
        --epoch-duration-ms <EPOCH_DURATION_MS>
            The duration for epochs (defaults to one minute) [default: 60000]

        --faucet-port <FAUCET_PORT>
            Port to start the Sui faucet on [default: 9123]

        --fullnode-rpc-port <FULLNODE_RPC_PORT>
            Port to start the Fullnode RPC server on [default: 9000]

Use sui-test-validator --help to see these options in your console.

Access your local Full node
Use the following command to retrieve the total transaction count from your local network:

curl --location --request POST 'http://127.0.0.1:9000' \
--header 'Content-Type: application/json' \
--data-raw '{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "sui_getTotalTransactionBlocks",
  "params": []
}'

If successful, the response resembles the following:

{
	"jsonrpc": "2.0",
	"result": 168,
	"id": 1
}

Connect the Sui Client CLI to your local network
You can use the Sui Client CLI with any Sui network. By default it connects to Sui Devnet. To connect to your local network, create a new environment alias named local that sets the RPC URL the client uses to your local network.

sui client new-env --alias local --rpc http://127.0.0.1:9000

Next, use the following command to set the active environment to the new local environment you created.

sui client switch --env local

The command returns:

Active environment switched to [local]

You can check the current active environment with the following command:

sui client active-env

The command returns:

local

Show the current active address
The Sui Client CLI uses the active address for command if you don't specify one. Use the following command to show the active address on your local network.

sui client active-address

The command returns an address:

0xbc33e6e4818f9f2ef77d020b35c24be738213e64d9e58839ee7b4222029610de

Use the active address to get test SUI to use on your local network. Use the sui client addresses command to see all of the addresses on your local network.

INFO
The address returned when you run the command is unique and does not match the one used in this example.

Use the local faucet
Transactions on your local network require SUI coins to pay for gas fees just like other networks. You can use the currently active address with the faucet.

Sui CLI provides the sui client faucet command to get coins from the faucet. In the most basic case, run sui client faucet and wait up to 60 seconds for the coins to reach your address. Use sui client gas to check for the new coins.

INFO
The faucet command uses the active address and the active network environment by default. If you need to pass in a different address or faucet server URL, check the help menu. If you're using a different network than a local network or the public ones (fullnode.network.sui.io), you will have to pass the URL to the faucet server.

Check the gas coin objects for the active address
After you get coins from the faucet, use the following command to view the coin objects for the address:

sui client gas

The response resembles the following, but with different IDs:

╭────────────────────────────────────────────────────────────────────┬────────────╮
│ gasCoinId                                                          │ gasBalance │
├────────────────────────────────────────────────────────────────────┼────────────┤
│ 0x1d790713c1c3441a307782597c088f11230c47e609af2cec97f393123ea4de45 │ 200000000  │
│ 0x20c1d5ad2e8693953fca09fd2fec0fbc52a787e0a0f77725220d36a09a5b312d │ 200000000  │
│ 0x236714566110f5624516faa0da215ad29f8daa611e8b651d1e972168207567b2 │ 200000000  │
│ 0xc81f30256bb04ad84bc4a92017cffd7c1f98286e028fa504d8515ad72ddd1088 │ 200000000  │
│ 0xf61c8b21b305cc8e062b3a37de8c3a37583e17f437a449a2ab42321d019aeeb4 │ 200000000  │
╰────────────────────────────────────────────────────────────────────┴────────────╯

Generate example data
Use the TypeScript SDK to add example data to your network. Run the following command from the sui root folder:

pnpm --filter @mysten/sui test:e2e

For additional information about example data for testing, see https://github.com/MystenLabs/sui/tree/main/sdk/typescript#testing.

Troubleshooting
If you do not use Node.js 18, you might see the following message:

Retrying requesting from faucet: Retry failed: fetch is not defined

To resolve this, switch or update to Node.js 18 and then try again.

Test with the Sui TypeScript SDK
The published version of the Sui TypeScript SDK might be an earlier version than the version of Sui you installed for your local network. To make sure you're using the latest version of the SDK, use the experimental-tagged version (for example, 0.0.0-experimental-20230317184920) in the Current Tags section of the Sui NPM registry.

Get Sui Address
An address is a way to uniquely and anonymously identify an account that exists on the Sui blockchain network. In other words, an address is a way for a user to store and use tokens on the Sui network, without providing any personally identifying information (such as email address, phone number, and so on). For example, if you want to purchase a number of SUI tokens to play a game, you must specify an address where these tokens are to be deposited.

The Sui address is unique, similarly to the way a social security number or a personal identification number is unique to one person. However, in Sui you can create and own multiple addresses, all of which are unique.

In Sui, an address is 32 bytes and is often encoded in base58 with a 0x prefix. For example, this is a valid Sui address: 0x02a212de6a9dfa3a69e22387acfbafbb1a9e591bd9d636e7895dcfc8de05f331. You can use a Sui network explorer to find more information about this address and the objects it owns.

If you'd like to understand how a Sui address is derived from private keys and other cryptography related topics, see the Keys and Addresses topic.

How to obtain a Sui address
Sui provides multiple ways to obtain a Sui address. The following are the two most common.

Sui Wallet
One of the most straightforward ways to obtain a Sui address for first-time users is through the Sui Wallet Chrome browser extension. After you install the extension, there are several ways to create an address.

Open the Chrome Sui Wallet browser extension and then:

Use your gmail/twitch/facebook account (ZkLogin) and follow the on-screen instructions
Click More Options → Create a new passphrase account. Then follow the on-screen instructions.
For more information on the Sui Wallet and how to keep it secure, see the Sui Wallet documentation.

Command line interface
If you are using the Sui command line interface (CLI) to interact with the Sui network, you can use the sui client command to generate a new address. By default, when the Sui CLI runs for the first time it will prompt you to set up your local wallet, and then it generates one Sui address and the associated secret recovery phrase. Make sure you write down the secret recovery phrase and store it in a safe place.

To generate a new Sui address use sui client new-address ed25519, which specifies the keypair scheme flag to be of type ed25519.

For more information, see the Sui Client CLI documentation.

To see all the generated addresses in the local wallet on your machine, run sui keytool list. For more information about the keytool options, see the Sui Keytool CLI documentation.

DANGER
The private keys associated with the Sui addresses are stored locally on the machine where the CLI is installed, in the ~/.sui/sui_config/sui.keystore file. Make sure you do not expose this to anyone, as they can use it to get access to your account.

Get SUI Tokens
Sui faucet is a helpful tool where Sui developers can get free test SUI tokens to deploy and interact with their programs on Sui's Devnet and Testnet networks. There is no faucet for Sui Mainnet.

Prerequisites
To request tokens from the faucet, you must own a wallet address that can receive the SUI tokens. See the Get Sui Address topic if you don't already have an address or need to create a new one.

Request test tokens via the CLI
If you are using the Devnet or Testnet networks, or you spun up a local network, you can use the Sui CLI to request tokens for your address. The sui client faucet uses the active network and active address that is currently set in the Sui CLI by default, but you can specify custom data through the following two arguments:

--address argument to provide a specific address (or its alias),
--url argument to provide a custom faucet endpoint.
Request test tokens through Discord
Join Discord. If you try to join the Sui Discord channel using a newly created Discord account, you may need to wait a few days for validation.
Request test SUI tokens in the Sui #devnet-faucet or #testnet-faucet Discord channels. Send the following message to the channel with your client address: !faucet <Your client address>
Request test tokens through wallet
You can request test tokens within Sui Wallet.

Request test tokens through cURL
Use the following cURL command to request tokens directly from the faucet server:

curl --location --request POST 'https://faucet.devnet.sui.io/gas' \
--header 'Content-Type: application/json' \
--data-raw '{
    "FixedAmountRequest": {
        "recipient": "<YOUR SUI ADDRESS>"
    }
}'

If you're working with a local network, replace 'https://faucet.devnet.sui.io/gas' with the appropriate value based on which package runs your network:

sui-faucet: http://127.0.0.1:5003/gas
sui-test-validator: http://127.0.0.1:9123/gas
Request test tokens through TypeScript SDK
You can also access the faucet using the Sui TypeScript-SDK.

import { getFaucetHost, requestSuiFromFaucetV0 } from '@mysten/sui/faucet';

// get tokens from the Devnet faucet server
await requestSuiFromFaucetV0({
	// connect to Devnet
	host: getFaucetHost('devnet'),
	recipient: '<YOUR SUI ADDRESS>',
});

Test tokens on a local network
If you are running a local Sui network, you can get tokens from your local faucet. See the Connect to a Local Network topic for details.

Querying Sui RPC with GraphQL
The quickest way to access the GraphQL service for Sui RPC is through the online IDE that provides a complete toolbox for fetching data and executing transactions on the network. The online IDE provides features such as auto-completion (use Ctrl+Space or just start typing), built-in documentation (Book icon, top-left), multi-tabs, and more.

The online IDE is available for Mainnet and Testnet. This guide contains various queries that you can try directly in the IDE.

INFO
Any existing addresses/object IDs in these examples refer to mainnet data only.
Both mainnet and testnet services are rate-limited to keep network throughput optimized.
For more details about some concepts used in the examples below, please see the GraphQL concepts page, and consult the reference for full documentation on the supported schema.

Discovering the schema
GraphQL introspection exposes the schema supported by the RPC service. The IDE's "Docs" pane (Book icon, top-left) and Search dialog (Cmd+K on macOS or Ctrl+K on Windows and Linux) offer a way to browse introspection output interactively.

The official documentation provides an overview on introspection, and how to interact with it programmatically.

Finding the reference gas price for latest epoch
query {
  epoch {
    referenceGasPrice
  }
}

Finding information about a specific historical epoch
This example finds the total stake rewards, the reference gas price, the number of checkpoints and the total gas fees for epoch 100. Note that in the query, the id argument is optional, and defaults to the latest epoch.

query {
  epoch(id: 100) # note that id is optional, and without it, latest epoch is returned
  {
    epochId
    totalStakeRewards
    referenceGasPrice
    totalCheckpoints
    totalGasFees
    totalStakeSubsidies
    storageFund {
      totalObjectStorageRebates
      nonRefundableBalance
    }
  }
}

Finding a transaction block by its digest
This example gets a transaction block by its digest and shows information such as the gas sponsor's address, the gas price, the gas budget, and effects from executing that transaction block.

query {
  transactionBlock(digest: "FdKFgsQ9iRrxW6b1dh9WPGuNuaJWMXHJn1wqBQSqVqK2") {
    gasInput {
      gasSponsor {
        address
      }
      gasPrice
      gasBudget
    }
    effects {
      status
      timestamp
      checkpoint {
        sequenceNumber
      }
      epoch {
        epochId
        referenceGasPrice
      }
    }
  }
}

Finding the last ten transactions that are not a system transaction
query {
  transactionBlocks(last: 10, filter: {kind: PROGRAMMABLE_TX}) {
    nodes {
      digest
      kind {
        __typename
      }
    }
  }
}

Finding all transactions that touched a given object
This example finds all the transactions that touched (modified/transferred/deleted) a given object. This is useful for when we want to trace the flow of a Coin/StakeSui/NFT.

INFO
This example uses GraphQL variables and pagination. When using the online IDE, copy the variables JSON to the "Variables" window, below the main editor.

query ($objectID: SuiAddress!) {
  transactionBlocks(filter: {changedObject: $objectID}) {
    nodes {
      sender {
        address
      }
      digest
      effects {
        objectChanges {
          nodes {
            address
          }
        }
      }
    }
  }
}

Variables:

{
  "objectID": "0x11c6ae8432156527fc2e12e05ac7db79f2e972510a823a4ef2e670f27ad7b52f"
}

Filtering transaction blocks by a function
This example finds the last ten transaction blocks that called the public_transfer function, (as a move call transaction command).

INFO
This example makes usage of the filter last, which indicates that the user only wants the last ten transaction blocks known to the service.

{
  transactionBlocks(
    last: 10,
      filter: {
        function: "0x2::transfer::public_transfer"
      }
  ) {
    nodes { digest }
  }
}

Finding transaction balance changes
This example finds the balance changes of all the transactions where a given address called a staking-related function. This is useful when you want to get your staking or unstaking history.

query ($address: SuiAddress!) {
  transactionBlocks(filter: {
    function: "0x3::sui_system::request_add_stake"
    signAddress: $address
  }) {
    nodes {
      digest
      effects {
        balanceChanges {
          nodes {
            owner {
              address
            }
            amount
          }
        }
      }
    }
  }
}

Variables:

{
  "address": "0xa9ad44383140a07cc9ea62d185c12c4d9ef9c6a8fd2f47e16316229815862d23"
}

Fetching a dynamic field on an object
INFO
This example uses aliases and fragments.

query DynamicField {
  object(
    address: "0xb57fba584a700a5bcb40991e1b2e6bf68b0f3896d767a0da92e69de73de226ac"
  ) {
    dynamicField(
      name: {
        type: "0x2::kiosk::Listing",
        bcs: "NLArx1UJguOUYmXgNG8Pv8KbKXLjWtCi6i0Yeq1VhfwA",
      }
    ) {
      ...DynamicFieldSelect
    }
  }
}

fragment DynamicFieldSelect on DynamicField {
  name {
    ...MoveValueFields
  }
  value {
    ...DynamicFieldValueSelection
  }
}

fragment DynamicFieldValueSelection on DynamicFieldValue {
  __typename
  ... on MoveValue {
    ...MoveValueFields
  }
  ... on MoveObject {
    hasPublicTransfer
    contents {
      ...MoveValueFields
    }
  }
}

fragment MoveValueFields on MoveValue {
  type {
    repr
  }
  data
  bcs
}

Fetching all dynamic fields on an object
This query can be used to paginate over the dynamic fields of an object. This works even when the object in question is wrapped, by using the owner query, so can be used for iterating over the elements of on-chain data structures, like Tables and Bags.

INFO
This example uses fragments and variables.

query ($id: SuiAddress!) {
  owner(address: $id) {
    dynamicFields {
      nodes {
        name { ...Value }
        value {
          __typename
          ... on MoveValue {
            ...Value
          }
          ... on MoveObject {
            contents {
              ...Value
            }
          }
        }
      }
    }
  }
}

fragment Value on MoveValue {
  type {
    repr
  }
  json
}

Paginating checkpoints forward, five at a time
query ($after: String) {
  checkpoints(first: 5, after: $after) {
    pageInfo {
      hasNextPage
      endCursor
    }
    nodes {
      digest
      timestamp
    }
  }
}

Sets up a paginated query, starting at the genesis checkpoint, reading five checkpoints at a time, in increasing order of sequence number. The value of pageInfo.hasNextPage determines whether there is another page to be read, and the value of pageInfo.endCursor is fed back in as the cursor to read $after.

INFO
This example uses GraphQL variables and pagination.

Paginating checkpoints backwards, five at a time
query ($before: String) {
  checkpoints(last: 5, before: $before) {
    pageInfo {
      hasPreviousPage
      startCursor
    }
    nodes {
      digest
      timestamp
    }
  }
}

Sets up a paginated query, starting at the latest indexed checkpoint, reading five checkpoints at a time, in decreasing order of sequence number. The value of pageInfo.hasPreviousPage determines whether there is another page to be read, and the value of pageInfo.startCursor is fed back in as the cursor to read $before.

INFO
This example uses GraphQL variables and pagination.

Executing a transaction
Transaction execution takes in two arguments, txBytes and signatures. txBytes is the serialized unsigned transaction data, which can be generated when using the Sui CLI's client call command, to call a Move function by passing the --serialize-unsigned-transaction flag. The signatures can be generated using Sui CLI's keytool command sui keytool sign. More information on Sui CLI can be found here.

mutation ($tx: String!, $sigs: [String!]!) {
  executeTransactionBlock(txBytes: $tx, signatures: $sigs) {
    errors
    effects {
      status
      epoch {
        startTimestamp
      }
      gasEffects {
        gasSummary {
          computationCost
        }
      }
    }
  }
}

Variables:

{
  "tx": "AAACACAZXApmrHgzTs3FGDyXWka+wmMCy2IwOdKLmTWHb5PnFQEASlCnLAw4qfzLF3unH9or5/L7YpOlReaSEWfoEwhTqpavSxAAAAAAACCUFUCOn8ljIxcG9O+CA1bzqjunqr4DLDSzSoNCkUvu2AEBAQEBAAEAALNQHmLi4jgC5MuwwmiMvZEeV5kuyh+waCS60voE7fpzAa3v/tOFuqDvQ+bjBpKTfjyL+6yIg+5eC3dKReVwghH/rksQAAAAAAAgxtZtKhXTr1zeFAo1JzEqVKn9J1H74ddbCJNVZGo2I1izUB5i4uI4AuTLsMJojL2RHleZLsofsGgkutL6BO36c+gDAAAAAAAAQEIPAAAAAAAA",
  "sigs": [
    "AB4ZihXxUMSs9Ju5Cstuuf/hvbTvvycuRk2TMuagLYNJgQuAeXmKyJF9DAXUtL8spIsHrDQgemn4NmojcNl8HQ3JFqhnaTC8gMX4fy/rGgqgL6CDcbikawUUjC4zlkflwg=="
  ]
}


Other examples
You can find other examples in the repository, grouped into sub-directories. For example, there are directories for transaction block effects, protocol configs, stake connection, and more.

INFO
Examples in the repository are designed to work with the version of GraphQL built at the same revision. The links above point to examples intended for GraphQL v2024.1, the latest production version at the time of writing.

Related links
GraphQL migration: Migrating to GraphQL guides you through migrating Sui RPC projects from JSON-RPC to GraphQL.
GraphQL concepts: GraphQL for Sui RPC examines the elements of GraphQL that you should know to get the most from the service.
GraphQL reference: Auto-generated GraphQL reference for Sui RPC.


Your First Sui dApp
Before you can create your first dApp, you must have Sui installed.

You use Move to write packages that live on chain, meaning they exist on the Sui network you publish them to. The instructions in this section walk you through writing a basic package, debugging and testing your code, and publishing. You need to follow these instructions in order to complete the exercise.

You use the move Sui CLI command for some instructions. The Sui CLI installs with the binaries, so you have it on your system if you follow the install instructions. To verify you have it installed, run the following command in a terminal or console.

$ sui --version

If the console does not respond with a version number similar to the following, see the instructions to install Sui.

$ sui 1.xx.x-abc123xyz

Connecting to a network
After installing Sui, you can connect to a network. Sui has three public networks (Devnet, Testnet, Mainnet), and you can also run and connect to a local Sui network. For each network, you need an on-chain address specific to that network. The address is an object with a unique ID in the form 0x8bd4613c004aac53d06bb7ceb7f46832c9ae69bdc105dfc5fcac225d2061fcac. In addition to that address, you need SUI to pay for the gas fees associated with your on-chain activity, like publishing packages and making Move calls to those packages. For all networks besides Mainnet, you can get free SUI coins for your account to facilitate package development. For the purposes of this example, connect to the Testnet network.

Connect to Testnet
If you already have a network config set up, switch your active environment to Testnet. The following instruction is for the initial set up.

In your terminal or console, use the following command to begin the configuration:
$ sui client

At the prompt, type y and press Enter to connect to a Sui Full node server.
At the following prompt, type the address of the Testnet server (https://fullnode.testnet.sui.io:443) and press Enter.
At the following prompt, type testnet to give the network an alias and press Enter. You can use the alias in subsequent commands instead of typing the complete URL.
At the following prompt, type 0 and press Enter. The selection creates an address in the ed25519 signing scheme.
The response provides an alias for your address, the actual address ID, and a secret recovery phrase. Be sure to save this information for later reference. Because this is on the Testnet network, the security of this information is not as important as if it were on Mainnet.
In your terminal or console, use the following command to get SUI for your account.
$ sui client faucet

You can confirm that you received SUI by using the following command. There may be a delay in receiving coins depending on the activity of the network.
$ sui client gas

You are now connected to the Sui Testnet network and should have an account with available SUI.

Related links
Write a Move Package: Continue this example by creating the necessary Move code for your package.
Connect to a Sui Network: Connect to an available Sui network.
Connect to a Local Network: Start and connect to a local Sui network.
Get Sui Address: Get an address for the current Sui network.
Get SUI Tokens: Get SUI for the active address on Devnet, Testnet, or a local network.

Write a Move Package
To begin, open a terminal or console at the location you plan to store your package. Use the sui move new command to create an empty Move package with the name my_first_package:

$ sui move new my_first_package

Running the previous command creates a directory with the name you provide (my_first_package in this case). The command populates the new directory with a skeleton Move project that consists of a sources directory and a Move.toml manifest file. Open the manifest with a text editor to review its contents:

my_first_package/Move.toml
[package]
name = "my_first_package"
edition = "2024.beta" # edition = "legacy" to use legacy (pre-2024) Move
# license = ""           # e.g., "MIT", "GPL", "Apache 2.0"
# authors = ["..."]      # e.g., ["Joe Smith (joesmith@noemail.com)", "John Snow (johnsnow@noemail.com)"]

[dependencies]
Sui = { git = "https://github.com/MystenLabs/sui.git", subdir = "crates/sui-framework/packages/sui-framework", rev = "framework/testnet" }

# For remote import, use the `{ git = "...", subdir = "...", rev = "..." }`.
# Revision can be a branch, a tag, and a commit hash.
# MyRemotePackage = { git = "https://some.remote/host.git", subdir = "remote/path", rev = "main" }

# For local dependencies use `local = path`. Path is relative to the package root
# Local = { local = "../path/to" }

# To resolve a version conflict and force a specific version for dependency
# override use `override = true`
# Override = { local = "../conflicting/version", override = true }

[addresses]
my_first_package = "0x0"

# Named addresses will be accessible in Move as `@name`. They're also exported:
# for example, `std = "0x1"` is exported by the Standard Library.
# alice = "0xA11CE"

[dev-dependencies]
# The dev-dependencies section allows overriding dependencies for `--test` and
# `--dev` modes. You can introduce test-only dependencies here.
# Local = { local = "../path/to/dev-build" }

[dev-addresses]
# The dev-addresses section allows overwriting named addresses for the `--test`
# and `--dev` modes.
# alice = "0xB0B"


The manifest file contents include available sections of the manifest and comments that provide additional information. In Move, you prepend the hash mark (#) to a line to denote a comment.

[package]: Contains metadata for the package. By default, the sui move new command populates only the name value of the metadata. In this case, the example passes my_first_package to the command, which becomes the name of the package. You can delete the first # of subsequent lines of the [package] section to provide values for the other available metadata fields.
[dependencies]: Lists the other packages that your package depends on to run. By default, the sui move new command lists the Sui package on GitHub (Testnet version) as the lone dependency.
[addresses]: Declares named addresses that your package uses. By default, the section includes the package you create with the sui move new command and an address of 0x0. The publish process replaces the 0x0 address with an actual on-chain address.
[dev-dependencies]: Includes only comments that describe the section.
[dev-addresses]: Includes only comments that describe the section.
Defining the package
You have a package now but it doesn't do anything. To make your package useful, you must add logic contained in .move source files that define modules. Use a text editor or the command line to create your first package source file named my_module.move in the sources directory of the package:

$ touch my_first_package/sources/my_module.move

Populate the my_module.move file with the following code:

module my_first_package::my_module {

    // Part 1: These imports are provided by default
    // use sui::object::{Self, UID};
    // use sui::transfer;
    // use sui::tx_context::{Self, TxContext};

    // Part 2: struct definitions
    public struct Sword has key, store {
        id: UID,
        magic: u64,
        strength: u64,
    }

    public struct Forge has key {
        id: UID,
        swords_created: u64,
    }

    // Part 3: Module initializer to be executed when this module is published
    fun init(ctx: &mut TxContext) {
        let admin = Forge {
            id: object::new(ctx),
            swords_created: 0,
        };
        // Transfer the forge object to the module/package publisher
        transfer::transfer(admin, ctx.sender());
    }

    // Part 4: Accessors required to read the struct fields
    public fun magic(self: &Sword): u64 {
        self.magic
    }

    public fun strength(self: &Sword): u64 {
        self.strength
    }

    public fun swords_created(self: &Forge): u64 {
        self.swords_created
    }

    // Part 5: Public/entry functions (introduced later in the tutorial)

    // Part 6: Tests

}

The comments in the preceding code highlight different parts of a typical Move source file.

Part 1: Imports - Code reuse is a necessity in modern programming. Move supports this concept with use aliases that allow your module to refer to types and functions declared in other modules. In this example, the module imports from object, transfer, and tx_context modules, but it does not need to do so explicitly, because the compiler provides these use statements by default. These modules are available to the package because the Move.toml file defines the Sui dependency (along with the sui named address) where they are defined.

Part 2: Struct declarations - Structs define types that a module can create or destroy. Struct definitions can include abilities provided with the has keyword. The structs in this example, for instance, have the key ability, which indicates that these structs are Sui objects that you can transfer between addresses. The store ability on the structs provides the ability to appear in other struct fields and be transferred freely.

Part 3: Module initializer - A special function that is invoked exactly once when the module publishes.

Part 4: Accessor functions - These functions allow the fields of the module's structs to be read from other modules.

After you save the file, you have a complete Move package.

Related links
Build and Test Packages: Continue this example to build and test your package to get it ready for publishing.
Sui Move CLI: Available Move commands the CLI provides.


Build and Test Packages
If you followed Write a Move Package, you have a basic module that you need to build. If you didn't, then either start with that topic or use your package, substituting that information where appropriate.

Building your package
Make sure your terminal or console is in the directory that contains your package (my_first_package if you're following along). Use the following command to build your package:

$ sui move build

A successful build returns a response similar to the following:

UPDATING GIT DEPENDENCY https://github.com/MystenLabs/sui.git
INCLUDING DEPENDENCY Sui
INCLUDING DEPENDENCY MoveStdlib
BUILDING my_first_package

If the build fails, you can use the verbose error messaging in output to troubleshoot and resolve root issues.

Now that you have designed your asset and its accessor functions, it's time to test the package code before publishing.

Testing a package
Sui includes support for the Move testing framework. Using the framework, you can write unit tests that analyze Move code much like test frameworks for other languages, such as the built-in Rust testing framework or the JUnit framework for Java.

An individual Move unit test is encapsulated in a public function that has no parameters, no return values, and has the #[test] annotation. The testing framework executes such functions when you call the sui move test command from the package root (my_move_package directory as per the current running example):

$ sui move test

If you execute this command for the package created in Write a Package, you see the following output. Unsurprisingly, the test result has an OK status because there are no tests written yet to fail.

BUILDING Sui
BUILDING MoveStdlib
BUILDING my_first_package
Running Move unit tests
Test result: OK. Total tests: 0; passed: 0; failed: 0

To actually test your code, you need to add test functions. Start with adding a basic test function to the my_module.move file, inside the module definition:

#[test]
fun test_sword_create() {
    // Create a dummy TxContext for testing
    let mut ctx = tx_context::dummy();

    // Create a sword
    let sword = Sword {
        id: object::new(&mut ctx),
        magic: 42,
        strength: 7,
    };

    // Check if accessor functions return correct values
    assert!(sword.magic() == 42 && sword.strength() == 7, 1);
}

As the code shows, the unit test function (test_sword_create()) creates a dummy instance of the TxContext struct and assigns it to ctx. The function then creates a sword object using ctx to create a unique identifier and assigns 42 to the magic parameter and 7 to strength. Finally, the test calls the magic and strength accessor functions to verify that they return correct values.

The function passes the dummy context, ctx, to the object::new function as a mutable reference argument (&mut), but passes sword to its accessor functions as a read-only reference argument, &sword.

Now that you have a test function, run the test command again:

$ sui move test

After running the test command, however, you get a compilation error instead of a test result:

error[E06001]: unused value without 'drop'
   ┌─ ./sources/my_module.move:59:65
   │
 9 │       public struct Sword has key, store {
   │                     ----- To satisfy the constraint, the 'drop' ability would need to be added here
   ·
52 │           let sword = Sword {
   │               ----- The local variable 'sword' still contains a value. The value does not have the 'drop' ability and must be consumed before the function returns
   │ ╭─────────────────────'
53 │ │             id: object::new(&mut ctx),
54 │ │             magic: 42,
55 │ │             strength: 7,
56 │ │         };
   │ ╰─────────' The type 'my_first_package::my_module::Sword' does not have the ability 'drop'
   · │
59 │           assert!(sword.magic() == 42 && sword.strength() == 7, 1);
   │                                                                   ^ Invalid return


The error message contains all the necessary information to debug the code. The faulty code is meant to highlight one of the Move language's safety features.

The Sword struct represents a game asset that digitally mimics a real-world item. Obviously, a real sword cannot simply disappear (though it can be explicitly destroyed), but there is no such restriction on a digital one. In fact, this is exactly what's happening in the test function - you create an instance of a Sword struct that simply disappears at the end of the function call. If you saw something disappear before your eyes, you'd be dumbfounded, too.

One of the solutions (as suggested in the error message), is to add the drop ability to the definition of the Sword struct, which would allow instances of this struct to disappear (be dropped). The ability to drop a valuable asset is not a desirable asset property in this case, so another solution is needed. Another way to solve this problem is to transfer ownership of the sword.

To get the test to work, we will need to use the transfer module, which is imported by default. Add the following lines to the end of the test function (after the assert! call) to transfer ownership of the sword to a freshly created dummy address:

// Create a dummy address and transfer the sword
let dummy_address = @0xCAFE;
transfer::public_transfer(sword, dummy_address);

Run the test command again. Now the output shows a single successful test has run:

BUILDING MoveStdlib
BUILDING Sui
BUILDING my_first_package
Running Move unit tests
[ PASS    ] 0x0::my_module::test_sword_create
Test result: OK. Total tests: 1; passed: 1; failed: 0

TIP
Use a filter string to run only a matching subset of the unit tests. With a filter string provided, the sui move test checks the fully qualified (<address>::<module_name>::<fn_name>) name for a match.

Example:

$ sui move test sword

The previous command runs all tests whose name contains sword.

You can discover more testing options through:

$ sui move test -h

Sui-specific testing
The previous testing example uses Move but isn't specific to Sui beyond using some Sui packages, such as sui::tx_context and sui::transfer. While this style of testing is already useful for writing Move code for Sui, you might also want to test additional Sui-specific features. In particular, a Move call in Sui is encapsulated in a Sui transaction, and you might want to test interactions between different transactions within a single test (for example, one transaction creating an object and the other one transferring it).

Sui-specific testing is supported through the test_scenario module that provides Sui-related testing functionality otherwise unavailable in pure Move and its testing framework.

The test_scenario module provides a scenario that emulates a series of Sui transactions, each with a potentially different user executing them. A test using this module typically starts the first transaction using the test_scenario::begin function. This function takes an address of the user executing the transaction as its argument and returns an instance of the Scenario struct representing a scenario.

An instance of the Scenario struct contains a per-address object pool emulating Sui object storage, with helper functions provided to manipulate objects in the pool. After the first transaction finishes, subsequent test transactions start with the test_scenario::next_tx function. This function takes an instance of the Scenario struct representing the current scenario and an address of a user as arguments.

Update your my_module.move file to include a function callable from Sui that implements sword creation. With this in place, you can then add a multi-transaction test that uses the test_scenario module to test these new capabilities. Put this functions after the accessors (Part 5 in comments).

public fun sword_create(magic: u64, strength: u64, ctx: &mut TxContext): Sword {
    // Create a sword
    Sword {
        id: object::new(ctx),
        magic: magic,
        strength: strength,
    }
}

The code of the new functions uses struct creation and Sui-internal modules (tx_context) in a way similar to what you have seen in the previous sections. The important part is for the function to have correct signatures.

With the new function included, add another test function to make sure it behaves as expected.

#[test]
fun test_sword_transactions() {
    use sui::test_scenario;

    // Create test addresses representing users
    let initial_owner = @0xCAFE;
    let final_owner = @0xFACE;

    // First transaction executed by initial owner to create the sword
    let mut scenario = test_scenario::begin(initial_owner);
    {
        // Create the sword and transfer it to the initial owner
        let sword = sword_create(42, 7, scenario.ctx());
        transfer::public_transfer(sword, initial_owner);
    };

    // Second transaction executed by the initial sword owner
    scenario.next_tx(initial_owner);
    {
        // Extract the sword owned by the initial owner
        let sword = scenario.take_from_sender<Sword>();
        // Transfer the sword to the final owner
        transfer::public_transfer(sword, final_owner);
    };

    // Third transaction executed by the final sword owner
    scenario.next_tx(final_owner);
    {
        // Extract the sword owned by the final owner
        let sword = scenario.take_from_sender<Sword>();
        // Verify that the sword has expected properties
        assert!(sword.magic() == 42 && sword.strength() == 7, 1);
        // Return the sword to the object pool (it cannot be simply "dropped")
        scenario.return_to_sender(sword)
    };
    scenario.end();
}

There are some details of the new testing function to pay attention to. The first thing the code does is create some addresses that represent users participating in the testing scenario. The test then creates a scenario by starting the first transaction on behalf of the initial sword owner.

The initial owner then executes the second transaction (passed as an argument to the test_scenario::next_tx function), who then transfers the sword they now own to the final owner. In pure Move there is no notion of Sui storage; consequently, there is no easy way for the emulated Sui transaction to retrieve it from storage. This is where the test_scenario module helps - its take_from_sender function allows an address-owned object of a given type (Sword) executing the current transaction to be available for Move code manipulation. For now, assume that there is only one such object. In this case, the test transfers the object it retrieves from storage to another address.

TIP
Transaction effects, such as object creation and transfer become visible only after a given transaction completes. For example, if the second transaction in the running example created a sword and transferred it to the administrator's address, it would only become available for retrieval from the administrator's address (via test_scenario, take_from_sender, or take_from_address functions) in the third transaction.

The final owner executes the third and final transaction that retrieves the sword object from storage and checks if it has the expected properties. Remember, as described in Testing a package, in the pure Move testing scenario, after an object is available in Move code (after creation or retrieval from emulated storage), it cannot simply disappear.

In the pure Move testing function, the function transfers the sword object to the fake address to handle the disappearing problem. The test_scenario package provides a more elegant solution, however, which is closer to what happens when Move code actually executes in the context of Sui - the package simply returns the sword to the object pool using the test_scenario::return_to_sender function. For scenarios where returning to the sender is not desirable or if you would like to simply destroy the object, the test_utils module also provides the generic destroy<T> function, that can be used on any type T regardless of its ability. It is advisable to check out other useful functions in the test_scenario and test_utils modules as well.

Run the test command again to see two successful tests for our module:

BUILDING Sui
BUILDING MoveStdlib
BUILDING my_first_package
Running Move unit tests
[ PASS    ] 0x0::my_module::test_sword_create
[ PASS    ] 0x0::my_module::test_sword_transactions
Test result: OK. Total tests: 2; passed: 2; failed: 0

Module initializers
Each module in a package can include a special initializer function that runs at publication time. The goal of an initializer function is to pre-initialize module-specific data (for example, to create singleton objects). The initializer function must have the following properties for it to execute at publication:

Function name must be init
The parameter list must end with either a &mut TxContext or a &TxContext type
No return values
Private visibility
Optionally, the parameter list starts by accepting the module's one-time witness by value
For example, the following init functions are all valid:

fun init(ctx: &TxContext)
fun init(ctx: &mut TxContext)
fun init(otw: EXAMPLE, ctx: &TxContext)
fun init(otw: EXAMPLE, ctx: &mut TxContext)
While the sui move command does not support publishing explicitly, you can still test module initializers using the testing framework by dedicating the first transaction to executing the initializer function.

The init function for the module in the running example creates a Forge object.

/// Module initializer to be executed when this module is published
fun init(ctx: &mut TxContext) {
    let admin = Forge {
        id: object::new(ctx),
        swords_created: 0,
    };

    // Transfer the forge object to the module/package publisher
    transfer::transfer(admin, ctx.sender());
}

The tests you have so far call the init function, but the initializer function itself isn't tested to ensure it properly creates a Forge object. To test this functionality, add a new_sword function to take the forge as a parameter and to update the number of created swords at the end of the function. If this were an actual module, you'd replace the sword_create function with new_sword. To keep the existing tests from failing, however, we will keep both functions.

/// Constructor for creating swords
public fun new_sword(
    forge: &mut Forge,
    magic: u64,
    strength: u64,
    ctx: &mut TxContext,
): Sword {
    forge.swords_created = forge.swords_created + 1;
    Sword {
        id: object::new(ctx),
        magic: magic,
        strength: strength,
    }
}

Now, create a function to test the module initialization:

#[test]
fun test_module_init() {
    use sui::test_scenario;

    // Create test addresses representing users
    let admin = @0xAD;
    let initial_owner = @0xCAFE;

    // First transaction to emulate module initialization
    let mut scenario = test_scenario::begin(admin);
    {
        init(scenario.ctx());
    };

    // Second transaction to check if the forge has been created
    // and has initial value of zero swords created
    scenario.next_tx(admin);
    {
        // Extract the Forge object
        let forge = scenario.take_from_sender<Forge>();
        // Verify number of created swords
        assert!(forge.swords_created() == 0, 1);
        // Return the Forge object to the object pool
        scenario.return_to_sender(forge);
    };

    // Third transaction executed by admin to create the sword
    scenario.next_tx(admin);
    {
        let mut forge = scenario.take_from_sender<Forge>();
        // Create the sword and transfer it to the initial owner
        let sword = forge.new_sword(42, 7, scenario.ctx());
        transfer::public_transfer(sword, initial_owner);
        scenario.return_to_sender(forge);
    };
    scenario.end();
}

As the new test function shows, the first transaction (explicitly) calls the initializer. The next transaction checks if the Forge object has been created and properly initialized. Finally, the admin uses the Forge to create a sword and transfer it to the initial owner.

You can refer to the source code for the package (with all the tests and functions properly adjusted) in the first_package module in the sui/examples directory.

Related links
Publish a Package: Continue the example by publishing your package to the Sui network.
Package Upgrades: Upgrading packages published on the Sui network.

Publish a Package
Before you can call functions in a Move package (beyond an emulated Sui execution scenario), that package must be available on the Sui network. When you publish a package, you are actually creating an immutable Sui object on the network that anyone can access.

To publish your package to the Sui network, use the publish CLI command in the root of your package. Use the --gas-budget flag to set a value for the maximum amount of gas the transaction can cost. If the cost of the transaction is more than the budget you set, the transaction fails and your package doesn't publish.

TIP
Beginning with the Sui v1.24.1 release, the --gas-budget flag is no longer required for CLI commands.

$ sui client publish --gas-budget 5000000

If the publish transaction is successful, your terminal or console responds with the details of the publish transaction separated into sections, including transaction data, transaction effects, transaction block events, object changes, and balance changes.

In the Object Changes table, you can find the information about the package you just published in the Published Objects section. Your response has the actual PackageID that identifies the package (instead of <PACKAGE-ID>) in the form 0x123...ABC.

╭─────────────────────────────────────────────────────────────────────╮
│ Object Changes                                                      │
├─────────────────────────────────────────────────────────────────────┤
│ Created Objects:                                                    │
│  ...                                                                │
|                                                                     |
│ Mutated Objects:                                                    │
│  ...                                                                │
|                                                                     |
│ Published Objects:                                                  │
│  ┌──                                                                │
│  │ PackageID: <PACKAGE-ID>                                          │
│  │ Version: 1                                                       │
│  │ Digest: <DIGEST-HASH>                                            │
│  │ Modules: my_module                                               │
│  └──                                                                │
╰─────────────────────────────────────────────────────────────────────╯

Your currently active address now has three objects (or more, if you had objects prior to this example). Assuming you are using a new address, running the sui objects command reveals what those objects are.

$ sui client objects

╭───────────────────────────────────────────────────────────────────────────────────────╮
│ ╭────────────┬──────────────────────────────────────────────────────────────────────╮ │
│ │ objectId   │  <OBJECT-ID>                                                         │ │
│ │ version    │  10                                                                  │ │
│ │ digest     │  <DIGEST-HASH>                                                       │ │
│ │ objectType │  <PACKAGE-ID>::my_module::Forge                                      │ │
│ ╰────────────┴──────────────────────────────────────────────────────────────────────╯ │
│ ╭────────────┬──────────────────────────────────────────────────────────────────────╮ │
│ │ objectId   │  <OBJECT-ID>                                                         │ │
│ │ version    │  10                                                                  │ │
│ │ digest     │  <DIGEST-HASH>                                                       │ │
│ │ objectType │  0x0000..0002::coin::Coin                                            │ │
│ ╰────────────┴──────────────────────────────────────────────────────────────────────╯ │
│ ╭────────────┬──────────────────────────────────────────────────────────────────────╮ │
│ │ objectId   │  <OBJECT-ID>                                                         │ │
│ │ version    │  10                                                                  │ │
│ │ digest     │  <DIGEST-HASH>                                                       │ │
│ │ objectType │  0x0000..0002::package::UpgradeCap                                   │ │
│ ╰────────────┴──────────────────────────────────────────────────────────────────────╯ │
╰───────────────────────────────────────────────────────────────────────────────────────╯

The objectId field is the unique identifier of each object.

Coin object: You received the Coin object from the Testnet faucet. It's value is slightly less than when you received it because of the cost of gas for the publish transaction.
Forge object: Recall that the init function runs when the package gets published. The init function for this example package creates a Forge object and transfers it to the publisher (you).
UpgradeCap object: Each package you publish results in the receipt of an UpgradeCap object. You use this object to upgrade the package later or to burn it so the package cannot be upgraded.
Sui Blockchain
Forge
address
UpgradeCap
Coin
Interact with the package
Now that the package is on chain, you can call its functions to interact with the package. You can use the sui client call command to make individual calls to package functions, or you can construct more advanced blocks of transactions using the sui client ptb command. The ptb part of the command stands for programmable transaction blocks. In basic terms, PTBs allow you to group commands together in a single transaction for more efficient and cost-effective network activity.

Sui Blockchain
Sword
PTB
my_module::new_sword(&Forge, strength, magic)
address
Sui client
For example, you can create a new Sword object defined in the package by calling the new_sword function in the my_module package, and then transfer the Sword object to any address:

$ sui client ptb \
	--assign forge @<FORGE-ID> \
	--assign to_address @<TO-ADDRESS> \
	--move-call <PACKAGE-ID>::my_module::new_sword forge 3 3 \
	--assign sword \
	--transfer-objects "[sword]" to_address \
	--gas-budget 20000000

INFO
You can pass literal addresses and objects IDs by prefixing them with '@'. This is needed to distinguish a hexadecimal value from an address in some situations.

For addresses that are in your local wallet, you can use their alias instead (passing them without '@', for example, --transfer-objects my_alias).

Make sure to replace <FORGE-ID>, <TO-ADDRESS>, and <PACKAGE-ID> with the actual objectId of the Forge object, the address of the recipient (your address in this case), and the packageID of the package, respectively.

After the transaction executes, you can check the status of the Sword object by using the sui client objects command again. Provided you used your address as the <TO-ADDRESS>, you should now see a total of four objects:

╭───────────────────────────────────────────────────────────────────────────────────────╮
│ ╭────────────┬──────────────────────────────────────────────────────────────────────╮ │
│ │ objectId   │  <OBJECT-ID>                                                         │ │
│ │ version    │  11                                                                  │ │
│ │ digest     │  <DIGEST-HASH>                                                       │ │
│ │ objectType │  <PACKAGE-ID>::my_module::Forge                                      │ │
│ ╰────────────┴──────────────────────────────────────────────────────────────────────╯ │
│ ╭────────────┬──────────────────────────────────────────────────────────────────────╮ │
│ │ objectId   │  <OBJECT-ID>                                                         │ │
│ │ version    │  11                                                                  │ │
│ │ digest     │  <DIGEST-HASH>                                                       │ │
│ │ objectType │  0x0000..0002::coin::Coin                                            │ │
│ ╰────────────┴──────────────────────────────────────────────────────────────────────╯ │
│ ╭────────────┬──────────────────────────────────────────────────────────────────────╮ │
│ │ objectId   │  <OBJECT-ID>                                                         │ │
│ │ version    │  11                                                                  │ │
│ │ digest     │  <DIGEST-HASH>                                                       │ │
│ │ objectType │  <PACKAGE-ID>::my_module::Sword                                      │ │
│ ╰────────────┴──────────────────────────────────────────────────────────────────────╯ │
│ ╭────────────┬──────────────────────────────────────────────────────────────────────╮ │
│ │ objectId   │  <OBJECT-ID>                                                         │ │
│ │ version    │  10                                                                  │ │
│ │ digest     │  <DIGEST-HASH>                                                       │ │
│ │ objectType │  0x0000..0002::package::UpgradeCap                                   │ │
│ ╰────────────┴──────────────────────────────────────────────────────────────────────╯ │
╰───────────────────────────────────────────────────────────────────────────────────────╯

Congratulations! You have successfully published a package to the Sui network and modified the blockchain state by using a programmable transaction block.

Related links
Debugging: Print values to aid in logic debugging.
Package Upgrades: Upgrading packages published on the Sui network.
Publish a Move Package: More details about using the CLI to publish a package.
Programmable Transaction Blocks: PTBs are collections of transactions that are executed together.
Sui Client PTB CLI: The client ptb command allows you to specify the transactions for execution in a programmable transaction block directly from your CLI or through bash scripts.
App Examples: End-to-end examples that include smart contract logic and frontend code.

Debugging
Move does not currently have a native debugger. You can use the std::debug module, however, to print arbitrary values to the console. Monitoring variable values in this manner can provide insight into the logic of your modules. To do so, first declare an alias to the debug module in your source file for more concise access:

use std::debug;

Then in places where you want to print out a value v, regardless of its type, add the following code:

debug::print(&v);

or the following if v is already a reference:

debug::print(v);

The debug module also provides a function to print out the current stacktrace:

debug::print_stack_trace();

Alternatively, any call to abort or assertion failure also prints the stacktrace at the point of failure.

Using debug in my_module
To see the module in action, update your my_module code to include debug calls. Specifically, update the new_sword function so that you print the value of forge before and after updating swords_created. Also, include a print_stack_trace so that the function looks like the following:

public fun new_sword(
    forge: &mut Forge,
    magic: u64,
    strength: u64,
    ctx: &mut TxContext,
): Sword {
    debug::print(forge);
    forge.swords_created = forge.swords_created + 1;
    debug::print(forge);
    debug::print_stack_trace();
    Sword {
        id: object::new(ctx),
        magic: magic,
        strength: strength,
    }
}

To see the results, run the module's tests.

$ sui move test

The response prints out the expected results as the test calls the new_sword function.

INCLUDING DEPENDENCY Sui
INCLUDING DEPENDENCY MoveStdlib
BUILDING my_first_package
Running Move unit tests
[ PASS    ] 0x0::my_module::test_module_init
[debug] 0x0::my_module::Forge {
  id: 0x2::object::UID {
    id: 0x2::object::ID {
      bytes: @0x34401905bebdf8c04f3cd5f04f442a39372c8dc321c29edfb4f9cb30b23ab96
    }
  },
  swords_created: 0
}
[debug] 0x0::my_module::Forge {
  id: 0x2::object::UID {
    id: 0x2::object::ID {
      bytes: @0x34401905bebdf8c04f3cd5f04f442a39372c8dc321c29edfb4f9cb30b23ab96
    }
  },
  swords_created: 1
}
Call Stack:
    [0] 0000000000000000000000000000000000000000000000000000000000000000::my_module::test_module_init

        Code:
            [35] LdU64(7)
            [36] MutBorrowLoc(3)
            [37] Call(15)
          > [38] Call(5)
            [39] LdConst(0)
            [40] CallGeneric(2)
            [41] ImmBorrowLoc(3)

        Locals:
            [0] -
            [1] { { { <OBJECT-ID-WITHOUT-0x> } }, 1 }
            [2] -
            [3] { 2, { 00000000000000000000000000000000000000000000000000000000000000ad, [2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 0, 0, 0 } }


Operand Stack:

[ PASS    ] 0x0::my_module::test_sword_transactions
Test result: OK. Total tests: 2; passed: 2; failed: 0


The output shows the value of the swords_created field of the Forge change after the increment. The stack trace shows the bytecode instructions that have been executed so far, and the next few instructions to execute.

INFO
The specific bytecode offsets and the indices of the local variables might vary depending on the version of the Sui toolchain.

Related links
Publish a Package: Publish the example to the Sui network.

Client App with Sui TypeScript SDK
This exercise diverges from the example built in the previous topics in this section. Rather than adding a frontend to the running example, the instruction walks you through setting up dApp Kit in a React App, allowing you to connect to wallets, and query data from Sui RPC nodes to display in your app. You can use it to create your own frontend for the example used previously, but if you want to get a fully functional app up and running quickly, run the following command in a terminal or console to scaffold a new app with all steps in this exercise already implemented:

INFO
You must use the pnpm or yarn package managers to create Sui project scaffolds. Follow the pnpm install or yarn install instructions, if needed.

pnpm create @mysten/dapp --template react-client-dapp

or

yarn create @mysten/dapp --template react-client-dapp

What is the Sui TypeScript SDK?
The Sui TypeScript SDK (@mysten/sui) provides all the low-level functionality needed to interact with Sui ecosystem from TypeScript. You can use it in any TypeScript or JavaScript project, including web apps, Node.js apps, or mobile apps written with tools like React Native that support TypeScript.

For more information on the Sui TypeScript SDK, see the Sui TypeScript SDK documentation.

What is dApp Kit?
dApp Kit (@mysten/dapp-kit) is a collection of React hooks, components, and utilities that make building dApps on Sui straightforward. For more information on dApp Kit, see the dApp Kit documentation.

Installing dependencies
To get started, you need a React app. The following steps apply to any React, so you can follow the same steps to add dApp Kit to an existing React app. If you are starting a new project, you can use Vite to scaffold a new React app.

Run the following command in your terminal or console, and select React as the framework, and then select one of the TypeScript templates:

npm
Yarn
pnpm
npm init vite

Now that you have a React app, you can install the necessary dependencies to use dApp Kit:

npm
Yarn
pnpm
npm install @mysten/sui @mysten/dapp-kit @tanstack/react-query

Setting up Provider components
To use all the features of dApp Kit, wrap your app with a couple of Provider components.

Open the root component that renders your app (the default location the Vite template uses is src/main.tsx) and integrate or replace the current code with the following.

The first Provider to set up is the QueryClientProvider from @tanstack/react-query. This Provider manages request state for various hooks in dApp kit. If you're already using @tanstack/react-query, dApp Kit can share the same QueryClient instance.

import { QueryClient, QueryClientProvider } from '@tanstack/react-query';

const queryClient = new QueryClient();

ReactDOM.createRoot(document.getElementById('root')!).render(
	<React.StrictMode>
		<QueryClientProvider client={queryClient}>
			<App />
		</QueryClientProvider>
	</React.StrictMode>,
);

Next, set up the SuiClientProvider. This Provider delivers a SuiClient instance from @mysten/sui to all the hooks in dApp Kit. This provider manages which network dApp Kit connects to, and can accept configuration for multiple networks. This exercise connects to devnet.

import { SuiClientProvider } from '@mysten/dapp-kit';
import { getFullnodeUrl } from '@mysten/sui/client';
import { QueryClient, QueryClientProvider } from '@tanstack/react-query';

const queryClient = new QueryClient();
const networks = {
	devnet: { url: getFullnodeUrl('devnet') },
	mainnet: { url: getFullnodeUrl('mainnet') },
};

ReactDOM.createRoot(document.getElementById('root')!).render(
	<React.StrictMode>
		<QueryClientProvider client={queryClient}>
			<SuiClientProvider networks={networks} defaultNetwork="devnet">
				<App />
			</SuiClientProvider>
		</QueryClientProvider>
	</React.StrictMode>,
);

Finally, set up the WalletProvider from @mysten/dapp-kit, and import styles for the dapp-kit components.

import '@mysten/dapp-kit/dist/index.css';

import { SuiClientProvider, WalletProvider } from '@mysten/dapp-kit';
import { getFullnodeUrl } from '@mysten/sui/client';
import { QueryClient, QueryClientProvider } from '@tanstack/react-query';

const queryClient = new QueryClient();
const networks = {
	devnet: { url: getFullnodeUrl('devnet') },
	mainnet: { url: getFullnodeUrl('mainnet') },
};

ReactDOM.createRoot(document.getElementById('root')!).render(
	<React.StrictMode>
		<QueryClientProvider client={queryClient}>
			<SuiClientProvider networks={networks} defaultNetwork="devnet">
				<WalletProvider>
					<App />
				</WalletProvider>
			</SuiClientProvider>
		</QueryClientProvider>
	</React.StrictMode>,
);

Connecting to a wallet
With all Providers set up, you can use dApp Kit hooks and components. To allow users to connect their wallets to your dApp, add a ConnectButton.

import { ConnectButton } from '@mysten/dapp-kit';

function App() {
	return (
		<div className="App">
			<header className="App-header">
				<ConnectButton />
			</header>
		</div>
	);
}

The ConnectButton component displays a button that opens a modal on click, enabling the user to connect their wallet. Upon connection, it displays their address, and provides the option to disconnect.

Getting the connected wallet address
Now that you have a way for users to connect their wallets, you can start using the useCurrentAccount hook to get details about the connected wallet account.

import { ConnectButton, useCurrentAccount } from '@mysten/dapp-kit';

function App() {
	return (
		<div className="App">
			<header className="App-header">
				<ConnectButton />
			</header>

			<ConnectedAccount />
		</div>
	);
}

function ConnectedAccount() {
	const account = useCurrentAccount();

	if (!account) {
		return null;
	}

	return <div>Connected to {account.address}</div>;
}

Querying data from Sui RPC nodes
Now that you have the account to connect to, you can query for objects the connected account owns:

import { useCurrentAccount, useSuiClientQuery } from '@mysten/dapp-kit';

function ConnectedAccount() {
	const account = useCurrentAccount();

	if (!account) {
		return null;
	}

	return (
		<div>
			<div>Connected to {account.address}</div>;
			<OwnedObjects address={account.address} />
		</div>
	);
}

function OwnedObjects({ address }: { address: string }) {
	const { data } = useSuiClientQuery('getOwnedObjects', {
		owner: address,
	});
	if (!data) {
		return null;
	}

	return (
		<ul>
			{data.data.map((object) => (
				<li key={object.data?.objectId}>
					<a href={`https://example-explorer.com/object/${object.data?.objectId}`}>
						{object.data?.objectId}
					</a>
				</li>
			))}
		</ul>
	);
}


You now have a dApp connected to wallets and can query data from RPC nodes.

Related links
The next step from here is to start interacting with Move modules, constructing transaction blocks, and making Move calls. This exercise continues in the Counter end-to-end example.

End-to-End Example: Continue this exercise by creating an app.
Sui 101: Learn the basics of the Sui network and how to interact with on-chain objects using Move.
Sui Move CLI: The move commands in the Sui CLI provide console or terminal interaction with the Move VM.

Sui 101
In many education systems, 101-level classes are those that teach core competencies to build a foundation for the more advanced topics that are to come. The topics in this section provide the same experience for the Sui blockchain. They examine the core Sui development concepts that you use to build apps on Sui. As you start developing more advanced solutions, knowledge of these topics provides a good base for understanding the more advanced concepts you will employ.

Creating coins and NFTs on Sui
Everything on the Sui blockchain is an object. These topics use code examples to demonstrate how to create these specific types of objects.

Create Coins
Create NFTs
Working with PTBs
You can create programmable transaction blocks (PTBs) on Sui to perform multiple commands in a single transaction. The Working with PTBs topics demonstrate how to build efficient PTBs using the Sui TypeScript SDK.

Go to Working with PTBs.

Using Events
You can emit events from your published packages on the Sui network. Using Events demonstrates how to emit events from your on-chain packages and monitor the activity of other objects emitting events.

Go to Using Events.

Shared versus Owned Objects
Objects on Sui, unlike other blockchains, can be owned as well as shared. You can create transactions that leverage either type or both. Shared versus Owned Objects examines the differences and what considerations you should account for when deciding how to structure your on-chain app.

Go to Shared versus Owned Objects.

Access On-Chain Time
Sui provides a Clock module you can use to get network-based time. Access On-Chain Time examines the Clock module and the behavior of the available methods that affect transaction processing speed and the temporal exactness of the data you receive.

Go to Access On-Chain Time.


Shared versus Owned Objects
Objects on Sui can be shared (accessible for reads and writes by any transaction) or owned (accessible for reads and writes by transactions signed by their owner). Many applications can be built using a solution that either uses shared objects or only owned objects, with trade-offs for each that need to be weighed.

Transactions that use only owned objects benefit from very low latency to finality, because they do not need to go through consensus. On the other hand, the fact that only the owner of the object can access it complicates processes that need to work with objects owned by multiple parties, and access to very hot objects needs to be coordinated off-chain.

Transactions that access one or more shared objects require consensus to sequence reads and writes to those objects, resulting in a slightly higher gas cost and increased latency.

Transactions that access multiple shared objects, or particularly popular objects, might have increases in latency due to contention. However, the advantage of using shared objects lies in the flexibility of allowing multiple addresses to access the same object in a coordinated manner.

To summarize, applications that are extremely sensitive to latency or gas costs, that do not need to handle complex multi-party transactions, or that already require an off-chain service could benefit from a design that only uses owned objects. Applications that require coordination between multiple parties will likely benefit from using shared objects.

For more information on the types of objects that Sui supports, see Object Ownership.

Example: Escrow
The Escrow example demonstrates the trade-offs between shared objects and owned objects by implementing the same application in both styles. It implements a service that allows two addresses to perform a trustless swap of objects with each other (a "trade") with the service holding their objects in escrow.

Locked<T> and Key
Code Sample

Both implementations use a primitive for locking values, which offers the following interface:

module escrow::lock {
    public fun lock<T: store>(obj: T, ctx: &mut TxContext): (Locked<T>, Key);
    public fun unlock<T: store>(locked: Locked<T>, key: Key): T
}

Any T: store can be locked, to get a Locked<T> and a corresponding Key, and conversely, the locked value and its corresponding key can be consumed to get back the wrapped object.

The important property that this interface provides is that locked values cannot be modified except by unlocking them first (and later relocking them). Because unlocking consumes the key, tampering with a locked value can be detected by remembering the ID of the key that it was locked with. This prevents situations where one party in a swap changes the object they are offering to reduce its value.

Owned objects
Code Sample

The protocol for swapping via escrow implemented using owned objects starts with both parties locking their respective objects.

Buyer
escrow::lock
Locked< B>,  key_b
 B
Seller
escrow::lock
Locked< S>,  key_s
 S
This is used to prove that the object has not been tampered with after the swap has been agreed to. If either party doesn't want to proceed at this stage, they just unlock their object.

Assuming both parties are happy to continue, the next step requires both parties to swap the keys.

 key_b
 key_s
Buyer
Seller
A third party acts as custodian. The custodian holds objects that are waiting for their counterparts to arrive and when they arrive, it matches them up to complete the swap.

public fun create<T: key + store>(
    key: Key,
    locked: Locked<T>,
    exchange_key: ID,
    recipient: address,
    custodian: address,
    ctx: &mut TxContext,
) {
    let escrow = Escrow {
        id: object::new(ctx),
        sender: tx_context::sender(ctx),
        recipient,
        exchange_key,
        escrowed_key: object::id(&key),
        escrowed: lock::unlock(locked, key),
    };

    transfer::transfer(escrow, custodian);
}

Seller
Buyer
create
create
Escrow< S>
 key_s,
Locked< S>,
exchange_key:  key_b,
recipient: Buyer
Escrow< B>
 key_b,
Locked< B>,
exchange_key:  key_s,
recipient: Seller
Third_Party
The create function prepares the Escrow request and sends it to the custodian. The object being offered by this party is passed in, locked, with its key, and the object being requested is identified by the ID of the key it was locked with. While preparing the request, the offered object is unlocked, while remembering the ID of its key.

Although the custodian is trusted to preserve liveness (to complete swaps if it owns both sides of a swap and to return objects if requested), all other correctness properties are maintained in Move: Even though the custodian owns both objects being swapped, the only valid action they are permitted to take is to match them up with their correct counterpart to finish the swap, or to return them:

 S
 B
Third_Party
swap
 S,  B
Escrow< B>, Escrow< S>
Buyer
Seller
public fun swap<T: key + store, U: key + store>(
    obj1: Escrow<T>,
    obj2: Escrow<U>,
) {
    let Escrow {
        id: id1,
        sender: sender1,
        recipient: recipient1,
        exchange_key: exchange_key1,
        escrowed_key: escrowed_key1,
        escrowed: escrowed1,
    } = obj1;

    let Escrow {
        id: id2,
        sender: sender2,
        recipient: recipient2,
        exchange_key: exchange_key2,
        escrowed_key: escrowed_key2,
        escrowed: escrowed2,
    } = obj2;

    object::delete(id1);
    object::delete(id2);

    // Make sure the sender and recipient match each other
    assert!(sender1 == recipient2, EMismatchedSenderRecipient);
    assert!(sender2 == recipient1, EMismatchedSenderRecipient);

    // Make sure the objects match each other and haven't been modified
    // (they remain locked).
    assert!(escrowed_key1 == exchange_key2, EMismatchedExchangeObject);
    assert!(escrowed_key2 == exchange_key1, EMismatchedExchangeObject);

    // Do the actual swap
    transfer::public_transfer(escrowed1, recipient1);
    transfer::public_transfer(escrowed2, recipient2);
}

The swap function checks that senders and recipients match and that each party wants the object that the other party is offering, by comparing their respective key IDs. If the custodian tried to match together two unrelated escrow requests to swap, the transaction would not succeed.

Shared objects
Code Sample

The protocol in the shared object case is less symmetric, but still starts with the first party locking the object they want to swap.

Buyer
escrow::lock
Locked< B>,  key_b
 B
The second party can then view the object that was locked, and if they decide they want to swap with it, they indicate their interest by creating a swap request:

Seller
create
Escrow< S>
 S,
exchange_key:  key_b,
recipient: Buyer
Shared Object
public fun create<T: key + store>(
    escrowed: T,
    exchange_key: ID,
    recipient: address,
    ctx: &mut TxContext
) {
    let escrow = Escrow {
        id: object::new(ctx),
        sender: tx_context::sender(ctx),
        recipient,
        exchange_key,
        escrowed,
    };

    transfer::public_share_object(escrow);
}

This time the create request accepts the object being escrowed directly (not locked), and creates a shared Escrow object. The request remembers the address that sent it (who is allowed to reclaim the object if the swap hasn't already happened), and the intended recipient, who is then expected to continue the swap by providing the object they initially locked:

Buyer
 B
Escrow< S>,
 key_b,
Locked< B>
 S
swap
Seller
public fun swap<T: key + store, U: key + store>(
    escrow: Escrow<T>,
    key: Key,
    locked: Locked<U>,
    ctx: &TxContext,
): T {
    let Escrow {
        id,
        sender,
        recipient,
        exchange_key,
        escrowed,
    } = escrow;

    assert!(recipient == tx_context::sender(ctx), EMismatchedSenderRecipient);
    assert!(exchange_key == object::id(&key), EMismatchedExchangeObject);

    // Do the actual swap
    transfer::public_transfer(lock::unlock(locked, key), sender);
    object::delete(id);

    escrowed
}

Even though the Escrow object is a shared object that is accessible by anyone, the Move interface ensures that only the original sender and the intended recipient can successfully interact with it. swap checks that the locked object matches the object that was requested when the Escrow was created (again, by comparing key IDs) and assumes that the intended recipient wants the escrowed object (if they did not, they would not have called swap).

Assuming all checks pass, the object held in Escrow is extracted, its wrapper is deleted and it is returned to the first party. The locked object offered by the first party is also unlocked and sent to the second party, completing the swap.

Comparison
This topic explores two ways to implement a swap between two objects. In both cases there is a point at which one party has made a request and the other has not responded. At this point, both parties may want to access the Escrow object: One to cancel the swap, and the other to complete it.

In one case, the protocol uses only owned objects but requires a custodian to act as an intermediary. This has the advantage of avoiding the costs and latencies of consensus altogether, but involves more steps and requires trusting a third party for liveness.

In the other case, the object is custodied on chain in a shared object. This requires consensus but involves fewer steps, and no third party.

Create Coins and Tokens
Coins and tokens on Sui are similar. In practice, the terms are used interchangeably, but there are some differences in their implementation. You can learn about these differences in the respective standard documentation, Closed-Loop Token and Coin.

Publishing a coin on Sui is nearly as straightforward as publishing a new type. The main difference is the requirement of a one-time witness when creating a coin.

module examples::mycoin {
    use std::option;
    use sui::coin::{Self, Coin, TreasuryCap};
    use sui::transfer;
    use sui::tx_context::{Self, TxContext};

    /// The type identifier of coin. The coin will have a type
    /// tag of kind: `Coin<package_object::mycoin::MYCOIN>`
    /// Make sure that the name of the type matches the module's name.
    struct MYCOIN has drop {}

    /// Module initializer is called once on module publish. A treasury
    /// cap is sent to the publisher, who then controls minting and burning
    fun init(witness: MYCOIN, ctx: &mut TxContext) {
        let (treasury, metadata) = coin::create_currency(witness, 6, b"MYCOIN", b"", b"", option::none(), ctx);
        transfer::public_freeze_object(metadata);
        transfer::public_transfer(treasury, tx_context::sender(ctx))
    }
}


The Coin<T> is a generic implementation of a coin on Sui. Access to the TreasuryCap provides control over the minting and burning of coins. Further transactions can be sent directly to the sui::coin::Coin with TreasuryCap object as authorization.

Extending the example further, add a mint function to the module. Use the mint function of the Coin module to create (mint) a coin and then transfer it to an address.

public fun mint(
    treasury_cap: &mut TreasuryCap<MYCOIN>, 
    amount: u64, 
    recipient: address, 
    ctx: &mut TxContext,
) {
    let coin = coin::mint(treasury_cap, amount, ctx);
    transfer::public_transfer(coin, recipient)
}

Sui CLI
If you published the previous example to a Sui network, you can use the sui client call command to mint coins and deliver them to the address you provide. See Sui CLI for more information on the command line interface.

TIP
Beginning with the Sui v1.24.1 release, the --gas-budget flag is no longer required for CLI commands.

sui client call --function mint --module mycoin --package <PACKAGE-ID> --args <TREASURY-CAP-ID> <COIN-AMOUNT> <RECIPIENT-ADDRESS> --gas-budget <GAS-AMOUNT>


If the call is successful your console displays the result, which includes a Balance Changes section with the following information included:

...

Owner: Account Address ( <RECIPIENT-ADDRESS> ) 
CoinType: <PACKAGE-ID>::mycoin::MYCOIN 
Amount: <COIN-AMOUNT>

...

DenyList
The Sui framework provides a DenyList singleton, shared object that the bearer of a DenyCap can access to specify a list of addresses that are unable to use a Sui core type. The initial use case for DenyList, however, focuses on limiting access to coins of a specified type. This is useful, for example, when creating a regulated coin on Sui that requires the ability to block certain addresses from using it as inputs to transactions. Regulated coins on Sui satisfy any regulations that require the ability to prevent known bad actors from having access to those coins.

INFO
The DenyList object is a system object that has the address 0x403. You cannot create it yourself.

Create regulated coin
If you need the ability to deny specific addresses from having access to your coin, you can use the create_regulated_currency function (instead of create_currency) to create it.

Behind the scenes, create_regulated_currency uses the create_currency function to create the coin, but also produces a DenyCap object that allows its bearer to control access to the coin's deny list in a DenyList object. Consequently, the way to create a coin using create_regulated_currency is similar to the previous example, with the addition of a transfer of the DenyCap object to the module publisher.

Create tokens
Tokens reuse the TreasuryCap defined in the sui::coin module and therefore have the same initialization process. The coin::create_currency function guarantees the uniqueness of the TreasuryCap and forces the creation of a CoinMetadata object.

Coin-like functions perform the minting and burning of tokens. Both require the TreasuryCap:

token::mint - mint a token
token::burn - burn a token
See Closed-Loop Token standard for complete details of working with tokens.

Examples
See the following topics for examples of some common use cases for coin and token creation.

Regulated Coin and Deny List: Create a regulated coin and add or remove names from the deny list.
Loyalty Token: Create a token to reward user loyalty.
In-Game Token: Create tokens that can be used only within a mobile game.

Regulated Coin and Deny List
The Sui Coin standard provides a create_regulated_currency function to create coins. This function is different than create_currency in that it generates a coin that you can block certain addresses from being able to use those coins in transactions. This ability is a requirement for assets like stablecoins.

Behind the scenes, create_regulated_currency uses the create_currency function to create the coin, but also produces a DenyCap object that allows its bearer to control access to the coin's deny list in a DenyList object. Consequently, the way to create a coin using create_regulated_currency is similar to the previous example, with the addition of a transfer of the DenyCap object to the module publisher.

regcoin.move
module examples::regcoin {
    use sui::coin;

    public struct REGCOIN has drop {}

    fun init(witness: REGCOIN, ctx: &mut TxContext) {
        let (treasury, deny_cap, metadata) = coin::create_regulated_currency(witness, 6, b"REGCOIN", b"", b"", option::none(), ctx);
        transfer::public_freeze_object(metadata);
        transfer::public_transfer(treasury, ctx.sender());
        transfer::public_transfer(deny_cap, ctx.sender())
    }
}


When you deploy the previous module using sui client publish, the console responds with transaction effects, including the creation of the following objects:

...

Object Changes

Created Objects:

   ObjectID: <OBJECT-ID>
   Sender: <SENDER-ADDR>
   Owner: Immutable
   ObjectType: 0x2::coin::CoinMetadata<<PACKAGE-ID>::regcoin::REGCOIN>
   Version: <VERSION-NUMBER>
   Digest: <DIGEST-HASH>

   ObjectID: <OBJECT-ID>
   Sender: <SENDER-ADDR>
   Owner: Account Address ( <PUBLISHER-ADDRESS )
   ObjectType: 0x2::package::UpgradeCap
   Version: <VERSION-NUMBER>
   Digest: <DIGEST-HASH>

   ObjectID: <OBJECT-ID>
   Sender: <SENDER-ADDR>
   Owner: Immutable
   ObjectType: 0x2::coin::RegulatedCoinMetadata<<PACKAGE-ID>::regcoin::REGCOIN>
   Version: <VERSION-NUMBER>
   Digest: <DIGEST-HASH>

   ObjectID: <OBJECT-ID>
   Sender: <SENDER-ADDR>
   Owner: Account Address ( <PUBLISHER-ADDRESS )
   ObjectType: 0x2::coin::DenyCap<<PACKAGE-ID>::regcoin::REGCOIN>
   Version: <VERSION-NUMBER>
   Digest: <DIGEST-HASH>


   ObjectID: <OBJECT-ID>
   Sender: <SENDER-ADDR>
   Owner: Account Address ( <PUBLISHER-ADDRESS )
   ObjectType: 0x2::coin::TreasuryCap<PACKAGE-ID>::regcoin::REGCOIN>
   Version: <VERSION-NUMBER>
   Digest: <DIGEST-HASH>

...

As you might have noticed, the publish action creates a RegulatedCoinMetadata object along with the standard CoinMetadata object. You don't need to explicitly call the freeze_object on the RegulatedCoinMetadata object, however, because create_regulated_currency automatically performs this action.

The output also shows the three objects that the publisher now owns: UpgradeCap for package upgrades, TreasuryCap for minting or burning coins, and the DenyCap for adding or removing addresses to or from the deny list for this coin.

DenyList
The Sui framework provides a DenyList singleton, shared object that the bearer of a DenyCap can access to specify a list of addresses that are unable to use a Sui core type. The initial use case for DenyList, however, focuses on limiting access to coins of a specified type. This is useful, for example, when creating a regulated coin on Sui that requires the ability to block certain addresses from using it as inputs to transactions. Regulated coins on Sui satisfy any regulations that require the ability to prevent known bad actors from having access to those coins.

INFO
The DenyList object is a system object that has the address 0x403. You cannot create it yourself.

Manipulate deny list
For the ability to manipulate the addresses assigned to the deny list for your coin, you must add a few functions to the previous example.

public fun add_addr_from_deny_list(denylist: &mut DenyList, denycap: &mut DenyCap<REGCOIN>, denyaddy: address, ctx: &mut TxContext){
    coin::deny_list_add(denylist, denycap, denyaddy, ctx );
}

public fun remove_addr_from_deny_list(denylist: &mut DenyList, denycap: &mut DenyCap<REGCOIN>, denyaddy: address, ctx: &mut TxContext){
    coin::deny_list_remove(denylist, denycap, denyaddy, ctx );
}


To use these functions, you pass the DenyList object (0x403), your DenyCap object ID, and the address you want to either add or remove. Using the Sui CLI, you could use sui client call with the required information:

TIP
Beginning with the Sui v1.24.1 release, the --gas-budget flag is no longer required for CLI commands.

sui client call --function add_addr_from_deny_list --module regcoin --package <PACKAGE-ID> --args <DENY-LIST> <DENY-CAP> <ADDRESS-TO-DENY> --gas-budget <GAS-AMOUNT>
Transaction Digest: <DIGEST-HASH>


The console displays the response from the network, where you can verify the DenyList object is mutated.

...

MutatedObjects:

  ObjectID: 0x0...403               
  Sender: <SENDER-ADDRESS>
  Owner: Shared
  ObjectType: 0x2::deny_list::DenyList
  Version: <VERSION-NUMBER>
  Digest: <DIGEST-HASH>

...


For all Coin functions available, see the Sui framework coin module documentation.

In-Game Currency
Using the Sui Closed-Loop Token standard, you can create in-game currency (such as gems or diamonds in mobile games) that you can grant to players for their actions or make available to purchase. You mint the tokens on Sui, but players can only use the tokens within the economy of the game itself. These types of tokens are usually not transferrable and you would typically mint them in predefined amounts to maintain scarcity and game balance.

The following example creates an in-game currency called a GEM, which represents a certain number of SUI. In the example, the user can buy fungible GEMs using SUI, which can then be used as currency within the game. Use the code comments to follow the logic of the example.

sui/examples/move/token/sources/gems.move
/// This is a simple example of a permissionless module for an imaginary game
/// that sells swords for Gems. Gems are an in-game currency that can be bought
/// with SUI.
module examples::sword {
    use sui::tx_context::TxContext;
    use sui::object::{Self, UID};

    use sui::token::{Self, Token, ActionRequest};
    use examples::gem::GEM;

    /// Trying to purchase a sword with an incorrect amount.
    const EWrongAmount: u64 = 0;

    /// The price of a sword in Gems.
    const SWORD_PRICE: u64 = 10;

    /// A game item that can be purchased with Gems.
    struct Sword has key, store { id: UID }

    /// Purchase a sword with Gems.
    public fun buy_sword(
        gems: Token<GEM>, ctx: &mut TxContext
    ): (Sword, ActionRequest<GEM>) {
        assert!(SWORD_PRICE == token::value(&gems), EWrongAmount);
        (
            Sword { id: object::new(ctx) },
            token::spend(gems, ctx)
        )
    }
}

/// Module that defines the in-game currency: GEMs which can be purchased with
/// SUI and used to buy swords (in the `sword` module).
module examples::gem {
    use std::option::none;
    use std::string::{Self, String};
    use sui::sui::SUI;
    use sui::transfer;
    use sui::object::{Self, UID};
    use sui::balance::{Self, Balance};
    use sui::tx_context::{sender, TxContext};
    use sui::coin::{Self, Coin, TreasuryCap};

    use sui::token::{Self, Token, ActionRequest};

    /// Trying to purchase Gems with an unexpected amount.
    const EUnknownAmount: u64 = 0;

    /// 10 SUI is the price of a small bundle of Gems.
    const SMALL_BUNDLE: u64 = 10_000_000_000;
    const SMALL_AMOUNT: u64 = 100;

    /// 100 SUI is the price of a medium bundle of Gems.
    const MEDIUM_BUNDLE: u64 = 100_000_000_000;
    const MEDIUM_AMOUNT: u64 = 5_000;

    /// 1000 SUI is the price of a large bundle of Gems.
    /// This is the best deal.
    const LARGE_BUNDLE: u64 = 1_000_000_000_000;
    const LARGE_AMOUNT: u64 = 100_000;

    #[allow(lint(coin_field))]
    /// Gems can be purchased through the `Store`.
    struct GemStore has key {
        id: UID,
        /// Profits from selling Gems.
        profits: Balance<SUI>,
        /// The Treasury Cap for the in-game currency.
        gem_treasury: TreasuryCap<GEM>,
    }

    /// The OTW to create the in-game currency.
    struct GEM has drop {}

    // In the module initializer we create the in-game currency and define the
    // rules for different types of actions.
    fun init(otw: GEM, ctx: &mut TxContext) {
        let (treasury_cap, coin_metadata) = coin::create_currency(
            otw, 0, b"GEM", b"Capy Gems", // otw, decimal, symbol, name
            b"In-game currency for Capy Miners", none(), // description, url
            ctx
        );

        // create a `TokenPolicy` for GEMs
        let (policy, cap) = token::new_policy(&treasury_cap, ctx);

        token::allow(&mut policy, &cap, buy_action(), ctx);
        token::allow(&mut policy, &cap, token::spend_action(), ctx);

        // create and share the GemStore
        transfer::share_object(GemStore {
            id: object::new(ctx),
            gem_treasury: treasury_cap,
            profits: balance::zero()
        });

        // deal with `TokenPolicy`, `CoinMetadata` and `TokenPolicyCap`
        transfer::public_freeze_object(coin_metadata);
        transfer::public_transfer(cap, sender(ctx));
        token::share_policy(policy);
    }

    /// Purchase Gems from the GemStore. Very silly value matching against module
    /// constants...
    public fun buy_gems(
        self: &mut GemStore, payment: Coin<SUI>, ctx: &mut TxContext
    ): (Token<GEM>, ActionRequest<GEM>) {
        let amount = coin::value(&payment);
        let purchased = if (amount == SMALL_BUNDLE) {
            SMALL_AMOUNT
        } else if (amount == MEDIUM_BUNDLE) {
            MEDIUM_AMOUNT
        } else if (amount == LARGE_BUNDLE) {
            LARGE_AMOUNT
        } else {
            abort EUnknownAmount
        };

        coin::put(&mut self.profits, payment);

        // create custom request and mint some Gems
        let gems = token::mint(&mut self.gem_treasury, purchased, ctx);
        let req = token::new_request(buy_action(), purchased, none(), none(), ctx);

        (gems, req)
    }

    /// The name of the `buy` action in the `GemStore`.
    public fun buy_action(): String { string::utf8(b"buy") }
}

Loyalty Tokens
Using the Sui Closed-Loop Token standard, you can create tokens that are valid only for a specific service, like an airline that wants to grant tokens to frequent flyers to purchase tickets or upgrades.

The following example demonstrates the creation of a loyalty token that bearers can use to make purchases in a digital gift shop. Use the comments in the code to follow the logic of the example.

examples/move/token/sources/loyalty.move
/// This module illustrates a Closed Loop Loyalty Token. The `Token` is sent to
/// users as a reward for their loyalty by the application Admin. The `Token`
/// can be used to buy a `Gift` in the shop.
///
/// Actions:
/// - spend - spend the token in the shop
module examples::loyalty {
    use std::option;
    use sui::transfer;
    use sui::object::{Self, UID};
    use sui::coin::{Self, TreasuryCap};
    use sui::tx_context::{Self, TxContext};

    use sui::token::{Self, ActionRequest, Token};

    /// Token amount does not match the `GIFT_PRICE`.
    const EIncorrectAmount: u64 = 0;

    /// The price for the `Gift`.
    const GIFT_PRICE: u64 = 10;

    /// The OTW for the Token / Coin.
    struct LOYALTY has drop {}

    /// This is the Rule requirement for the `GiftShop`. The Rules don't need
    /// to be separate applications, some rules make sense to be part of the
    /// application itself, like this one.
    struct GiftShop has drop {}

    /// The Gift object - can be purchased for 10 tokens.
    struct Gift has key, store {
        id: UID
    }

    // Create a new LOYALTY currency, create a `TokenPolicy` for it and allow
    // everyone to spend `Token`s if they were `reward`ed.
    fun init(otw: LOYALTY, ctx: &mut TxContext) {
        let (treasury_cap, coin_metadata) = coin::create_currency(
            otw,
            0, // no decimals
            b"LOY", // symbol
            b"Loyalty Token", // name
            b"Token for Loyalty", // description
            option::none(), // url
            ctx
        );

        let (policy, policy_cap) = token::new_policy(&treasury_cap, ctx);

        // but we constrain spend by this shop:
        token::add_rule_for_action<LOYALTY, GiftShop>(
            &mut policy,
            &policy_cap,
            token::spend_action(),
            ctx
        );

        token::share_policy(policy);

        transfer::public_freeze_object(coin_metadata);
        transfer::public_transfer(policy_cap, tx_context::sender(ctx));
        transfer::public_transfer(treasury_cap, tx_context::sender(ctx));
    }

    /// Handy function to reward users. Can be called by the application admin
    /// to reward users for their loyalty :)
    ///
    /// `Mint` is available to the holder of the `TreasuryCap` by default and
    /// hence does not need to be confirmed; however, the `transfer` action
    /// does require a confirmation and can be confirmed with `TreasuryCap`.
    public fun reward_user(
        cap: &mut TreasuryCap<LOYALTY>,
        amount: u64,
        recipient: address,
        ctx: &mut TxContext
    ) {
        let token = token::mint(cap, amount, ctx);
        let req = token::transfer(token, recipient, ctx);

        token::confirm_with_treasury_cap(cap, req, ctx);
    }

    /// Buy a gift for 10 tokens. The `Gift` is received, and the `Token` is
    /// spent (stored in the `ActionRequest`'s `burned_balance` field).
    public fun buy_a_gift(
        token: Token<LOYALTY>,
        ctx: &mut TxContext
    ): (Gift, ActionRequest<LOYALTY>) {
        assert!(token::value(&token) == GIFT_PRICE, EIncorrectAmount);

        let gift = Gift { id: object::new(ctx) };
        let req = token::spend(token, ctx);

        // only required because we've set this rule
        token::add_approval(GiftShop {}, &mut req, ctx);

        (gift, req)
    }
}

Create a Non-Fungible Token
On Sui, everything is an object. Moreover, in Sui, everything is a non-fungible token (NFT) as its objects are unique, non-fungible, and owned. So technically, a basic type publishing is enough to create a specific NFT.

module examples::devnet_nft {
    use sui::url::{Self, Url};
    use std::string;
    use sui::object::{Self, ID, UID};
    use sui::event;
    use sui::transfer;
    use sui::tx_context::{Self, TxContext};

    /// An example NFT that can be minted by anybody
    struct DevNetNFT has key, store {
        id: UID,
        /// Name for the token
        name: string::String,
        /// Description of the token
        description: string::String,
        /// URL for the token
        url: Url,
        // TODO: allow custom attributes
    }

    // ===== Events =====

    struct NFTMinted has copy, drop {
        // The Object ID of the NFT
        object_id: ID,
        // The creator of the NFT
        creator: address,
        // The name of the NFT
        name: string::String,
    }

    // ===== Public view functions =====

    /// Get the NFT's `name`
    public fun name(nft: &DevNetNFT): &string::String {
        &nft.name
    }

    /// Get the NFT's `description`
    public fun description(nft: &DevNetNFT): &string::String {
        &nft.description
    }

    /// Get the NFT's `url`
    public fun url(nft: &DevNetNFT): &Url {
        &nft.url
    }

    // ===== Entrypoints =====

    /// Create a new devnet_nft
    public fun mint_to_sender(
        name: vector<u8>,
        description: vector<u8>,
        url: vector<u8>,
        ctx: &mut TxContext
    ) {
        let sender = tx_context::sender(ctx);
        let nft = DevNetNFT {
            id: object::new(ctx),
            name: string::utf8(name),
            description: string::utf8(description),
            url: url::new_unsafe_from_bytes(url)
        };

        event::emit(NFTMinted {
            object_id: object::id(&nft),
            creator: sender,
            name: nft.name,
        });

        transfer::public_transfer(nft, sender);
    }

    /// Transfer `nft` to `recipient`
    public fun transfer(
        nft: DevNetNFT, recipient: address, _: &mut TxContext
    ) {
        transfer::public_transfer(nft, recipient)
    }

    /// Update the `description` of `nft` to `new_description`
    public fun update_description(
        nft: &mut DevNetNFT,
        new_description: vector<u8>,
        _: &mut TxContext
    ) {
        nft.description = string::utf8(new_description)
    }

    /// Permanently delete `nft`
    public fun burn(nft: DevNetNFT, _: &mut TxContext) {
        let DevNetNFT { id, name: _, description: _, url: _ } = nft;
        object::delete(id)
    }
}

Using Events
The Sui network stores countless objects on chain where Move code can perform actions using those objects. Tracking this activity is often desired, for example, to discover how many times a module mints an NFT or to tally the amount of SUI in transactions that a smart contract generates.

To support activity monitoring, Move provides a structure to emit events on the Sui network. When you establish a connection with the Sui network, you create a two-way interactive communication session between your client and a Sui network node. With an open session, you can subscribe to specific events that the Sui network adds to the stream to create real-time monitoring of events.

Move event structure
An event object in Sui consists of the following attributes:

id: JSON object containing the transaction digest ID and event sequence.
packageId: The object ID of the package that emits the event.
transactionModule: The module that performs the transaction.
sender: The Sui network address that triggered the event.
type: The type of event being emitted.
parsedJson: JSON object describing the event.
bcs: Binary canonical serialization value.
timestampMs: Unix epoch timestamp in milliseconds.
Discovering events
If you want to subscribe to events on chain, you first need to know what events are available. You typically know or can discover the events your own code emits, but it's not as straightforward when you need to subscribe to on-chain events from packages you don't own. The Sui RPC provides a queryEvents method to query on-chain packages and return available events that you can subscribe to.

Filter events
You can filter the events your code targets for either querying or subscribing. Both filter options are similar but have some differences.

Emit events in Move
To create an event in your Move modules, add the sui::event dependency.

use sui::event;

With the dependency added, you can use the emit function to fire an event whenever the action you want to monitor fires. For example, the following code is part of an example application using digital donuts. The collect_profits function handles the collection of SUI and emits an event whenever the function is called. To act on that event, you need to subscribe to it.

/// Take coin from `DonutShop` and transfer it to tx sender.
/// Requires authorization with `ShopOwnerCap`.
public fun collect_profits( _: &ShopOwnerCap, shop: &mut DonutShop, ctx: &mut TxContext ) {
    let amount = balance::value(&shop.balance);
    let profits = coin::take(&mut shop.balance, amount, ctx);
    // simply create new type instance and emit it.
    event::emit(ProfitsCollected { amount });
    transfer::public_transfer(profits, tx_context::sender(ctx));
}


Subscribe to events in Move
Firing events is not very useful in a vacuum. You also need the ability to listen for those events so that you can act on them. In Sui, you subscribe to those events and provide logic that triggers when the event fires.

Sui Full nodes support subscribe functionality using JSON-RPC notifications transmitted through the WebSocket API. You can interact with the RPC directly (suix_subscribeEvent, suix_subscribeTransaction) or you can use an SDK like the Sui TypeScript SDK. The following excerpt from one of the examples uses the TypeScript SDK to create an asynchronous subscription to the filter identified in the filter.

let unsubscribe = await provider.subscribeEvent({
    filter: { <PACKAGE_ID> },
    onMessage: (event) => {
        console.log("subscribeEvent", JSON.stringify(event, null, 2))
    }
});

Move smart contracts can call other smart contracts that emit events. For example, Deepbook_utils can call the dee9 smart contract and emit this event. Note that using package, transaction module to query for dee9/clob_v2 misses the following event even though it is actually an event the dee9 package emits. The current workaround for this issue is to know all the packageIds you care about and search those in the queryEvent call.

{
	"id": {
		"txDigest": "bZnc1E7k1fJYLxWihfre5xCw1tX1CyAN6579zypJeiU",
		"eventSeq": "0"
	},
	"packageId": "0x158f2027f60c89bb91526d9bf08831d27f5a0fcb0f74e6698b9f0e1fb2be5d05",
	"transactionModule": "deepbook_utils",
	"sender": "0x4419ae182ac112bb065bda2146136ed02524ee2611478bfe8ca5d3835bee4af6",
	"type": "0xdee9::clob_v2::OrderPlaced<0x2::sui::SUI, 0x5d4b302506645c37ff133b98c4b50a5ae14841659738d6d733d59d0d217a93bf::coin::COIN>",
	"parsedJson": {
		"base_asset_quantity_placed": "1000000000",
		"client_order_id": "20082022",
		"expire_timestamp": "1697121171540",
		"is_bid": false,
		"order_id": "9223372036854945121",
		"original_quantity": "1000000000",
		"owner": "0x8c23e5e23c6eb654d69f8ae7de3be23584f435cad81fa4b9cb024b6c989b7818",
		"pool_id": "0x7f526b1263c4b91b43c9e646419b5696f424de28dda3c1e6658cc0a54558baa7",
		"price": "500000"
	},
	"bcs": "2pWctGGQ9KULfmnzNtGuPpggLQrj1ZiUQaxva4neM6QWAtUAkuPAzU2eGrdZaGHti3bsUefDioUwwYoVR3bYBkG7Gxf5JVVSxxqTqzxdg5os5ESwFaP69ZcrNsya4G9rHK4KBac9i3m1MseN38xDwMvAMx3"
}


{
	"id": {
		"txDigest": "896CKHod5GQ4kzhF7EwTAGyhQBdaTb9rQS41dcL76gj8",
		"eventSeq": "0"
	},
	"packageId": "0x000000000000000000000000000000000000000000000000000000000000dee9",
	"transactionModule": "clob_v2",
	"sender": "0xf821d3483fc7725ebafaa5a3d12373d49901bdfce1484f219daa7066a30df77d",
	"type": "0xdee9::clob_v2::OrderPlaced<0xbc3a676894871284b3ccfb2eec66f428612000e2a6e6d23f592ce8833c27c973::coin::COIN, 0x5d4b302506645c37ff133b98c4b50a5ae14841659738d6d733d59d0d217a93bf::coin::COIN>",
	"parsedJson": {
		"base_asset_quantity_placed": "5000000",
		"client_order_id": "1696545636947311087",
		"expire_timestamp": "1696549236947",
		"is_bid": true,
		"order_id": "562414",
		"original_quantity": "5000000",
		"owner": "0xf995d6df20e18421928ff0648bd583ccdf384ab05791d8be21d32977a37dacfc",
		"pool_id": "0xf0f663cf87f1eb124da2fc9be813e0ce262146f3df60bc2052d738eb41a25899",
		"price": "274518000000"
	},
	"bcs": "4SgemkCzrqEsTHLFgMcbUtttZCf2CrEH2njjFL1rizCHzvAoYsToGrbFLffQPtGxsSt96Xr4j2SLNeLcBGKeYXDrVYWqivhf3551Mqj71DZBxq5D1Qwfgh1TKeF43Jz4b4XH1nEpkya2Pr8515vzJbHUkpP"
}


Examples
Subscribe to event
This example leverages the Sui TypeScript SDK to subscribe to events the package with ID <PACKAGE_ID> emits. Each time the event fires, the code displays the response to the console.

TypeScript
To create the event subscription, you can use a basic Node.js app. You need the Sui TypeScript SDK, so install the module using npm install @mysten/sui at the root of your project. In your TypeScript code, import JsonRpcProvider and a connection from the library.

import { getFullnodeUrl, SuiClient } from '@mysten/sui/client';

// Package is on Testnet.
const client = new SuiClient({
	url: getFullnodeUrl('testnet'),
});
const Package = '<PACKAGE_ID>';

const MoveEventType = '<PACKAGE_ID>::<MODULE_NAME>::<METHOD_NAME>';

console.log(
	await client.getObject({
		id: Package,
		options: { showPreviousTransaction: true },
	}),
);

let unsubscribe = await client.subscribeEvent({
	filter: { Package },
	onMessage: (event) => {
		console.log('subscribeEvent', JSON.stringify(event, null, 2));
	},
});

process.on('SIGINT', async () => {
	console.log('Interrupted...');
	if (unsubscribe) {
		await unsubscribe();
		unsubscribe = undefined;
	}
});

Response
When the subscribed to event fires, the example displays the following JSON representation of the event.

subscribeEvent {
  "id": {
    "txDigest": "HkCBeBLQbpKBYXmuQeTM98zprUqaACRkjKmmtvC6MiP1",
    "eventSeq": "0"
  },
  "packageId": "0x2d6733a32e957430324196dc5d786d7c839f3c7bbfd92b83c469448b988413b1",
  "transactionModule": "coin_flip",
  "sender": "0x46f184f2d68007e4344fffe603c4ccacd22f4f28c47f321826e83619dede558e",
  "type": "0x2d6733a32e957430324196dc5d786d7c839f3c7bbfd92b83c469448b988413b1::coin_flip::Outcome",
  "parsedJson": {
    "bet_amount": "4000000000",
    "game_id": "0xa7e1fb3c18a88d048b75532de219645410705fa48bfb8b13e8dbdbb7f4b9bbce",
    "guess": 0,
    "player_won": true
  },
  "bcs": "3oWWjWKRVu115bnnZphyDcJ8EyF9X4pgVguwhEtcsVpBf74B6RywQupm2X",
  "timestampMs": "1687912116638"
}


Rust SDK
use futures::StreamExt;
use sui_sdk::rpc_types::EventFilter;
use sui_sdk::SuiClientBuilder;
use anyhow::Result;

#[tokio::main]
async fn main() -> Result<()> {
    let sui = SuiClientBuilder::default()
        .ws_url("wss://fullnode.mainnet.sui.io:443")
        .build("https://fullnode.mainnet.sui.io:443")
        .await.unwrap();
    let mut subscribe_all = sui.event_api().subscribe_event(EventFilter::All(vec![])).await?;
    loop {
        println!("{:?}", subscribe_all.next().await);
    }
}


Filtering event queries
To filter the events returned from your queries, use the following data structures.

INFO
This set of filters applies only to event querying APIs. It differs from the filters offered for the subscriptions API (see following section). In particular, it does not support combinations like "All": [...], "Any": [...], "And": [_, _], "Or": [_, _], and "Not": _.

Query	Description	JSON-RPC Parameter Example
All	All events	{"All"}
Transaction	Events emitted from the specified transaction	{"Transaction":"DGUe2TXiJdN3FI6MH1FwghYbiHw+NKu8Nh579zdFtUk="}
MoveModule	Events emitted from the specified Move module	{"MoveModule":{"package":"<PACKAGE-ID>", "module":"nft"}}
MoveEventModule	Events emitted, defined on the specified Move module.	{"MoveEventModule": {"package": "<DEFINING-PACKAGE-ID>", "module": "nft"}}
MoveEvent	Move struct name of the event	{"MoveEvent":"::nft::MintNFTEvent"}
EventType	Type of event described in Events section	{"EventType": "NewObject"}
Sender	Query by sender address	{"Sender":"0x008e9c621f4fdb210b873aab59a1e5bf32ddb1d33ee85eb069b348c234465106"}
Recipient	Query by recipient	{"Recipient":{"AddressOwner":"0xa3c00467938b392a12355397bdd3d319cea5c9b8f4fc9c51b46b8e15a807f030"}}
Object	Return events associated with the given object	{"Object":"0x727b37454ab13d5c1dbb22e8741bff72b145d1e660f71b275c01f24e7860e5e5"}
TimeRange	Return events emitted in [start_time, end_time] interval	{"TimeRange":{"startTime":1669039504014, "endTime":1669039604014}}
Filtering events for subscription
To create a subscription, you can set a filter to return only the set of events you're interested in listening for.

INFO
This set of filters applies only to event subscription APIs. It differs from the filters offered for the query API (see previous section). In particular, it supports combinations like "All": [...], "Any": [...], "And": [_, _], "Or": [_, _], and "Not": _.

Filter	Description	JSON-RPC Parameter Example
Package	Move package ID	{"Package":"<PACKAGE-ID>"}
MoveModule	Move module where the event was emitted	{"MoveModule": {"package": "<PACKAGE-ID>", "module": "nft"}}
MoveEventType	Move event type defined in the move code	{"MoveEventType":"<PACKAGE-ID>::nft::MintNFTEvent"}
MoveEventModule	Move event module defined in the move code	{"MoveEventModule": {"package": "<PACKAGE-ID>", "module": "nft", "event": "MintNFTEvent"}}
MoveEventField	Filter using the data fields in the move event object	{"MoveEventField":{ "path":"/name", "value":"NFT"}}
SenderAddress	Address that started the transaction	{"SenderAddress": "0x008e9c621f4fdb210b873aab59a1e5bf32ddb1d33ee85eb069b348c234465106"}
Sender	Sender address	{"Sender":"0x008e9c621f4fdb210b873aab59a1e5bf32ddb1d33ee85eb069b348c234465106"}
Transaction	Transaction hash	{"Transaction":"ENmjG42TE4GyqYb1fGNwJe7oxBbbXWCdNfRiQhCNLBJQ"}
TimeRange	Time range in millisecond	{"TimeRange": {"start_time": "1685959791871", "end_time": "1685959791871"}}

Access On-Chain Time
You have options when needing to access network-based time for your transactions. If you need a near real-time measurement (within a few seconds), use the immutable reference of time provided by the Clock module in Move. The reference value from this module updates with every network checkpoint. If you don't need as current a time slice, use the epoch_timestamp_ms function to capture the precise moment the current epoch started.

The sui::clock::Clock module
To access a prompt timestamp, you must pass a read-only reference of sui::clock::Clock as an entry function parameter in your transactions. An instance of Clock is provided at address 0x6, no new instances can be created.

Extract a unix timestamp in milliseconds from an instance of Clock using

module sui::clock {
    public fun timestamp_ms(clock: &Clock): u64;
}

The example below demonstrates an entry function that emits an event containing a timestamp from the Clock:

module basics::clock {
    use sui::{clock::Clock, event};

    public struct TimeEvent has copy, drop, store {
        timestamp_ms: u64,
    }

    entry fun access(clock: &Clock) {
        event::emit(TimeEvent { timestamp_ms: clock.timestamp_ms() });
    }
}

A call to the previous entry function takes the following form, passing 0x6 as the address for the Clock parameter:

TIP
Beginning with the Sui v1.24.1 release, the --gas-budget flag is no longer required for CLI commands.

sui client call --package <EXAMPLE> --module 'clock' --function 'access' --args '0x6' --gas-budget <GAS-AMOUNT>


Expect the Clock timestamp to change at the rate the network generates checkpoints, which is every 1 second with Narwhal/Bullshark consensus and every 0.1 to 0.2 seconds with Mysticeti consensus.

Successive calls to sui::clock::timestamp_ms in the same transaction always produce the same result (transactions are considered to take effect instantly), but timestamps from Clock are otherwise monotonic across transactions that touch the same shared objects: Successive transactions seeing a greater or equal timestamp to their predecessors.

Any transaction that requires access to a Clock must go through consensus because the only available instance is a shared object. As a result, this technique is not suitable for transactions that must use the single-owner fastpath (see Epoch timestamps for a single-owner-compatible source of timestamps).

Transactions that use the clock must accept it as an immutable reference (not a mutable reference or value). This prevents contention, as transactions that access the Clock can only read it, so do not need to be sequenced relative to each other. Validators refuse to sign transactions that do not meet this requirement and packages that include entry functions that accept a Clock or &mut Clock fail to publish.

The following functions test Clock-dependent code by manually creating a Clock object and manipulating its timestamp. This is possible only in test code:

module sui::clock {
    #[test_only]
    public fun create_for_testing(ctx: &mut TxContext);

    #[test_only]
    public fun share_for_testing(clock: Clock);

    #[test_only]
    public fun increment_for_testing(clock: &mut Clock, tick: u64);

    #[test_only]
    public fun set_for_testing(clock: &mut Clock, timestamp_ms: u64);

    #[test_only]
    public fun destroy_for_testing(clock: Clock);
}

The next example presents a simple test that creates a Clock, increments it, and then checks its value:

module example::clock_tests {
    use sui::clock::{Self, Clock};
    use sui::tx_context;

    #[test]
    fun creating_a_clock_and_incrementing_it() {
        let ctx = tx_context::dummy();
        let clock = clock::create_for_testing(&mut ctx);

        clock.increment_for_testing(42);
        assert!(clock.timestamp_ms() == 42, 1);

        clock.set_for_testing(50);
        assert!(clock.timestamp_ms() == 50, 1);

        clock.destroy_for_testing();
    }
}

Epoch timestamps
You can use the following function to access the timestamp for the start of the current epoch for all transactions (including ones that do not go through consensus):

module sui::tx_context {
    public fun epoch_timestamp_ms(ctx: &TxContext): u64;
}

The preceding function returns the point in time when the current epoch started, as a millisecond granularity unix timestamp in a u64. This value changes roughly once every 24 hours, when the epoch changes.

Tests based on sui::test_scenario can use later_epoch (following code), to exercise time-sensitive code that uses epoch_timestamp_ms (previous code):

module sui::test_scenario {
    public fun later_epoch(
        scenario: &mut Scenario,
        delta_ms: u64,
        sender: address,
    ): TransactionEffects;
}

later_epoch behaves like sui::test_scenario::next_epoch (finishes the current transaction and epoch in the test scenario), but also increments the timestamp by delta_ms milliseconds to simulate the progress of time.

Signing and Sending Transactions
Transactions in Sui represent calls to specific functionality (like calling a smart contract function) that execute on inputs to define the result of the transaction.

Inputs can either be an object reference (either to an owned object, an immutable object, or a shared object), or an encoded value (for example, a vector of bytes used as an argument to a Move call). After a transaction is constructed, usually through using programmable transaction blocks (PTBs), the user signs the transaction and submits it to be executed on chain.

The signature is provided with the private key owned by the wallet, and its public key must be consistent with the transaction sender's Sui address.

Sui uses a SuiKeyPair to produce the signature, which commits to the Blake2b hash digest of the intent message (intent || bcs bytes of tx_data). The signature schemes currently supported are Ed25519 Pure, ECDSA Secp256k1, ECDSA Secp256r1, Multisig, and zkLogin.

You can instantiate Ed25519 Pure, ECDSA Secp256k1, and ECDSA Secp256r1 using SuiKeyPair and use it to sign transactions. Note that this guide does not apply to Multisig and zkLogin, please refer to their own pages (Multisig and zkLogin respectively) for instructions.

With a signature and the transaction bytes, a transaction can be submitted to be executed.

Workflow
The following high-level process describes the overall workflow for constructing, signing and executing an on-chain transaction:

Construct the transaction data by creating a Transaction where multiple transactions are chained. See Building Programmable Transaction Blocks for more information.
The SDK's built-in gas estimation and coin selection picks the gas coin.
Sign the transaction to generate a signature.
Submit the Transaction and its signature for on-chain execution.
INFO
If you want to use a specific gas coin, first find the gas coin object ID to be used to pay for gas, and explicitly use that in the PTB. If there is no gas coin object, use the splitCoin transaction to create a gas coin object. The split coin transaction should be the first transaction call in the PTB.

Examples
The following examples demonstrate how to sign and execute transactions using Rust, TypeScript, or the Sui CLI.

TypeScript
Rust
Sui CLI
There are various ways to instantiate a key pair and to derive its public key and Sui address using the Sui TypeScript SDK.

import { fromHEX } from '@mysten/bcs';
import { getFullnodeUrl, SuiClient } from '@mysten/sui/client';
import { type Keypair } from '@mysten/sui/cryptography';
import { Ed25519Keypair } from '@mysten/sui/keypairs/ed25519';
import { Secp256k1Keypair } from '@mysten/sui/keypairs/secp256k1';
import { Secp256r1Keypair } from '@mysten/sui/keypairs/secp256r1';
import { Transaction } from '@mysten/sui/transactions';

const kp_rand_0 = new Ed25519Keypair();
const kp_rand_1 = new Secp256k1Keypair();
const kp_rand_2 = new Secp256r1Keypair();

const kp_import_0 = Ed25519Keypair.fromSecretKey(
	fromHex('0xd463e11c7915945e86ac2b72d88b8190cfad8ff7b48e7eb892c275a5cf0a3e82'),
);
const kp_import_1 = Secp256k1Keypair.fromSecretKey(
	fromHex('0xd463e11c7915945e86ac2b72d88b8190cfad8ff7b48e7eb892c275a5cf0a3e82'),
);
const kp_import_2 = Secp256r1Keypair.fromSecretKey(
	fromHex('0xd463e11c7915945e86ac2b72d88b8190cfad8ff7b48e7eb892c275a5cf0a3e82'),
);

// $MNEMONICS refers to 12/15/18/21/24 words from the wordlist, e.g. "retire skin goose will hurry this field stadium drastic label husband venture cruel toe wire". Refer to [Keys and Addresses](/concepts/cryptography/transaction-auth/keys-addresses.mdx) for more.
const kp_derive_0 = Ed25519Keypair.deriveKeypair('$MNEMONICS');
const kp_derive_1 = Secp256k1Keypair.deriveKeypair('$MNEMONICS');
const kp_derive_2 = Secp256r1Keypair.deriveKeypair('$MNEMONICS');

const kp_derive_with_path_0 = Ed25519Keypair.deriveKeypair('$MNEMONICS', "m/44'/784'/1'/0'/0'");
const kp_derive_with_path_1 = Secp256k1Keypair.deriveKeypair('$MNEMONICS', "m/54'/784'/1'/0/0");
const kp_derive_with_path_2 = Secp256r1Keypair.deriveKeypair('$MNEMONICS', "m/74'/784'/1'/0/0");

// replace `kp_rand_0` with the variable names above.
const pk = kp_rand_0.getPublicKey();
const sender = pk.toSuiAddress();

// create an example transaction block.
const txb = new Transaction();
txb.setSender(sender);
txb.setGasPrice(5);
txb.setGasBudget(100);
const bytes = await txb.build();
const serializedSignature = (await keypair.signTransaction(bytes)).signature;

// verify the signature locally
expect(await keypair.getPublicKey().verifyTransaction(bytes, serializedSignature)).toEqual(true);

// define sui client for the desired network.
const client = new SuiClient({ url: getFullnodeUrl('testnet') });

// execute transaction.
let res = client.executeTransaction({
	transaction: bytes,
	signature: serializedSignature,
});
console.log(res);


Notes
This guide demonstrates how to sign with a single private key. Refer to Multisig when it is preferred to set up more complex signing policies.
Similarly, native zkLogin does not follow the above steps, see the docs to understand how to derive a zkLogin address, and produce a zkLogin signature with an ephemeral key pair.
If you decide to implement your own signing mechanisms instead of using the previous tools, see the Signatures doc on the accepted signature specifications for each scheme.
Flag is one byte that differentiates signature schemes. See supported schemes and its flag in Signatures.
The execute_transaction_block endpoint takes a list of signatures, so it should contain exactly one user signature, unless you are using sponsored transaction that a second signature for the gas object can be provided. See Sponsored Transactions for more information.

Sponsored transactions are a primitive on the Sui blockchain that enable the execution of a transaction without a user paying the gas. It also discusses the roles in Sponsored Transaction, and a few common use cases. Then it discusses the flow of Sponsored Transaction, mostly for developers who are interested in building a Gas Station or integrate with one. Finally it talks about risk considerations of Sponsored Transaction.

Overview
A transaction on Sui takes a payment to execute. The payment, also known as gas, is a list of 0x2::coin::Coin<0x2::sui::Sui> objects, and paid to Sui validators to secure the network. Although gas is a critical piece in Sui tokenomics, it sometimes adds challenges when new users start to navigate on Sui, especially for web 2.0 users.

Sponsored transactions can reduce the onboarding friction for users because the feature streamlines the process for end users. Using sponsored transactions, you can execute a transaction without requiring the user to pay it themselves. Instead, you can act as a sponsor of the transaction, offering your own payment gas objects for the transaction.

Roles in sponsored transactions
In a sponsored transaction there are three roles: the user, the gas station, and the sponsor.

The user is the entity who wants to execute a transaction.
The gas station is the entity that fulfills the sponsorship request for the user's transaction by providing the gas payment they own.
The sponsor is entity that funds the gas station for its operations.
It's not uncommon for the gas station and the sponsor to be the same entity. For example, a web3 gaming studio could run its own gas station to sponsor users with real free-to-play gaming experiences at its user acquisition stage. Because it's not always trivial to maintain a gas station for teams of any size, that gaming studio could also leverage third-party gas stations to sponsor transactions they want to promote.

The remainder of this guide assumes the sponsor uses their own gas station.

Use cases
The following sections describe some common scenarios where sponsored transactions offer an improved user experience.

App-specific sponsorship
In this scenario, the sponsor has a specific set of applications they want to sponsor.

If the transaction is initialized by the user, the sponsor examines the transaction to make sure it's within the set of approved applications before agreeing to provide the gas payment.
If the transaction is proposed by the sponsor, the user must examine the transaction and decide if they want to execute it. Examples of this type of transaction might include a rewards claim transaction of a campaign or a "try it out" advertisement transaction.
Wildcard sponsorship
In this scenario, the sponsor has few restrictions on the type of transactions the gas payment can be used for.

If the sponsor is a gasless wallet, it may agree to sponsor any valid transactions proposed by its users.
In the form of a reward or discount, the sponsor could offer the user a wildcard gas payment, expressly promising to execute any transactions with that gas payment.
A sponsored transaction is not restricted to these use cases. Essentially, a sponsored transaction is any transaction jointly made by the user and the sponsor. As long as the stakeholders can agree on the transaction details, then the number of possible ways to provide sponsored transactions is limited only by the imagination. Because at least two stakeholders are involved in a sponsored transaction, however, there are some [additional risks](#risk} that you should take steps to mitigate.

Sponsored transaction flow
This section is mostly for developers who are interested in building a gas station or integrating with one.

The data structure of a transaction resembles the following:


pub struct SenderSignedTransaction {
    pub intent_message: IntentMessage<TransactionData>,
    /// A list of signatures signed by all transaction participants.
    /// 1. non participant signature must not be present.
    /// 2. signature order does not matter.
    pub tx_signatures: Vec<GenericSignature>,
}

pub struct TransactionDataV1 {  // <-- A variant of `TransactionData`
    pub kind: TransactionKind,  // <-- This is the actual transaction details
    pub sender: SuiAddress,
    pub gas_data: GasData,
    pub expiration: TransactionExpiration,
}

pub struct GasData {
    pub payment: Vec<ObjectRef>,
    pub owner: SuiAddress,
    pub price: u64,
    pub budget: u64,
}


A few details of note for the preceding code:

sender in TransactionDataV1 (a variant of TransactionData) is the user address.
gas_data in TransactionDataV1 is the gas payment.
GasData allows a list of gas objects, but the same address must own them, namely the owner in GasData (the sponsor). When owner is equal to sender, then it is a regular/non-sponsored transaction.
tx_signatures in SenderSignedTransaction is a list of signatures. For a sponsored transaction, the list needs to contain both signatures of the user and the sponsor in some order. The signatures are signed over the entire TransactionData, including GasData.
So, to construct a correct sponsored transaction, you must first build a TransactionData object. If you are neither the user or the sponsor, you would then pass the transaction to both parties to sign. If you're the sponsor, you would sign the transaction and then pass it and the signature to the other party (in the form of SenderSignedTransaction) for them to sign. In practice, the latter is the more common scenario.

There are three flows of sponsored transaction.

User proposed transaction

(swimlane link)



Sponsor proposed transaction

(swimlane link)



Wildcard gas payment

(swimlane link)



Risk considerations
Because at least two stakeholders are involved in a sponsored transaction, you should take steps to mitigate risk.

Client equivocation risk
Client equivocation happens when more than one legit transaction that shares at least one owned object (such as a gas coin object) at a certain version are submitted to the network simultaneously. On Sui, before a transaction is executed, owned objects in this transaction are locked on validators at specific versions. An honest validator only accepts one transaction and rejects others. Depending on the order validators receive these transactions, validators might accept different transactions. In the event of no single transaction getting accepted by at least 2/3rds of validators, the owned object is locked until end of the epoch.

Practically speaking, client equivocation is rare, mostly caused by buggy client software. After all, no one has incentives to lock their own objects. However, sponsored transactions come with counterparty risks. For example, a malicious user could equivocate the gas station's gas coin object by submitting another transaction that uses one owned object in the gas station signed transaction at the same version. Similarly, a Byzantine gas station could do the same to the user owned objects.

Although this risk might seem trivial, it is helpful to be aware of it. Your gas station should actively monitor user behavior and alert on anything abnormal. Whether you're a user taking advantage of sponsored transactions or a developer integrating with a gas station, consider your reputation to minimize the risk of client equivocation.

Both the user and the sponsor need to sign over the entire TransactionData, including GasData because otherwise a third party (such as a malicious Full node) could snip the partially signed data and cause client equivocation and locking of owned objects.

Censorship risk
If you chooses to submit the dual-signed transaction to the sponsor or gas station rather than a Full node, the transaction might be subject to sponsor or gas station censorship. Namely, the sponsor might choose not to submit the transaction to the network, or delay the submission.

You can mitigate this risk by submitting the transaction directly to a Full node.


Building Programmable Transaction Blocks
This guide explores creating a programmable transaction block (PTB) on Sui using the TypeScript SDK. For an overview of what a PTB is, see Programmable Transaction Blocks in the Concepts section. If you don't already have the Sui TypeScript SDK, follow the install instructions on the Sui TypeScript SDK site.

This example starts by constructing a PTB to send Sui. If you are familiar with the legacy Sui transaction types, this is similar to a paySui transaction. To construct transactions, import the Transaction class, and construct it:

import { Transaction } from '@mysten/sui/transactions';

const txb = new Transaction();

Using this, you can then add transactions to this PTB.

// Create a new coin with balance 100, based on the coins used as gas payment.
// You can define any balance here.
const [coin] = txb.splitCoins(txb.gas, [txb.pure(100)]);

// Transfer the split coin to a specific address.
txb.transferObjects([coin], txb.pure('0xSomeSuiAddress'));

You can attach multiple transaction commands of the same type to a PTB as well. For example, to get a list of transfers, and iterate over them to transfer coins to each of them:

interface Transfer {
	to: string;
	amount: number;
}

// Procure a list of some Sui transfers to make:
const transfers: Transfer[] = getTransfers();

const txb = new Transaction();

// First, split the gas coin into multiple coins:
const coins = txb.splitCoins(
	txb.gas,
	transfers.map((transfer) => txb.pure(transfer.amount)),
);

// Next, create a transfer transaction for each coin:
transfers.forEach((transfer, index) => {
	txb.transferObjects([coins[index]], txb.pure(transfer.to));
});

After you have the PTB defined, you can directly execute it with a signer using signAndExecuteTransaction.

signer.signAndExecuteTransaction({ transaction: txb });

Constructing inputs
Inputs are how you provide external values to PTBs. For example, defining an amount of Sui to transfer, or which object to pass into a Move call, or a shared object.

There are currently two ways to define inputs:

For objects: the txb.object(objectId) function is used to construct an input that contains an object reference.
For pure values: the txb.pure(value, type?) function is used to construct an input for a non-object input.
If value is a Uint8Array, then the value is assumed to be raw bytes and is used directly.
If type is provided, it's used to generate the BCS serialization layout for the value. If not provided, the type is automatically determined based on the value.
Available transactions
Sui supports following transaction commands:

txb.splitCoins(coin, amounts): Creates new coins with the defined amounts, split from the provided coin. Returns the coins so that it can be used in subsequent transactions.
Example: txb.splitCoins(txb.gas, [txb.pure(100), txb.pure(200)])
txb.mergeCoins(destinationCoin, sourceCoins): Merges the sourceCoins into the destinationCoin.
Example: txb.mergeCoins(txb.object(coin1), [txb.object(coin2), txb.object(coin3)])
txb.transferObjects(objects, address): Transfers a list of objects to the specified address.
Example: txb.transferObjects([txb.object(thing1), txb.object(thing2)], txb.pure(myAddress))
txb.moveCall({ target, arguments, typeArguments }): Executes a Move call. Returns whatever the Sui Move call returns.
Example: txb.moveCall({ target: '0x2::devnet_nft::mint', arguments: [txb.pure(name), txb.pure(description), txb.pure(image)] })
txb.makeMoveVec({ type, elements }): Constructs a vector of objects that can be passed into a moveCall. This is required as there's no other way to define a vector as an input.
Example: txb.makeMoveVec({ elements: [txb.object(id1), txb.object(id2)] })
txb.publish(modules, dependencies): Publishes a Move package. Returns the upgrade capability object.
Passing transaction results as arguments
You can use the result of a transaction command as an argument in subsequent transaction commands. Each transaction command method on the transaction builder returns a reference to the transaction result.

// Split a coin object off of the gas object:
const [coin] = txb.splitCoins(txb.gas, [txb.pure(100)]);
// Transfer the resulting coin object:
txb.transferObjects([coin], txb.pure(address));

When a transaction command returns multiple results, you can access the result at a specific index either using destructuring, or array indexes.

// Destructuring (preferred, as it gives you logical local names):
const [nft1, nft2] = txb.moveCall({ target: '0x2::nft::mint_many' });
txb.transferObjects([nft1, nft2], txb.pure(address));

// Array indexes:
const mintMany = txb.moveCall({ target: '0x2::nft::mint_many' });
txb.transferObjects([mintMany[0], mintMany[1]], txb.pure(address));

Use the gas coin
With PTBs, you can use the gas payment coin to construct coins with a set balance using splitCoin. This is useful for Sui payments, and avoids the need for up-front coin selection. You can use txb.gas to access the gas coin in a PTB, and it is valid as input for any arguments; with the exception of transferObjects, txb.gas must be used by-reference. Practically speaking, this means you can also add to the gas coin with mergeCoins or borrow it for Move functions with moveCall.

You can also transfer the gas coin using transferObjects, in the event that you want to transfer all of your coin balance to another address.

Get PTB bytes
If you need the PTB bytes, instead of signing or executing the PTB, you can use the build method on the transaction builder itself.

TIP
You might need to explicitly call setSender() on the PTB to ensure that the sender field is populated. This is normally done by the signer before signing the transaction, but will not be done automatically if you're building the PTB bytes yourself.

const txb = new Transaction();

// ... add some transactions...

await txb.build({ provider });

In most cases, building requires your JSON RPC provider to fully resolve input values.

If you have PTB bytes, you can also convert them back into a Transaction class:

const bytes = getTransactionBytesFromSomewhere();
const txb = Transaction.from(bytes);

Building offline
In the event that you want to build a PTB offline (as in with no provider required), you need to fully define all of your input values, and gas configuration (see the following example). For pure values, you can provide a Uint8Array which is used directly in the transaction. For objects, you can use the Inputs helper to construct an object reference.

import { Inputs } from '@mysten/sui/transactions';

// For pure values:
txb.pure(pureValueAsBytes);

// For owned or immutable objects:
txb.object(Inputs.ObjectRef({ digest, objectId, version }));

// For shared objects:
txb.object(Inputs.SharedObjectRef({ objectId, initialSharedVersion, mutable }));

You can then omit the provider object when calling build on the transaction. If there is any required data that is missing, this will throw an error.

Gas configuration
The new transaction builder comes with default behavior for all gas logic, including automatically setting the gas price, budget, and selecting coins to be used as gas. This behavior can be customized.

Gas price
By default, the gas price is set to the reference gas price of the network. You can also explicitly set the gas price of the PTB by calling setGasPrice on the transaction builder.

txb.setGasPrice(gasPrice);

Budget
By default, the gas budget is automatically derived by executing a dry-run of the PTB beforehand. The dry run gas consumption is then used to determine a balance for the transaction. You can override this behavior by explicitly setting a gas budget for the transaction, by calling setGasBudget on the transaction builder.

INFO
The gas budget is represented in Sui, and should take the gas price of the PTB into account.

txb.setGasBudget(gasBudgetAmount);

Gas payment
By default, the gas payment is automatically determined by the SDK. The SDK selects all coins at the provided address that are not used as inputs in the PTB.

The list of coins used as gas payment will be merged down into a single gas coin before executing the PTB, and all but one of the gas objects will be deleted. The gas coin at the 0-index will be the coin that all others are merged into.

// NOTE: You need to ensure that the coins do not overlap with any
// of the input objects for the PTB.
txb.setGasPayment([coin1, coin2]);

dApp / Wallet integration
The Wallet Standard interface has been updated to support the Transaction kind directly. All signTransaction and signAndExecuteTransaction calls from dApps into wallets is expected to provide a Transaction class. This PTB class can then be serialized and sent to your wallet for execution.

To serialize a PTB for sending to a wallet, Sui recommends using the txb.serialize() function, which returns an opaque string representation of the PTB that can be passed from the wallet standard dApp context to your wallet. This can then be converted back into a Transaction using Transaction.from().

TIP
You should not build the PTB from bytes in the dApp code. Using serialize instead of build allows you to build the PTB bytes within the wallet itself. This allows the wallet to perform gas logic and coin selection as needed.

// Within a dApp
const tx = new Transaction();
wallet.signTransaction({ transaction: tx });

// Your wallet standard code:
function handleSignTransaction(input) {
	sendToWalletContext({ transaction: input.transaction.serialize() });
}

// Within your wallet context:
function handleSignRequest(input) {
	const userTx = Transaction.from(input.transaction);
}

Sponsored PTBs
The PTB builder can support sponsored PTBs by using the onlyTransactionKind flag when building the PTB.

const txb = new Transaction();
// ... add some transactions...

const kindBytes = await txb.build({ provider, onlyTransactionKind: true });

// Construct a sponsored transaction from the kind bytes:
const sponsoredTxb = Transaction.fromKind(kindBytes);

// You can now set the sponsored transaction data that is required:
sponsoredTxb.setSender(sender);
sponsoredTxb.setGasOwner(sponsor);
sponsoredTxb.setGasPayment(sponsorCoins);

Coin Management
A key concept when programming on Sui is that of owned objects. Address-owned objects are important in that they allow for highly parallelizable transactions. And they also logically map to assets or resources that someone exclusively owns. Coins are a typical case of owned object usage, with cash being a real-life reference. The owned objects paradigm, however, and particularly as related to coins, is somewhat of a divergence from other blockchains which have a concept of balance. In other words, in other systems, especially account based systems, coins are held in a single location (field) which can be thought of as a balance in a bank account.

Because Sui uses owned objects instead of a balance, it is common to own a number of coins, at times even a significant number of them. Some scenarios necessitate merging some or all of those coins into a single object. At times, merging coins together might even be required because the amount necessary to execute a transaction is more than any single coin the sender owns, thus making merging an inevitable step.

SDK usage
The Sui SDKs (TypeScript and Rust) manage coins on your behalf, removing the overhead of having to deal with coin management manually. The SDKs attempt to merge coins whenever possible and assume that transactions are executed in sequence. That's a reasonable assumption with wallet-based transactions and for common scenarios in general. Sui recommends relying on this feature if you do not have a need for heavy parallel or concurrent execution.

Gas Smashing
When executing a transaction Sui allows you to provide a number of coins as payment. In other words, the payment can be a vector of coins rather than a single coin. That feature, known as gas smashing, performs merging of coins automatically, and presents the PTBs you write with a single gas coin that can be used for other purposes besides just gas.

Basically, you can provide as many coins as you want (with a max limit defined in the protocol configuration) and have all of them merged (smashed) into the first coin provided as payment. That coin, minus the gas budget, is then available inside the transaction and can be used in any command. If the coin is unused it is returned to the user.

Gas smashing is an important feature - and a key concept to understand - to have for the optimal management of coins. See Gas Smashing for more details.

Generic coins
Gas smashing works well for Coin<Sui> objects, which is the only coin type that can be used for gas payment.

Any other coin type requires explicit management from users. PTBs offer a mergeCoins command that you can use to combine multiple coins into a single one. And a splitCoins as the complementary operation to break them up.

From a cost perspective, those are very cheap transactions, however they require a user to be aware of their coin distribution and their own needs.

Concurrency
Merging coins, and particularly Coin<Sui>, into a single coin or a very small number of coins might prove problematic in scenarios where heavy or high concurrency is required.

If you merge all Coin<Sui> into a single one, you would need to sequentially submit every transaction. The coin - being an owned object - would have to be provided with a version and it would be locked by the system when signing a transaction, effectively making it impossible to use it in any other transaction until the one that locked it was executed. Moreover, an attempt to sign multiple transactions with the same coin might result in equivocation and the coin being unusable and locked until the end of the epoch.

So when you require heavy concurrency, you should first split a coin into as many coins as the number of transactions to execute concurrently. Alternatively, you could provide multiple and different coins (gas smashing) to the different transactions. It is critically important that the set of coins you use in the different transactions has no intersection at all.

The possible pitfalls in dealing with heavy concurrency are many. Concurrency in transaction execution is not the only performance bottleneck. In creating and submitting a transaction, several round trips with a Full node might be required to discover and fetch the right objects, and to dry run a transaction. Those round trips might affect performance significantly.

Concurrency is a difficult subject and is beyond the scope of this documentation. You must take maximum care when dealing with coin management in the face of concurrency, and the right strategy is often tied to the specific scenario, rather than universally available.

Simulating References
Everything on the Sui blockchain is an object. When you develop Move packages for the Sui network, you're typically manipulating or using on-chain objects in some way through functionality available in the Sui API. For most API functions, you provide an object by reference.

References are a key construct when programming in Move and on Sui. Most of the functionality available in the Sui API takes objects by reference.

There are two ways to use an object:

by value: When you use an object by value, you have full control over that object. You can destroy it (if the functionality is available), wrap it (if it has the store ability), or transfer it to an address.
by reference: When you use an object by reference, operations over that object are determined by the logic the module that defines the object provides because you are using a reference to its data rather than having ownership of the object itself. The restrictions of references allow you to develop smart contracts with a high level of security and safety around assets. There are two types of references:
Mutable reference (&mut): You can alter the object (according to the API) but you can't destroy or transfer it.
Immutable reference (&): Further restricts the set of operations and the guarantees/invariants over the referenced object. You have read-only access to the object's data.
Programmable transaction blocks (PTBs) do not currently allow the use of object references returned from one of its transaction commands. You can use input objects to the PTB, objects created by the PTB (like MakeMoveVec), or returned from a transaction command by value as references in subsequent transaction commands. If a transaction command returns a reference, however, you can't use that reference in any call, significantly limiting certain common patterns in Move.

The borrow module
The Sui framework includes a borrow module that offers a solution to the reference problem. The module provides access to an object by value but builds a model that makes it impossible to destroy, transfer, or wrap the object retrieved. The borrow module exposes a Referent object that wraps another object (the object you want to reference). The module uses the hot potato pattern (via a Borrow instance) to allow retrieval of the wrapped object by value. Within the same PTB, the module then forces the object to be returned to the Referent. The Borrow instance guarantees that the object returned is the same that was retrieved.

As an example, consider the following module stub that exposes an object (Asset) and a function (use_asset) to use that object.

module a_module {
    struct Asset has key, store {
        … // some data
    }

    public fun use_asset(asset: &Asset) {
        …. // some code
    }
}

The function use_asset takes an immutable reference to the asset (&Asset), which is a common pattern in a an API definition.

Now consider another module that uses this asset.

module another_module {
    struct AssetManager has key {
        asset: Asset,
    }

    public fun get_asset(manager: &AssetManager): &Asset {
        &manager.asset
    }
}

This module creates an object (AssetManager) that references the object (Asset) created in the previous module (a_module).

You could then write a Move function that retrieves an object by reference and passes it to the use_asset function.

fun do_something(manager: &AssetManager) {
    let asset = another_module::get_asset(manager);
    a_module::use_asset(asset);
}

The two functions in do_something are not valid within a PTB, however, because PTBs do not support a reference returned by a function and passed to another function.

To make this operation valid within a PTB, you would need to include functionality from the borrow module. Consequently, you could change the another_module code to the following:

module another_module {
    struct AssetManager has key {
        asset: Referent<Asset>,
    }

    public fun get_asset(manager: &mut AssetManager): (Asset, Borrow) {
        borrow::borrow(&mut manager.asset)
    }


    public fun return_asset(
        manager: &mut AssetManager,
        asset: Asset,
        b: Borrow) {
            borrow::put_back(&mut manager.asset, asset, b)
    }
}

Now the PTB can retrieve the asset, use it in a call to use_asset, and return the asset.

Considerations
The Borrow object is the key to the guarantees the borrow module offers. The definition of Borrow is struct Borrow { ref: address, obj: ID } which makes it such that you cannot drop or save its instance anywhere, so it must be consumed in the same transaction that retrieves it (hot potato). Moreover, fields in the Borrow struct make sure that the object returned is for the same Referent and the object that was originally held by the Referent instance. In other words, there is no way to either keep the object retrieved or to swap it with another object in a different Referent.

CAUTION
Using a Referent is a very explicit and intrusive change. That has to be taken into consideration when designing a solution.

Support for references in a PTB is planned, which is a much more natural and proper pattern for APIs.

You must consider the implications of using the borrow module and whether you have a mechanism to later move to a more natural, reference pattern.

Finally, the Referent model forces the usage of a mutable reference and returns an object by value. Both have significant implications when designing an API. You must be careful in what logic your modules provide and how objects are exposed.

Example
Extending the previous example, a PTB that calls use_asset is written as follows:

// initialize the PTB
const txb = new TransactionBlock();
// load the assetManager
const assetManager = txb.object(assetManagerId);
// retrieve the asset
const [asset, borrow] = txb.moveCall({
    target: "0xaddr1::another_module::get_asset",
    arguments: [ assetManager ],
});
// use the asset
txb.moveCall({
    target: "0xaddr2::a_module::use_asset",
    arguments: [ asset ],
});
// return the asset
txb.moveCall({
    target: "0xaddr1::another_module::return_asset",
    arguments: [ assetManager, asset, borrow ],
});
...

Cryptography
Effective use of cryptography keeps your smart contract transactions secure on the Sui blockchain.

Signature verification
Move contracts in Sui support verifications for several on-chain signature schemes. Not all signatures supported in on-chain verification are supported as user signature verification. See Signatures for valid signature schemes for transaction authorization.

Go to Sui On-Chain Signatures Verification in Move.

Groth16
A zero-knowledge proof is a method by which a party, known as the prover, can confirm the truthfulness of a claim without disclosing any information about the underlying data. For instance, it's possible for the prover to demonstrate they have solved a sudoku puzzle without showing the actual solution. Groth16 is one such proof you can use in your smart contracts.

Go to Groth16.

Hashing
A cryptographic hash function is a widely used cryptographic primitive that maps an arbitrary length input to a fixed length output, the hash value. The hash function is designed to be a one-way function, which means that it is infeasible to invert the function to find the input data from a given hash value, and to be collision resistant, which means that it is infeasible to find two different inputs that map to the same hash value. Use available hashing functions to provide security to your smart contracts.

Go to Hashing.

Elliptic Curve Verifiable Random Function (ECVRF)
Use ECVRFs to generate a random number and provide proof that the number used a secret key for generation. The public key corresponding to the secret key verifies the proof, so you can use it as a random number generator that generates outputs that anyone can verify. Applications that need verifiable randomness on chain can also benefit from its use.

Go to ECVRF.

Multisig
Sui allows you to mix and match key schemes in a single multisig account. For example, you can pick a single Ed25519 mnemonic-based key and two ECDSA secp256r1 keys to create a multisig account that always requires the Ed25519 key, but also one of the ECDSA secp256r1 keys to sign. You could use this structure for mobile secure enclave stored keys as two-factor authentication.

Go to Multisig.

Related links
Cryptography concepts: Before you use the guides, you might want to learn about the concepts behind the use of cryptography on Sui.

Sui On-Chain Signatures Verification in Move
Move contracts in Sui support verifications for several signature schemes on-chain. Not all signatures supported in on-chain verification are supported as user signature verification. See Sui Signatures for valid signature schemes for transaction authorization.

This topic covers:

How to use fastcrypto's CLI tool to create a signature of a given scheme. For testing and debugging only, DO NOT use in production.
Call the Move method on-chain to verification by submitting the signature, the message and the public key.
Signature schemes covered:

Ed25519 signature (64 bytes)
Secp256k1 non-recoverable signature (64 bytes)
Secp256k1 recoverable signature (65 bytes)
Secp256r1 non-recoverable signature (64 bytes)
Secp256r1 recoverable signature (65 bytes)
BLS G1 signature (minSig setting)
BLS G2 signature (minPk setting)
Usage
Set up fastcrypto CLI binary
git@github.com:MystenLabs/fastcrypto.git
cd fastcrypto/
cargo build --bin sigs-cli

Sign with CLI and submit to on-chain Move method
Ed25519 signature (64 bytes)
Generate a key and sign a message.
target/debug/sigs-cli keygen --scheme ed25519 --seed 0000000000000000000000000000000000000000000000000000000000000000                
Private key in hex: $SK
Public key in hex: $PK

target/debug/sigs-cli sign --scheme ed25519 --msg $MSG --secret-key  $SK

Signature in hex: $SIG
Public key in hex: $PK


Call the verify method in Move. All inputs are represented in bytes in hex format:
    use sui::ed25519;

    let msg = x"$MSG";
    let pk = x"$PK";
    let sig = x"$SIG";
    let verify = ed25519::ed25519_verify(&sig, &pk, &msg);
    assert!(verify == true, 0);

Secp256k1 non-recoverable signature (64 bytes)
Generate a key and sign a message.
target/debug/sigs-cli keygen --scheme secp256k1 --seed 0000000000000000000000000000000000000000000000000000000000000000                
Private key in hex: $SK
Public key in hex: $PK

target/debug/sigs-cli sign --scheme secp256k1 --msg $MSG --secret-key $SK

Signature in hex: $SIG
Public key in hex: $PK


Call the verify method in Move.
    use sui::ecdsa_k1;
    
    let msg = x"$MSG";
    let pk = x"$PK";
    let sig = x"$SIG";
    // The last param 1 represents the hash function used is SHA256, the default hash function used when signing in CLI.
    let verify = ecdsa_k1::secp256k1_verify(&sig, &pk, &msg, 1);
    assert!(verify == true, 0);


Secp256k1 recoverable signature (65 bytes)
Generate a key and sign a message.
target/debug/sigs-cli keygen --scheme secp256k1-rec --seed 0000000000000000000000000000000000000000000000000000000000000000                
Private key in hex: $SK
Public key in hex: $PK

target/debug/sigs-cli sign --scheme secp256k1-rec --msg $MSG --secret-key $SK

Signature in hex: $SIG
Public key in hex: $PK


Call the ecrecover method in Move and check equality.
    use sui::ecdsa_k1;

    let msg = x"$MSG";
    let pk = x"$PK";
    let sig = x"$SIG";
    // The last param 1 represents the hash function used is SHA256, the default hash function used when signing in CLI.
    let recovered = ecdsa_k1::secp256k1_ecrecover(&sig, &msg, 1);
    assert!(pk == recovered, 0);


Secp256r1 non-recoverable signature (64 bytes)
Generate a key and sign a message.
target/debug/sigs-cli keygen --scheme secp256r1 --seed 0000000000000000000000000000000000000000000000000000000000000000                
Private key in hex: $SK
Public key in hex: $PK

target/debug/sigs-cli sign --scheme secp256r1 --msg $MSG --secret-key $SK

Signature in hex: $SIG
Public key in hex: $PK


Call the verify method in Move.
    use sui::ecdsa_r1;

    let msg = x"$MSG";
    let pk = x"$PK";
    let sig = x"$SIG";
    // The last param 1 represents the hash function used is SHA256, the default hash function used when signing in CLI.
    let verify = ecdsa_r1::secp256r1_verify(&sig, &pk, &msg, 1);
    assert!(verify == true, 0);


Secp256r1 recoverable signature (65 bytes)
Generate a key and sign a message.
target/debug/sigs-cli keygen --scheme secp256r1-rec --seed 0000000000000000000000000000000000000000000000000000000000000000                
Private key in hex: $SK
Public key in hex: $PK

target/debug/sigs-cli sign --scheme secp256r1-rec --msg $MSG --secret-key $SK

Signature in hex: $SIG
Public key in hex: $PK


Call the ecrecover method in Move and check equality.
    use sui::ecdsa_r1;

    let msg = x"$MSG";
    let pk = x"$PK";
    let sig = x"$SIG";
    // The last param 1 represents the hash function used is SHA256, the default hash function used when signing in CLI.
    let recovered = ecdsa_r1::secp256r1_ecrecover(&sig, &msg, 1);
    assert!(pk == recovered, 0);


BLS G1 signature (48 bytes, minSig setting)
Generate a key and sign a message.
target/debug/sigs-cli keygen --scheme bls12381-minsig --seed 0000000000000000000000000000000000000000000000000000000000000000                
Private key in hex: $SK
Public key in hex: $PK

target/debug/sigs-cli sign --scheme bls12381-minsig --msg $MSG --secret-key $SK

Signature in hex: $SIG
Public key in hex: $PK


Call the verify method in Move.
    use sui::bls12381;

    let msg = x"$MSG";
    let pk = x"$PK";
    let sig = x"$SIG";
    let verified = bls12381::bls12381_min_sig_verify(&sig, &pk, &msg);
    assert!(verified == true, 0);

BLS G1 signature (96 bytes, minPk setting)
Generate a key and sign a message.
target/debug/sigs-cli keygen --scheme bls12381-minpk --seed 0000000000000000000000000000000000000000000000000000000000000000                
Private key in hex: $SK
Public key in hex: $PK

target/debug/sigs-cli sign --scheme bls12381-minpk --msg $MSG --secret-key $SK

Signature in hex: $SIG
Public key in hex: $PK


Call the verify method in Move.
    use sui::bls12381;

    let msg = x"$MSG";
    let pk = x"$PK";
    let sig = x"$SIG";
    let verified = bls12381::bls12381_min_pk_verify(&sig, &pk, &msg);
    assert!(verified == true, 0);


Groth16
A zero-knowledge proof allows a prover to validate that a statement is true without revealing any information about the inputs. For example, a prover can validate that they know the solution to a sudoku puzzle without revealing the solution.

Zero-knowledge succinct non-interactive argument of knowledge (zk-SNARKs) are a family of zero-knowledge proofs that are non-interactive, have succinct proof size and efficient verification time. An important and widely used variant of them is pairing-based zk-SNARKs like the Groth16 proof system, which is one of the most efficient and widely used.

The Move API in Sui enables you to verify any statement that can be expressed in a NP-complete language efficiently using Groth16 zk-SNARKs over either the BN254 or BLS12-381 elliptic curve constructions.

There are high-level languages for expressing these statements, such as Circom, used in the following example.

Groth16 requires a trusted setup for each circuit to generate the verification key. The API is not pinning any particular verification key and each user can generate their own parameters or use an existing verification to their apps.

Usage
The following example demonstrates how to create a Groth16 proof from a statement written in Circom and then verify it using the Sui Move API. The API currently supports up to eight public inputs.

Create circuit
The proof demonstrates that we know a secret input to a hash function which gives a certain public output.

pragma circom 2.1.5;

include "node_modules/circomlib/circuits/poseidon.circom";

template Main() {
    component poseidon = Poseidon(1);
    signal input in;
    signal output digest;
    poseidon.inputs[0] <== in;
    digest <== poseidon.out;
}

component main = Main();

We use the Poseidon hash function which is a ZK-friendly hash function. Assuming that the circom compiler has been installed, the above circuit is compiled using the following command:

circom main.circom --r1cs --wasm

This outputs the constraints in R1CS format and the circuit in Wasm format.

Generate proof
To generate a proof verifiable in Sui, you need to generate a witness. This example uses Arkworks' ark-circom Rust library. The code constructs a witness for the circuit and generates a proof for it for a given input. Finally, it verifies that the proof is correct.

use ark_bn254::Bn254;
use ark_circom::CircomBuilder;
use ark_circom::CircomConfig;
use ark_groth16::Groth16;
use ark_snark::SNARK;

fn main() {
    // Load the WASM and R1CS for witness and proof generation
    let cfg = CircomConfig::<Bn254>::new("main.wasm", "main.r1cs").unwrap();

    // Insert our secret inputs as key value pairs. We insert a single input, namely the input to the hash function.
    let mut builder = CircomBuilder::new(cfg);
    builder.push_input("in", 7);

    // Create an empty instance for setting it up
    let circom = builder.setup();

    // WARNING: The code below is just for debugging, and should instead use a verification key generated from a trusted setup.
    // See for example https://docs.circom.io/getting-started/proving-circuits/#powers-of-tau.
    let mut rng = rand::thread_rng();
    let params =
        Groth16::<Bn254>::generate_random_parameters_with_reduction(circom, &mut rng).unwrap();

    let circom = builder.build().unwrap();

    // There's only one public input, namely the hash digest.
    let inputs = circom.get_public_inputs().unwrap();

    // Generate the proof
    let proof = Groth16::<Bn254>::prove(&params, circom, &mut rng).unwrap();

    // Check that the proof is valid
    let pvk = Groth16::<Bn254>::process_vk(&params.vk).unwrap();
    let verified = Groth16::<Bn254>::verify_with_processed_vk(&pvk, &inputs, &proof).unwrap();
    assert!(verified);
}


The proof shows that an input (7) which, when hashed with the Poseidon hash function, gives a certain output (which in this case is inputs[0].to_string() = 7061949393491957813657776856458368574501817871421526214197139795307327923534).

Verification in Sui
The API in Sui for verifying a proof expects a special processed verification key, where only a subset of the values are used. Ideally, computation for this prepared verification key happens only once per circuit. You can perform this processing using the sui::groth16::prepare_verifying_key method of the Sui Move API with a serialization of the params.vk value used previously.

The output of the prepare_verifying_key function is a vector with four byte arrays, which corresponds to the vk_gamma_abc_g1_bytes, alpha_g1_beta_g2_bytes, gamma_g2_neg_pc_bytes, delta_g2_neg_pc_bytes.

To verify a proof, you also need two more inputs, public_inputs_bytes and proof_points_bytes, which contain the public inputs and the proof respectively. These are serializations of the inputs and proof values from the previous example, which you can compute in Rust as follows:

let mut vk_bytes = Vec::new();
params.vk.serialize_compressed(&mut vk_bytes).unwrap();

let mut public_inputs_bytes = Vec::new();
for i in 0..inputs.len() { // if there is more than one public input, serialize one by one
    inputs[i].serialize_compressed(&mut inputs_bytes).unwrap();
}

let mut proof_points_bytes = Vec::new();
proof.serialize_compressed(&mut proof_points_bytes).unwrap();


The following example smart contract prepares a verification key and verifies the corresponding proof. This example uses the BN254 elliptic curve construction, which is given as the first parameter to the prepare_verifying_key and verify_groth16_proof functions. You can use the bls12381 function instead for BLS12-381 construction.

module test::groth16_test {
    use sui::groth16;
    use sui::event;

    /// Event on whether the proof is verified
    struct VerifiedEvent has copy, drop {
        is_verified: bool,
    }

    public fun verify_proof(vk_bytes: vector<u8>, public_inputs_bytes: vector<u8>, proof_points_bytes: vector<u8>) {
        let pvk = groth16::prepare_verifying_key(&groth16::bn254(), &vk_bytes);
        let public_inputs = groth16::public_proof_inputs_from_bytes(public_inputs_bytes);
        let proof_points = groth16::proof_points_from_bytes(proof_points_bytes);
        event::emit(VerifiedEvent {is_verified: groth16::verify_groth16_proof(&groth16::bn254(), &pvk, &public_inputs, &proof_points)});
    }
}


Hashing
A cryptographic hash function is a widely used cryptographic primitive that maps an arbitrary length input to a fixed length output, the hash value. The hash function is designed to be a one-way function, which means that it is infeasible to invert the function to find the input data from a given hash value, and to be collision resistant, which means that it is infeasible to find two different inputs that map to the same hash value.

The Sui Move API supports the following cryptographic hash functions:

SHA2-256 as std::hash::sha2_256
SHA3-256 as std::hash::sha3_256
Keccak256 as sui::hash::keccak256
Blake2b-256 as sui::hash::blake2b256
Usage
The SHA2-256 and SHA3-256 hash functions are available in the Move Standard Library in the std::hash module. The following example shows how to use the SHA2-256 hash function in a smart contract:

module test::hashing_std {
    use std::hash;
    use sui::object::{Self, UID};
    use sui::tx_context::TxContext;
    use sui::transfer;
    use std::vector;

    /// Object that holds the output hash value.
    struct Output has key, store {
        id: UID,
        value: vector<u8>
    }

    public fun hash_data(data: vector<u8>, recipient: address, ctx: &mut TxContext) {
        let hashed = Output {
            id: object::new(ctx),
            value: hash::sha2_256(data),
        };
        // Transfer an output data object holding the hashed data to the recipient.
        transfer::public_transfer(hashed, recipient)
    }
}

The Keccak256 and Blake2b-256 hash functions are available through the sui::hash module in the Sui Move Library. An example of how to use the Keccak256 hash function in a smart contract is shown below. Notice that here, the input to the hash function is given as a reference. This is the case for both Keccak256 and Blake2b-256.

module test::hashing_sui {
    use sui::hash;
    use sui::object::{Self, UID};
    use sui::tx_context::TxContext;
    use sui::transfer;
    use std::vector;

    /// Object that holds the output hash value.
    struct Output has key, store {
        id: UID,
        value: vector<u8>
    }

    public fun hash_data(data: vector<u8>, recipient: address, ctx: &mut TxContext) {
        let hashed = Output {
            id: object::new(ctx),
            value: hash::keccak256(&data),
        };
        // Transfer an output data object holding the hashed data to the recipient.
        transfer::public_transfer(hashed, recipient)
    }
}


Elliptic Curve Verifiable Random Function
A verifiable random function (VRF) is a cryptographic primitive that enables you to generate a random number and provide proof that the number used a secret key for generation. Anyone can verify the proof using the public key corresponding to the secret key, so you can use it as a random number generator (RNG) that generates outputs that anyone can verify. Applications that need verifiable randomness on chain can also benefit from its use.

VRF construction
The VRF used in the Move API in Sui is an elliptic curve VRF (ECVRF) following the CFRG VRF draft specifications version 15. It uses Ristretto255 elliptic curve group construction with the SHA-512 hash function. The nonce is generated according to RFC6979.

Any implementation following the same specifications with suite string sui_vrf (see section 5 in the VRF specs) can be used to compute VRF output and generate proofs.

The fastcrypto library provides a CLI tool for such an implementation and is used in the following example.

Generate keys
From the root of the fastcrypto repository, run the following command to generate a key pair:

cargo run --bin ecvrf-cli keygen

This outputs a secret key and a public key in hex format. Both the secret and public keys are 32-byte strings:

Secret key: c0cbc5bf0b2f992fe14fee0327463c7b03d14cbbcb38ce2584d95ee0c112b40b
Public key: 928744da5ffa614d65dd1d5659a8e9dd558e68f8565946ef3d54215d90cba015

Compute VRF output and proof
To compute the VRF output and proof for the input string Hello, world!, which is 48656c6c6f2c20776f726c6421 in hexadecimal, with the key pair generated previously, run the following command:

cargo run --bin ecvrf-cli prove --input 48656c6c6f2c20776f726c6421 --secret-key c0cbc5bf0b2f992fe14fee0327463c7b03d14cbbcb38ce2584d95ee0c112b40b


This should the 80-byte proof and VRF 64-byte output, both in hex format:

Proof:  18ccf8bf316f00b387fc6e7b26f2d3ddadbf5e9c66d3a30986f12b208108551f9c6da87793a857d79261338a50430074b1dbc7f8f05e492149c51313381248b4229ebdda367146dbbbf95809c7fb330d
Output: 2b7e45821d80567761e8bb3fc519efe5ad80cdb4423227289f960319bbcf6eea1aef30c023617d73f589f98272b87563c6669f82b51dafbeb5b9cf3b17c73437


Verify proof
You can verify the proof and output in a smart contract using sui::ecvrf::ecvrf_verify from the Sui Move framework:

module math::ecvrf_test {
    use sui::ecvrf;
    use sui::event;

    /// Event on whether the output is verified
    struct VerifiedEvent has copy, drop {
        is_verified: bool,
    }

    public fun verify_ecvrf_output(output: vector<u8>, alpha_string: vector<u8>, public_key: vector<u8>, proof: vector<u8>) {
        event::emit(VerifiedEvent {is_verified: ecvrf::ecvrf_verify(&output, &alpha_string, &public_key, &proof)});
    }
}


You can also use the CLI tool for verification:

cargo run --bin ecvrf-cli verify --output 2b7e45821d80567761e8bb3fc519efe5ad80cdb4423227289f960319bbcf6eea1aef30c023617d73f589f98272b87563c6669f82b51dafbeb5b9cf3b17c73437 --proof 18ccf8bf316f00b387fc6e7b26f2d3ddadbf5e9c66d3a30986f12b208108551f9c6da87793a857d79261338a50430074b1dbc7f8f05e492149c51313381248b4229ebdda367146dbbbf95809c7fb330d --input 48656c6c6f2c20776f726c6421 --public-key 928744da5ffa614d65dd1d5659a8e9dd558e68f8565946ef3d54215d90cba015


The preceding command returns the verification:

Proof verified correctly!


Multisig Authentication
The following steps demonstrate how to create a multisig transaction and then submit it against a local network using the Sui CLI. A transaction can be the transfer of an object, the publish or upgrade of a package, the payment of SUI, and so on. To learn how to set up a local network, see Connect to a Local Network.

To learn more about how to create multisig addresses and create multisig transactions using the TypeScript SDK, see the SDK documentation for details.

Step 1: Create keys
Use the following command to generate a Sui address and key for each supported key scheme and add it to the sui.keystore, then list the keys.

Use sui client to create Sui addresses of different key schemes.

sui client new-address ed25519
sui client new-address secp256k1
sui client new-address secp256r1

Step 2: Add keys to Sui keystore
Use sui keytool to list the signatures you created in the previous step.

sui keytool list

The response resembles the following, but displays actual addresses, keys, and peer IDs:

╭────────────────────────────────────────────────────────────────────────────────────────────╮
│ ╭─────────────────┬──────────────────────────────────────────────────────────────────────╮ │
│ │ suiAddress      │  <SUI-ADDRESS>                                                       │ │
│ │ publicBase64Key │  <PUBLIC-KEY>                                                        │ │
│ │ keyScheme       │  ed25519                                                             │ │
│ │ flag            │  0                                                                   │ │
│ │ peerId          │  <PEER-ID>                                                           │ │
│ ╰─────────────────┴──────────────────────────────────────────────────────────────────────╯ │
│ ╭─────────────────┬──────────────────────────────────────────────────────────────────────╮ │
│ │ suiAddress      │  <SUI-ADDRESS>                                                       │ │
│ │ publicBase64Key │  <PUBLIC-KEY>                                                        │ │
│ │ keyScheme       │  secp256k1                                                           │ │
│ │ flag            │  0                                                                   │ │
│ │ peerId          │  <PEER-ID>                                                           │ │
│ ╰─────────────────┴──────────────────────────────────────────────────────────────────────╯ │
│ ╭─────────────────┬──────────────────────────────────────────────────────────────────────╮ │
│ │ suiAddress      │  <SUI-ADDRESS>                                                       │ │
│ │ publicBase64Key │  <PUBLIC-KEY>                                                        │ │
│ │ keyScheme       │  secp256r1                                                           │ │
│ │ flag            │  0                                                                   │ │
│ │ peerId          │  <PEER-ID>                                                           │ │
│ ╰─────────────────┴──────────────────────────────────────────────────────────────────────╯ │
╰────────────────────────────────────────────────────────────────────────────────────────────╯


Step 3: Create a multisig address
To create a multisig address, input a list of public keys to use for the multisig address and a list of their corresponding weights and the threshold (replacing <VARIABLES> with actual values).

sui keytool multi-sig-address --pks <PUBLIC-KEY-ED25519> <PUBLIC-KEY-SECPK1> <PUBLIC-KEY-SECP256R1> --weights 1 2 3 --threshold 3


The response resembles the following:

╭─────────────────┬────────────────────────────────────────────────────────────────────────────────────╮
│ multisigAddress │  <MULTISIG-ADDRESS>                                                                │
│ multisig        │ ╭────────────────────────────────────────────────────────────────────────────────╮ │
│                 │ │ ╭─────────────────┬──────────────────────────────────────────────────────────╮ │ │
│                 │ │ │ address         │  <SUI-ADDRESS>                                           │ │ │
│                 │ │ │ publicBase64Key │  <PUBLIC-KEY>                                            │ │ │
│                 │ │ │ weight          │  1                                                       │ │ │
│                 │ │ ╰─────────────────┴──────────────────────────────────────────────────────────╯ │ │
│                 │ │ ╭─────────────────┬──────────────────────────────────────────────────────────╮ │ │
│                 │ │ │ address         │  <SUI-ADDRESS>                                           │ │ │
│                 │ │ │ publicBase64Key │  <PUBLIC-KEY>                                            │ │ │
│                 │ │ │ weight          │  2                                                       │ │ │
│                 │ │ ╰─────────────────┴──────────────────────────────────────────────────────────╯ │ │
│                 │ │ ╭─────────────────┬──────────────────────────────────────────────────────────╮ │ │
│                 │ │ │ address         │  <SUI-ADDRESS>                                           │ │ │
│                 │ │ │ publicBase64Key │  <PUBLIC-KEY>                                            │ │ │
│                 │ │ │ weight          │  3                                                       │ │ │
│                 │ │ ╰─────────────────┴──────────────────────────────────────────────────────────╯ │ │
│                 │ ╰────────────────────────────────────────────────────────────────────────────────╯ │
╰─────────────────┴────────────────────────────────────────────────────────────────────────────────────╯


Step 4: Send objects to a multisig address
This example requests gas from a local network using the default URL following the guidance in Connect to a Local Network. If following along, be sure to replace <MULTISIG-ADDR> with the address you receive in the previous step.

curl --location --request POST 'http://127.0.0.1:9123/gas' --header 'Content-Type: application/json' --data-raw "{ \"FixedAmountRequest\": { \"recipient\": \"<MULTISIG-ADDR>\" } }"


The response resembles the following:

{"transferred_gas_objects":[{"amount":200000,"id":"<OBJECT-ID>", ...}]}

Step 5: Serialize any transaction
This section demonstrates how to use an object that belongs to a multisig address and serialize a transfer to be signed. The tx_bytes value can be any serialized transaction data where the sender is the multisig address. Use the --serialize-unsigned-transaction flag for supported commands in sui client -h (publish, upgrade, call, transfer, transfer-sui, pay, pay-all-sui, pay-sui, split, merge-coin) to output the Base64 encoded transaction bytes.

TIP
Beginning with the Sui v1.24.1 release, the --gas-budget flag is no longer required for CLI commands.

sui client transfer --to <SUI-ADDRESS> --object-id <OBJECT-ID> --gas-budget <GAS-AMOUNT> --serialize-unsigned-transaction

Raw tx_bytes to execute: <TX_BYTES>


Step 6: Sign the transaction with two keys
Use the following code sample to sign the transaction with two keys in sui.keystore. You can do this with other tools as long as you serialize it to flag || sig || pk.

sui keytool sign --address <SUI-ADDRESS> --data <TX_BYTES>

Raw tx_bytes to execute: <TX_BYTES>
Serialized signature (`flag || sig || pk` in Base64): $SIG_1

sui keytool sign --address <SUI-ADDRESS> --data <TX_BYTES>

Raw tx_bytes to execute: <TX_BYTES>
Serialized signature (`flag || sig || pk` in Base64): $SIG_2

Step 7: Combine individual signatures into a multisig
This sample demonstrates how to combine the two signatures:

sui keytool multi-sig-combine-partial-sig --pks <PUBLIC-KEY-1> <PUBLIC-KEY-2> <PUBLIC-KEY-3> --weights 1 2 3 --threshold 3 --sigs <SIGNATURE-1> <SIGNATURE-2>

multisig address: <MULTISIG-ADDRESS> # Informational
multisig parsed: <HUMAN-READABLE-STRUCT> # Informational
multisig serialized: <SERIALIZED-MULTISIG>


You need only the signatures of the participating signers whose sum of weights >=k. You must provide all public keys and their weights, and the threshold that defined the multisig address.

Step 8: Execute a transaction with multisig
Use sui client to execute a transaction using multisig:

sui client execute-signed-tx --tx-bytes <TX_BYTES> --signatures <SERIALIZED-MULTISIG>

Related links
Multisig: Definition of multisig transactions on the Sui network and how to use it with CLI.
Multisig Typescript SDK: How to create multisig addresses and sign transactions using the Sui SDK.


zkLogin Integration Guide
Here is the high-level flow the wallet or frontend application must implement to support zkLogin-enabled transactions:

The wallet creates an ephemeral key pair.
The wallet prompts the user to complete an OAuth login flow with the nonce corresponding to the ephemeral public key.
After receiving the JSON Web Token (JWT), the wallet obtains a zero-knowledge proof.
The wallet obtains a unique user salt based on a JWT. Use the OAuth subject identifier and salt to compute the zkLogin Sui address.
The wallet signs transactions with the ephemeral private key.
The wallet submits the transaction with the ephemeral signature and the zero-knowledge proof.
Let's dive into the specific implementation details.

Install the zkLogin TypeScript SDK
To use the zkLogin TypeScript SDK in your project, run the following command in your project root:

npm
Yarn
pnpm
npm install @mysten/zklogin

If you want to use the latest experimental version:

npm
Yarn
pnpm
npm install @mysten/zklogin@experimental

Get JWT
Generate an ephemeral key pair. Follow the same process as you would generating a key pair in a traditional wallet. See Sui SDK for details.

Set the expiration time for the ephemeral key pair. The wallet decides whether the maximum epoch is the current epoch or later. The wallet also determines whether this is adjustable by the user.

Assemble the OAuth URL with configured client ID, redirect URL, ephemeral public key and nonce: This is what the application sends the user to complete the login flow with a computed nonce.

import { generateNonce, generateRandomness } from '@mysten/zklogin';

const FULLNODE_URL = 'https://fullnode.devnet.sui.io'; // replace with the RPC URL you want to use
const suiClient = new SuiClient({ url: FULLNODE_URL });
const { epoch, epochDurationMs, epochStartTimestampMs } = await suiClient.getLatestSuiSystemState();

const maxEpoch = Number(epoch) + 2; // this means the ephemeral key will be active for 2 epochs from now.
const ephemeralKeyPair = new Ed25519Keypair();
const randomness = generateRandomness();
const nonce = generateNonce(ephemeralKeyPair.getPublicKey(), maxEpoch, randomness);


The auth flow URL can be constructed with $CLIENT_ID, $REDIRECT_URL and $NONCE.

For some providers ("Yes" for "Auth Flow Only"), the JWT can be found immediately in the redirect URL after the auth flow.

For other providers ("No" for "Auth Flow Only"), the auth flow only returns a code ($AUTH_CODE) in redirect URL. To retrieve the JWT, an additional POST call is required with "Token Exchange URL".

Provider	Auth Flow URL	Token Exchange URL	Auth Flow Only
Google	https://accounts.google.com/o/oauth2/v2/auth?client_id=$CLIENT_ID&response_type=id_token&redirect_uri=$REDIRECT_URL&scope=openid&nonce=$NONCE	N/A	Yes
Facebook	https://www.facebook.com/v17.0/dialog/oauth?client_id=$CLIENT_ID&redirect_uri=$REDIRECT_URL&scope=openid&nonce=$NONCE&response_type=id_token	N/A	Yes
Twitch	https://id.twitch.tv/oauth2/authorize?client_id=$CLIENT_ID&force_verify=true&lang=en&login_type=login&redirect_uri=$REDIRECT_URL& response_type=id_token&scope=openid&nonce=$NONCE	N/A	Yes
Kakao	https://kauth.kakao.com/oauth/authorize?response_type=code&client_id=$CLIENT_ID&redirect_uri=$REDIRECT_URL&nonce=$NONCE	https://kauth.kakao.com/oauth/token?grant_type=authorization_code&client_id=$CLIENT_ID&redirect_uri=$REDIRECT_URL&code=$AUTH_CODE	No
Apple	https://appleid.apple.com/auth/authorize?client_id=$CLIENT_ID&redirect_uri=$REDIRECT_URL&scope=email&response_mode=form_post&response_type=code%20id_token&nonce=$NONCE	N/A	Yes
Slack	https://slack.com/openid/connect/authorize?response_type=code&client_id=$CLIENT_ID&redirect_uri=$REDIRECT_URL&nonce=$NONCE&scope=openid	https://slack.com/api/openid.connect.token?code=$AUTH_CODE&client_id=$CLIENT_ID&client_secret=$CLIENT_SECRET	No
Decoding JWT
Upon successful redirection, the OpenID provider attaches the JWT as a URL parameter. The following is an example using the Google flow.

http://host/auth?id_token=tokenPartA.tokenPartB.tokenPartC&authuser=0&prompt=none

The id_token param is the JWT in encoded format. You can validate the correctness of the encoded token and investigate its structure by pasting it in the jwt.io website.

To decode the JWT you can use a library like: jwt_decode: and map the response to the provided type JwtPayload:

const decodedJwt = jwt_decode(encodedJWT) as JwtPayload;

export interface JwtPayload {
	iss?: string;
	sub?: string; //Subject ID
	aud?: string[] | string;
	exp?: number;
	nbf?: number;
	iat?: number;
	jti?: string;
}

User salt management
zkLogin uses the user salt to compute the zkLogin Sui address (see definition). The salt must be a 16-byte value or a integer smaller than 2n**128n. There are several options for the application to maintain the user salt:

Client side:
Option 1: Request user input for the salt during wallet access, transferring the responsibility to the user, who must then remember it.
Option 2: Browser or Mobile Storage: Ensure proper workflows to prevent users from losing wallet access during device or browser changes. One approach is to email the salt during new wallet setup.
Backend service that exposes an endpoint that returns a unique salt for each user consistently.
Option 3: Store a mapping from user identifier (e.g. sub) to user salt in a conventional database (e.g. user or password table). The salt is unique per user.
Option 4: Implement a service that keeps a master seed value, and derive a user salt with key derivation by validating and parsing the JWT. For example, use HKDF(ikm = seed, salt = iss || aud, info = sub) defined here. Note that this option does not allow any rotation on master seed or change in client ID (i.e. aud), otherwise a different user address will be derived and will result in loss of funds.
Here's an example request and response for the Mysten Labs-maintained salt server (using option 4). If you want to use the Mysten Labs salt server, please contact us for whitelisting your registered client ID. Only valid JWT authenticated with whitelisted client IDs are accepted.

curl -X POST https://salt.api.mystenlabs.com/get_salt -H 'Content-Type: application/json' -d '{"token": "$JWT_TOKEN"}'

Response: {"salt":"129390038577185583942388216820280642146"}


User salt is used to disconnect the OAuth identifier (sub) from the on-chain Sui address to avoid linking Web2 credentials with Web3 credentials. While losing or misusing the salt could enable this link, it wouldn't compromise fund control or zkLogin asset authority. See more discussion here.

Get the user's Sui address
Once the OAuth flow completes, the JWT can be found in the redirect URL. Along with the user salt, the zkLogin address can be derived as follows:

import { jwtToAddress } from '@mysten/zklogin';

const zkLoginUserAddress = jwtToAddress(jwt, userSalt);

Get the zero-knowledge proof
The next step is to fetch the ZK proof. This is an attestation (proof) over the ephemeral key pair that proves the ephemeral key pair is valid.

First, generate the extended ephemeral public key to use as an input to the ZKP.

import { getExtendedEphemeralPublicKey } from '@mysten/zklogin';

const extendedEphemeralPublicKey = getExtendedEphemeralPublicKey(ephemeralKeyPair.getPublicKey());


You need to fetch a new ZK proof if the previous ephemeral key pair is expired or is otherwise inaccessible.

Because generating a ZK proof can be resource-intensive and potentially slow on the client side, it's advised that wallets utilize a backend service endpoint dedicated to ZK proof generation.

There are two options:

Call the Mysten Labs-maintained proving service.
Run the proving service in your backend using the provided Docker images.
Call the Mysten Labs-maintained proving service
If you want to use the Mysten hosted ZK Proving Service for Mainnet, please refer to Enoki docs and contact us for accessing it.

Use the prover-dev endpoint (https://prover-dev.mystenlabs.com/v1) freely for testing on Devnet. Note that you can submit proofs generated with this endpoint for Devnet zkLogin transactions only; submitting them to Testnet or Mainnet fails.

You can use BigInt or Base64 encoding for extendedEphemeralPublicKey, jwtRandomness, and salt. The following examples show two sample requests with the first using BigInt encoding and the second using Base64.

curl -X POST $PROVER_URL -H 'Content-Type: application/json' \
-d '{"jwt":"$JWT_TOKEN", \
"extendedEphemeralPublicKey":"84029355920633174015103288781128426107680789454168570548782290541079926444544", \
"maxEpoch":"10", \
"jwtRandomness":"100681567828351849884072155819400689117", \
"salt":"248191903847969014646285995941615069143", \
"keyClaimName":"sub" \
}'

curl -X POST $PROVER_URL -H 'Content-Type: application/json' \
-d '{"jwt":"$JWT_TOKEN", \
"extendedEphemeralPublicKey":"ucbuFjDvPnERRKZI2wa7sihPcnTPvuU//O5QPMGkkgA=", \
"maxEpoch":"10", \
"jwtRandomness":"S76Qi8c/SZlmmotnFMr13Q==", \
"salt":"urgFnwIxJ++Ooswtf0Nn1w==", \
"keyClaimName":"sub" \
}'


Response:

{
	"proofPoints": {
		"a": [
			"17267520948013237176538401967633949796808964318007586959472021003187557716854",
			"14650660244262428784196747165683760208919070184766586754097510948934669736103",
			"1"
		],
		"b": [
			[
				"21139310988334827550539224708307701217878230950292201561482099688321320348443",
				"10547097602625638823059992458926868829066244356588080322181801706465994418281"
			],
			[
				"12744153306027049365027606189549081708414309055722206371798414155740784907883",
				"17883388059920040098415197241200663975335711492591606641576557652282627716838"
			],
			["1", "0"]
		],

		"c": [
			"14769767061575837119226231519343805418804298487906870764117230269550212315249",
			"19108054814174425469923382354535700312637807408963428646825944966509611405530",
			"1"
		]
	},
	"issBase64Details": {
		"value": "wiaXNzIjoiaHR0cHM6Ly9pZC50d2l0Y2gudHYvb2F1dGgyIiw",
		"indexMod4": 2
	},
	"headerBase64": "eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IjEifQ"
}


How to handle CORS error
To avoid possible CORS errors in Frontend apps, it is suggested to delegate this call to a backend service.

The response can be mapped to the inputs parameter type of getZkLoginSignature of zkLogin SDK.

const proofResponse = await post('/your-internal-api/zkp/get', zkpRequestPayload);

export type PartialZkLoginSignature = Omit<
	Parameters<typeof getZkLoginSignature>['0']['inputs'],
	'addressSeed'
>;
const partialZkLoginSignature = proofResponse as PartialZkLoginSignature;

Run the proving service in your backend
Download the Groth16 proving key zkey file that will be later used as an argument to run the prover. There are zkeys available for Mainnet and Testnet, as well as a test zkey for Devnet. See the Ceremony section for more details on how the main proving key is generated. Please install git lfs which is needed before downloading the zkey.

Main zkey (for Mainnet and Testnet)

wget -O - https://raw.githubusercontent.com/sui-foundation/zklogin-ceremony-contributions/main/download-main-zkey.sh | bash


Test zkey (for Devnet)

wget -O - https://raw.githubusercontent.com/sui-foundation/zklogin-ceremony-contributions/main/download-test-zkey.sh | bash


To verify the download contains the correct zkey file, you can run the following command to check the Blake2b hash: b2sum ${file_name}.zkey.

Network	zkey file name	Hash
Mainnet, Testnet	zkLogin-main.zkey	060beb961802568ac9ac7f14de0fbcd55e373e8f5ec7cc32189e26fb65700aa4e36f5604f868022c765e634d14ea1cd58bd4d79cef8f3cf9693510696bcbcbce
Devnet	zkLogin-test.zkey	686e2f5fd969897b1c034d7654799ee2c3952489814e4eaaf3d7e1bb539841047ae8ee5fdcdaca5f4ddd76abb5a8e8eb77b44b693a2ba9d4be57e94292b26ce2
For the next step, you need two Docker images from the mysten/zklogin repository (tagged as prover and prover-fe). To simplify, a docker compose file is available that automates this process. Run docker compose with the downloaded zkey from the same directory as the YAML file.

services:
  backend:
    image: mysten/zklogin:prover-stable
    volumes:
      # The ZKEY environment variable must be set to the path of the zkey file.
      - ${ZKEY}:/app/binaries/zkLogin.zkey
    environment:
      - ZKEY=/app/binaries/zkLogin.zkey
      - WITNESS_BINARIES=/app/binaries

  frontend:
    image: mysten/zklogin:prover-fe-stable
    command: '8080'
    ports:
      # The PROVER_PORT environment variable must be set to the desired port.
      - '${PROVER_PORT}:8080'
    environment:
      - PROVER_URI=http://backend:8080/input
      - NODE_ENV=production
      - DEBUG=zkLogin:info,jwks
      # The default timeout is 15 seconds. Uncomment the following line to change it.
      # - PROVER_TIMEOUT=30

ZKEY=<path_to_zkLogin.zkey> PROVER_PORT=<PROVER_PORT> docker compose up

To call the service, the following two endpoints are supported:
/ping: To test if the service is up. Running curl http://localhost:PROVER_PORT/ping should return pong.
/v1: The request and response are the same as the Mysten Labs maintained service.
A few important things to note:

The backend service (mysten/zklogin:prover-stable) is compute-heavy. Use at least the minimum recommended 16 cores and 16GB RAM. Using weaker instances can lead to timeout errors with the message "Call to rapidsnark service took longer than 15s". You can adjust the environment variable PROVER_TIMEOUT to set a different timeout value, for example, PROVER_TIMEOUT=30 for a timeout of 30 seconds.

If you want to compile the prover from scratch (for performance reasons), please see our fork of rapidsnark. You'd need to compile and launch the prover in server mode.

Setting DEBUG=* turns on all logs in the prover-fe service some of which may contain PII. Consider using DEBUG=zkLogin:info,jwks in production environments.

Assemble the zkLogin signature and submit the transaction
First, sign the transaction bytes with the ephemeral private key using the key pair generated previously. This is the same as traditional KeyPair signing. Make sure that the transaction sender is also defined.

const ephemeralKeyPair = new Ed25519Keypair();

const client = new SuiClient({ url: '<YOUR_RPC_URL>' });

const txb = new Transaction();

txb.setSender(zkLoginUserAddress);

const { bytes, signature: userSignature } = await txb.sign({
	client,
	signer: ephemeralKeyPair, // This must be the same ephemeral key pair used in the ZKP request
});


Next, generate an address seed by combining userSalt, sub (subject ID), and aud (audience).

Set the address seed and the partial zkLogin signature to be the inputs parameter.

You can now serialize the zkLogin signature by combining the ZK proof (inputs), the maxEpoch, and the ephemeral signature (userSignature).

import { genAddressSeed, getZkLoginSignature } from '@mysten/zklogin';

const addressSeed: string = genAddressSeed(
	BigInt(userSalt!),
	'sub',
	decodedJwt.sub,
	decodedJwt.aud,
).toString();

const zkLoginSignature: SerializedSignature = getZkLoginSignature({
	inputs: {
		...partialZkLoginSignature,
		addressSeed,
	},
	maxEpoch,
	userSignature,
});

Finally, execute the transaction.

client.executeTransaction({
	transaction: bytes,
	signature: zkLoginSignature,
});

Caching the ephemeral private key and ZK proof
As previously documented, each ZK proof is tied to an ephemeral key pair. So you can reuse the proof to sign any number of transactions until the ephemeral key pair expires (until the current epoch crosses maxEpoch).

You might want to cache the ephemeral key pair along with the ZKP for future uses.

However, the ephemeral key pair needs to be treated as a secret akin to a key pair in a traditional wallet. This is because if both the ephemeral private key and ZK proof are revealed to an attacker, then they can typically sign any transaction on behalf of the user (using the same process described previously).

Consequently, you should not store them persistently in an unsecure storage location, on any platform. For example, on browsers, use session storage instead of local storage to store the ephemeral key pair and the ZK proof. This is because session storage automatically clears its data when the browser session ends, while data in local storage persists indefinitely.

Related links
zkLogin Concepts
zkLogin Example
Configure OpenID Providers



Configure OpenID Providers
To integrate zkLogin with your app, you need an OAuth client from at least one of the available providers. You use the Client ID and redirect URI from those providers in your zkLogin project. For example, the following TypeScript code constructs a Google login URL for testing.

const REDIRECT_URI = '<YOUR_SITE_URL>';

const params = new URLSearchParams({
	// Configure client ID and redirect URI with an OpenID provider
	client_id: $CLIENT_ID,
	redirect_uri: $REDIRECT_URI,
	response_type: 'id_token',
	scope: 'openid',
	// See below for details about generation of the nonce
	nonce: nonce,
});

const loginURL = `https://accounts.google.com/o/oauth2/v2/auth?${params}`;

OpenID providers
The following table lists the OpenID providers that can support zkLogin or are currently being reviewed to determine whether they can support zkLogin.

Provider	Can support?	Devnet	Testnet	Mainnet
Facebook	Yes	Yes	Yes	Yes
Google	Yes	Yes	Yes	Yes
Twitch	Yes	Yes	Yes	Yes
Slack	Yes	Yes	No	No
Kakao	Yes	Yes	No	No
Apple	Yes	Yes	Yes	Yes
RedBull	Under review	No	No	No
Microsoft	Under review	No	No	No
AWS (Tenant)	Under review	No	No	No
Amazon	Under review	No	No	No
WeChat	Under review	No	No	No
Auth0	Under review	No	No	No
Okta	Under review	No	No	No
Configuring an OpenID provider
Select a tab for instruction on configuring the client ID ($CLIENT_ID in the previous example) and redirect URI ($REDIRECT_URI in the previous example) with the relevant provider.

Google
Facebook
Twitch
Kakao
Slack
Apple
Navigate a browser to the Google Cloud dashboard. Either sign in or register for a Google Cloud account.

Open APIs & Services > Credentials using the Google Cloud dashboard navigation.

1

On the Credentials page, select CREATE CREDENTIALS > OAuth client ID.

2

Set the Application type and Name of your application.

3

In the Authorized redirect URIs section, click the ADD URI button. Set the value for your redirect URI in the field. This should be the wallet or application frontend.

4

Click Create. If successful, Google Cloud displays the OAuth client created dialog with metadata, including your Client ID. Click OK to dismiss the dialog.

Your new OAuth client should now appear in the OAuth 2.0 Client IDs section of the Credentials page. Click the Client ID that appears next to the client to copy the value to your clipboard. Click the client name to access the redirect URI and other client data.

Related links
zkLogin Integration Guide
zkLogin Example

zkLogin Example
The Sui community created an example to facilitate a comprehensive understanding of each step involved in Sui zkLogin for developers.

Sui zkLogin Example
ZKLogin Overview This example breaks down the complete process of Sui zkLogin into seven steps, as follows:

Generate ephemeral key pair
Fetch JWT
Decode JWT
Generate salt
Generate user Sui address
Fetch ZK proof
Assemble zkLogin signature
Each step includes corresponding code snippets, providing instructions on how to obtain the required data for each step.

Operating environment
The example runs in Sui Devnet. All data the user generates is stored locally on the client-side (browser). The acquisition of the zero-knowledge proof (ZK proof) is done through a call to the Mysten Labs-maintained proving service. Therefore, running the example does not require an additional deployed backend server (or a Docker container).

Storage locations for key data
The following table lists the storage location for key data the example uses:

Data	Storage location
Ephemeral key pair	window.sessionStorage
Randomness	window.sessionStorage
User salt	window.localStorage
Max epoch	window.localStorage
The user salt is stored long-term in the browser's localStorage. Consequently, provided the localStorage is not cleared manually, you can use the same JWT (in this example, logging in with the same Google account) to access the corresponding zkLogin address generated from the current salt value at any time.

CAUTION
Changing browsers or devices results in the inability to access previously generated Sui zkLogin addresses, even when using the same JWT.

Troubleshooting
ZK Proof request failure:

This might occur because of inconsistencies in the creation of multiple randomness or user salts, causing request failures. Click the Reset Button in the top right corner of the UI to restart the entire process.
Request test tokens failure:

This is because you have surpassed the faucet server request frequency limitations.
You can go to Sui #devnet-faucet or #testnet-faucet Discord channels to claim test coins.
Any suggestions are welcome on the project's GitHub repo through raised issues, and of course, pull requests are highly appreciated.

Related links
zkLogin Integration Guide
zkLogin FAQ
Configure OpenID Providers

Advanced Topics
Information in the Advanced Topics section covers coding practices, useful features, and other developer-focused considerations that might arise as you continue your development journey on Sui. The topics in this section aren't necessarily more difficult than other topics, but they include subjects you might not encounter or need to consider until you're developing more advanced solutions on the Sui network.

Asset Tokenization
Asset tokenization refers to the process of representing real-world assets, such as real estate, art, commodities, stocks, or other valuable assets, as digital tokens on the blockchain network. This involves converting the ownership or rights of an asset into digital tokens, which are then recorded and managed on the blockchain.

Go to Asset Tokenization.

Custom Indexer
You can build custom indexers using the Sui micro-data ingestion framework. To create an indexer, you subscribe to a checkpoint stream with full checkpoint content. Establishing a custom indexer helps improve latency, allows pruning the data of your Sui Full node, and provides efficient assemblage of checkpoint data.

Go to Custom Indexer.

Migrating to GraphQL
See the Migrating to GraphQL guide to upgrade your smart contracts to use the GraphQL API.

This guide compares JSON-RPC queries to their equivalent GraphQL counterpart. While it is possible to systematically rewrite JSON-RPC queries (for example, sui_getTotalTransactionBlocks) to their GraphQL counterparts using this guide, it is recommended that you revisit your application's query patterns to take full advantage of the flexibility that GraphQL offers in serving queries that touch multiple potentially nested endpoints (for example transactions, balances, coins), and use the following examples to get a flavor of how the two APIs express similar concepts.

Go to Migrating to GraphQL.

Migrating to GraphQL
This guide compares JSON-RPC queries to their equivalent GraphQL counterpart. While it is possible to systematically rewrite JSON-RPC queries (for example, sui_getTotalTransactionBlocks) to their GraphQL counterparts using this guide, it is recommended that you revisit your application's query patterns to take full advantage of the flexibility that GraphQL offers in serving queries that touch multiple potentially nested endpoints (for example transactions, balances, coins), and use the following examples to get a flavor of how the two APIs express similar concepts.

For a comprehensive list of all available GraphQL features, consult the reference.

Example 1: Get total transaction blocks
The goal is to get the total number of transaction blocks in the network.

JSON-RPC
GraphQL
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "sui_getTotalTransactionBlocks",
  "params": []
}

Example 2: Get a specific transaction block
The goal is to get the transaction block by its digest.

JSON-RPC
GraphQL
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "sui_getTransactionBlock",
  "params": [
    "Hay2tj3GcDYcE3AMHrej5WDsHGPVAYsegcubixLUvXUF",
    {
      "showInput": true,
      "showRawInput": false,
      "showEffects": true,
      "showEvents": true,
      "showObjectChanges": false,
      "showBalanceChanges": false
    }
  ]
}

Example 3: Get coin objects owned by an address
The goal is to return all Coin<0x2::sui::SUI> objects an address owns.

JSON-RPC
GraphQL
query {
  "jsonrpc": "2.0",
  "id": 1,
  "method": "suix_getCoins",
  "params": [
    "0x5094652429957619e6efa79a404a6714d1126e63f551f4b6c7fb76440f8118c9", //owner
    "0x2::sui::SUI",                                                      //coin type
    "0xe5c651321915b06c81838c2e370109b554a448a78d3a56220f798398dde66eab", //cursor
    3 //limit
  ]
}

Related links
GraphQL reference: Auto-generated GraphQL reference for Sui RPC.
GraphQL quick-start: Querying Sui RPC with GraphQL gets you started using GraphQL to query the Sui RPC for on-chain data.
GraphQL concepts: GraphQL for Sui RPC examines the elements of GraphQL that you should know to get the most from the service.


Migrating to Move 2024
New features for Move are becoming available in 2024, a part of the aptly titled "Move 2024" edition. Many of these changes are enhancements to the source language, affecting the compiler without requiring any changes to the binary representation published on chain.

The primary goal of these changes is to make Move easier to write, and hopefully easier to read. The relatively few breaking changes introduced to the source language are to better position Move to handle future advancements.

Existing code will continue to compile, even with the addition of these new features. And because these features are opt-in, you can write your packages with the new features, even if your dependencies do not. Opting to take advantage of the new features in your current modules, however, does introduce some breaking changes.

This document highlights some new features to try out and shows how to migrate your existing modules to use Move 2024.

INFO
Please, provide any feedback or report any issues you encounter via GitHub, Discord, or Telegram.

How to migrate
To migrate a project to Move 2024 Beta:

Delete your existing Move.lock file (if one exists) to make sure you're using the newest sui-framework version.
Perform one of the following:
Run sui move migrate in the root of your Move project. See Automatic migration.
Alternatively, update your Move.toml file's [package] entry to include edition = "2024.beta". If you do this, you might receive a number of new errors related to the breaking changes.
Automatic migration
Move 2024 includes an automatic migration script that you can use by calling sui move migrate in the root of your Move project. Upon running, your console prompts you for which Move edition to use. If you select 2024.beta, the script invokes the compiler and attempts to automatically update your code to avoid the breaking changes the update introduces (including marking structs as public, mutable variables with the mut keyword, avoiding restricted keywords, swapping friends for public(package), and even updating paths to global paths in many cases).

After this is done, your console displays a diff of the changes the script intends to make. If you accept the changes, the script updates your code and your Move.toml file automatically. You are now using Move 2024 Beta.

Update IDE support
Use the new VSCode Move extension to get support for Move 2024 features. The new extension has a number of improvements over the original move-analyzer extension, but if you would like to keep using the original one, be sure to rebuild and reinstall the move-analyzer binary to get 2024 support:

cargo install --git https://github.com/MystenLabs/sui.git move-analyzer

See the getting started guide on Move IDEs and plugins for more information.

New features
Here is a brief overview of some of the new features in Move 2024.

Method syntax
You can call certain functions now as methods using the . syntax. For example, the following call

vector::push_back(&mut v, coin::value(&c));

can now be written as

v.push_back(c.value());

Where the receiver of the method (v and c in this example) is automatically borrowed if necessary (as &mut v and &c respectively).

You can call any function defined in the same module as the receiver's type as a method if it takes the receiver as its first argument.

For functions defined outside the module, you can declare methods using public use fun and use fun.

Index syntax
With method syntax, you can annotate certain functions as being #[syntax(index)] methods. You then call these methods using v[i]-style calls.

For example,

*&mut v[i] = v[j];

resolves to

*vector::borrow_mut(&mut v, i) = *vector::borrow(&v, j);

public(package)
friend declarations, and the associated public(friend) visibility modifiers, are deprecated. In their place is the public(package) visibility modifier, which allows calling functions only within the same package where they are defined.

Positional fields
You can now define structs with positional fields, which are accessed by zero-based index. For example,

public struct Pair(u64, u64) has copy, drop, store;

then to access each field,

public fun sum(p: &Pair): u64 {
  p.0 + p.1
}

And as this example shows, you can now declare abilities after the struct field list.

Nested use and standard library defaults
You can now nest use aliases for more conciseness.

use sui::{balance, coin::{Self, Coin}};

Additionally, the following use declarations are now automatically included in every module:

use std::vector;
use std::option::{Self, Option};
use sui::object::{Self, ID, UID};
use sui::transfer;
use sui::tx_context::{Self, TxContext};

Automatic referencing in equality
Equality operations, == and !=, now automatically borrow if one side is a reference and the other is not. For example,

fun check(x: u64, r: &u64): bool {
  x == r
}

is equivalent to

fun check(x: u64, r: &u64): bool {
  &x == r
}

This automatic borrowing can occur on either side of == and !=.

Loop labels
When nesting loops, it can be convenient to break to the outer loop. For example,

let mut i = 0;
let mut j = 0;
let mut terminate_loop = false;
while (i < 10) {
    while (j < 10) {
        if (haystack(i, j) == needle) {
            terminate_loop = true;
            break;
        };
        j = j + 1;
    };
    if (terminate_loop) break;
    i = i + 1;
}

Now, you can directly name the outer loop (outer in this case) and break it all at once:

let mut i = 0;
let mut j = 0;
'outer: while (i < 10) {
    while (j < 10) {
        if (haystack(i, j) == needle) break'outer;
        j = j + 1;
    };
    i = i + 1;
}

break with value
It's now possible to break with a value from a loop. For example,

let mut i = 0;
let x: u64 = loop {
    if (v[i] > 10) break i;
    i = i + 1;
};

You can achieve this with labels, as well. For example,

let mut i = 0;
let mut j = 0;
let item = 'outer: loop {
    while (j < 10) {
        let item = haystack(i, j);
        if (item == needle) break'outer option::some(item);
        j = j + 1;
    };
    i = i + 1;
    if (i == 10) break option::none();
};

Breaking changes
Breaking changes are, unfortunately, a growing pain in Move 2024. We anticipate these changes to be minimally invasive and have provided a migration script to automate them in most cases. In addition, these changes pave the way for new features still to come in Move 2024.

Datatype visibility requirements
Currently, all structs in Move are, by convention, public: any other module or package can import them and refer to them by type. To make this clearer, Move 2024 requires that all structs be declared with the public keyword. For example,

// legacy code
struct S { x: u64 }

// Move 2024 code
public struct S { x: u64 }

Any non-public struct produces an error at this time, though the Move team is working on new visibility options for future releases.

Mutability requirements
Previously, all variables in Move were implicitly mutable. For example,

fun f(s: S, y: u64): u64 {
    let a = 0;
    let S { x } = s;
    a = 1;
    x = 10;
    y = 5;
    x + y
}

Now, you must declare mutable variables explicitly:

fun f(s: S, mut y: u64): u64 {
    let mut a = 0;
    let S { mut x } = 5;
    a = 1;
    x = 10;
    y = 5;
    x + y
}

The compiler now produces an error if you attempt to reassign or borrow a variable mutably without this explicit declaration.

Removing friends and public(friend)
Friends and the public(friend) visibilities were introduced early in Move's development, predating even the package system. As indicated in the public(package) section, public(package) deprecates public(friend) in Move 2024.

The following declaration now produces an error:

module pkg::m {
    friend pkg::a;
    public(friend) fun f() { ... }
}

module pkg::a {
    fun calls_f() { ... pkg::m::f() ... }
}

Instead, if you want your function to be visible only in the package, write:

module pkg::m {
    public(package) fun f() { ... }
}

module pkg::a {
    // this now works directly
    fun calls_f() { ... pkg::m::f() ... }
}

New keywords
Looking toward the future, Move 2024 Beta adds the following keywords to the language: enum, for, match, mut, and type. The compiler, unfortunately, now produces parsing errors when it finds these in other positions. This is a necessary change as the language matures. If you perform automatic migration, the migration tool renames these as enum and so on, rewriting the code to use these escaped forms.

Revised paths and namespaces
Move 2024 revises how paths and namespaces work compared to legacy Move, toward easing enum aliasing in the future. Consider the following snippet from a test annotation in the sui_system library:

use sui_system::sui_system;
...
#[expected_failure(abort_code = sui_system::validator_set::EInvalidCap)]

Legacy Move would always treat a three-part name as an address(sui_system), module(validator_set), and module member (EInvalidCap). Move 2024 respects scope for use, so sui_system in the attribute resolves to the module, producing a name resolution error overall.

To avoid cases where this is the intended behavior, Move 2024 introduces a prefix operation for global qualification. To use, you can rewrite this annotation as:

use sui_system::sui_system;
...
#[expected_failure(abort_code = ::sui_system::validator_set::EInvalidCap)]
                             // ^ note `::` here

The migration script attempts to remediate naming errors using global qualification when possible.

Follow along
The beta release of Move 2024 comes with some powerful new features in addition to the breaking changes described here. There are also more on the horizon. Join the Sui developer newsletter to learn about new, exciting features coming to Move this year, including syntactic macros, enums with pattern matching, and other user-defined syntax extensions.

alpha and beta guidance
beta (specified via edition = "2024.beta") is the recommended edition. It includes all the new features mentioned above and all breaking changes. While there is the risk of breaking changes or bugs in beta, you should feel comfortable using it in your projects. As new features are added and tested, they will be included in the beta edition. The beta edition will end after all features for the year have been added and finalized.
alpha (specified via edition = "2024.alpha") will get new features and changes as they are developed. Breaking changes to features in alpha should be expected. As such, take caution when usingalpha in your projects.

Migrating to Move 2024
New features for Move are becoming available in 2024, a part of the aptly titled "Move 2024" edition. Many of these changes are enhancements to the source language, affecting the compiler without requiring any changes to the binary representation published on chain.

The primary goal of these changes is to make Move easier to write, and hopefully easier to read. The relatively few breaking changes introduced to the source language are to better position Move to handle future advancements.

Existing code will continue to compile, even with the addition of these new features. And because these features are opt-in, you can write your packages with the new features, even if your dependencies do not. Opting to take advantage of the new features in your current modules, however, does introduce some breaking changes.

This document highlights some new features to try out and shows how to migrate your existing modules to use Move 2024.

INFO
Please, provide any feedback or report any issues you encounter via GitHub, Discord, or Telegram.

How to migrate
To migrate a project to Move 2024 Beta:

Delete your existing Move.lock file (if one exists) to make sure you're using the newest sui-framework version.
Perform one of the following:
Run sui move migrate in the root of your Move project. See Automatic migration.
Alternatively, update your Move.toml file's [package] entry to include edition = "2024.beta". If you do this, you might receive a number of new errors related to the breaking changes.
Automatic migration
Move 2024 includes an automatic migration script that you can use by calling sui move migrate in the root of your Move project. Upon running, your console prompts you for which Move edition to use. If you select 2024.beta, the script invokes the compiler and attempts to automatically update your code to avoid the breaking changes the update introduces (including marking structs as public, mutable variables with the mut keyword, avoiding restricted keywords, swapping friends for public(package), and even updating paths to global paths in many cases).

After this is done, your console displays a diff of the changes the script intends to make. If you accept the changes, the script updates your code and your Move.toml file automatically. You are now using Move 2024 Beta.

Update IDE support
Use the new VSCode Move extension to get support for Move 2024 features. The new extension has a number of improvements over the original move-analyzer extension, but if you would like to keep using the original one, be sure to rebuild and reinstall the move-analyzer binary to get 2024 support:

cargo install --git https://github.com/MystenLabs/sui.git move-analyzer

See the getting started guide on Move IDEs and plugins for more information.

New features
Here is a brief overview of some of the new features in Move 2024.

Method syntax
You can call certain functions now as methods using the . syntax. For example, the following call

vector::push_back(&mut v, coin::value(&c));

can now be written as

v.push_back(c.value());

Where the receiver of the method (v and c in this example) is automatically borrowed if necessary (as &mut v and &c respectively).

You can call any function defined in the same module as the receiver's type as a method if it takes the receiver as its first argument.

For functions defined outside the module, you can declare methods using public use fun and use fun.

Index syntax
With method syntax, you can annotate certain functions as being #[syntax(index)] methods. You then call these methods using v[i]-style calls.

For example,

*&mut v[i] = v[j];

resolves to

*vector::borrow_mut(&mut v, i) = *vector::borrow(&v, j);

public(package)
friend declarations, and the associated public(friend) visibility modifiers, are deprecated. In their place is the public(package) visibility modifier, which allows calling functions only within the same package where they are defined.

Positional fields
You can now define structs with positional fields, which are accessed by zero-based index. For example,

public struct Pair(u64, u64) has copy, drop, store;

then to access each field,

public fun sum(p: &Pair): u64 {
  p.0 + p.1
}

And as this example shows, you can now declare abilities after the struct field list.

Nested use and standard library defaults
You can now nest use aliases for more conciseness.

use sui::{balance, coin::{Self, Coin}};

Additionally, the following use declarations are now automatically included in every module:

use std::vector;
use std::option::{Self, Option};
use sui::object::{Self, ID, UID};
use sui::transfer;
use sui::tx_context::{Self, TxContext};

Automatic referencing in equality
Equality operations, == and !=, now automatically borrow if one side is a reference and the other is not. For example,

fun check(x: u64, r: &u64): bool {
  x == r
}

is equivalent to

fun check(x: u64, r: &u64): bool {
  &x == r
}

This automatic borrowing can occur on either side of == and !=.

Loop labels
When nesting loops, it can be convenient to break to the outer loop. For example,

let mut i = 0;
let mut j = 0;
let mut terminate_loop = false;
while (i < 10) {
    while (j < 10) {
        if (haystack(i, j) == needle) {
            terminate_loop = true;
            break;
        };
        j = j + 1;
    };
    if (terminate_loop) break;
    i = i + 1;
}

Now, you can directly name the outer loop (outer in this case) and break it all at once:

let mut i = 0;
let mut j = 0;
'outer: while (i < 10) {
    while (j < 10) {
        if (haystack(i, j) == needle) break'outer;
        j = j + 1;
    };
    i = i + 1;
}

break with value
It's now possible to break with a value from a loop. For example,

let mut i = 0;
let x: u64 = loop {
    if (v[i] > 10) break i;
    i = i + 1;
};

You can achieve this with labels, as well. For example,

let mut i = 0;
let mut j = 0;
let item = 'outer: loop {
    while (j < 10) {
        let item = haystack(i, j);
        if (item == needle) break'outer option::some(item);
        j = j + 1;
    };
    i = i + 1;
    if (i == 10) break option::none();
};

Breaking changes
Breaking changes are, unfortunately, a growing pain in Move 2024. We anticipate these changes to be minimally invasive and have provided a migration script to automate them in most cases. In addition, these changes pave the way for new features still to come in Move 2024.

Datatype visibility requirements
Currently, all structs in Move are, by convention, public: any other module or package can import them and refer to them by type. To make this clearer, Move 2024 requires that all structs be declared with the public keyword. For example,

// legacy code
struct S { x: u64 }

// Move 2024 code
public struct S { x: u64 }

Any non-public struct produces an error at this time, though the Move team is working on new visibility options for future releases.

Mutability requirements
Previously, all variables in Move were implicitly mutable. For example,

fun f(s: S, y: u64): u64 {
    let a = 0;
    let S { x } = s;
    a = 1;
    x = 10;
    y = 5;
    x + y
}

Now, you must declare mutable variables explicitly:

fun f(s: S, mut y: u64): u64 {
    let mut a = 0;
    let S { mut x } = 5;
    a = 1;
    x = 10;
    y = 5;
    x + y
}

The compiler now produces an error if you attempt to reassign or borrow a variable mutably without this explicit declaration.

Removing friends and public(friend)
Friends and the public(friend) visibilities were introduced early in Move's development, predating even the package system. As indicated in the public(package) section, public(package) deprecates public(friend) in Move 2024.

The following declaration now produces an error:

module pkg::m {
    friend pkg::a;
    public(friend) fun f() { ... }
}

module pkg::a {
    fun calls_f() { ... pkg::m::f() ... }
}

Instead, if you want your function to be visible only in the package, write:

module pkg::m {
    public(package) fun f() { ... }
}

module pkg::a {
    // this now works directly
    fun calls_f() { ... pkg::m::f() ... }
}

New keywords
Looking toward the future, Move 2024 Beta adds the following keywords to the language: enum, for, match, mut, and type. The compiler, unfortunately, now produces parsing errors when it finds these in other positions. This is a necessary change as the language matures. If you perform automatic migration, the migration tool renames these as enum and so on, rewriting the code to use these escaped forms.

Revised paths and namespaces
Move 2024 revises how paths and namespaces work compared to legacy Move, toward easing enum aliasing in the future. Consider the following snippet from a test annotation in the sui_system library:

use sui_system::sui_system;
...
#[expected_failure(abort_code = sui_system::validator_set::EInvalidCap)]

Legacy Move would always treat a three-part name as an address(sui_system), module(validator_set), and module member (EInvalidCap). Move 2024 respects scope for use, so sui_system in the attribute resolves to the module, producing a name resolution error overall.

To avoid cases where this is the intended behavior, Move 2024 introduces a prefix operation for global qualification. To use, you can rewrite this annotation as:

use sui_system::sui_system;
...
#[expected_failure(abort_code = ::sui_system::validator_set::EInvalidCap)]
                             // ^ note `::` here

The migration script attempts to remediate naming errors using global qualification when possible.

Follow along
The beta release of Move 2024 comes with some powerful new features in addition to the breaking changes described here. There are also more on the horizon. Join the Sui developer newsletter to learn about new, exciting features coming to Move this year, including syntactic macros, enums with pattern matching, and other user-defined syntax extensions.

alpha and beta guidance
beta (specified via edition = "2024.beta") is the recommended edition. It includes all the new features mentioned above and all breaking changes. While there is the risk of breaking changes or bugs in beta, you should feel comfortable using it in your projects. As new features are added and tested, they will be included in the beta edition. The beta edition will end after all features for the year have been added and finalized.
alpha (specified via edition = "2024.alpha") will get new features and changes as they are developed. Breaking changes to features in alpha should be expected. As such, take caution when usingalpha in your projects.


Asset Tokenization
Asset tokenization refers to the process of representing real-world assets, such as real estate, art, commodities, stocks, or other valuable assets, as digital tokens on the blockchain network. This involves converting the ownership or rights of an asset into digital tokens, which are then recorded and managed on the blockchain.

High-level overview
The concept is to divide high-value assets into smaller, more affordable units, representing ownership or a fraction of the asset.

This strategy enables wider participation from investors who might want to mitigate risk by investing in a portion of a digital asset rather than being the sole owner, thereby expanding accessibility to a broader range of investors.

This pattern is similar to the ERC1155 multi-token standard with additional functionality. This makes it a suitable choice for Solidity based use cases that one might want to implement on Sui.

Asset creation

Each asset is fractionalized into a total supply, with each fraction represented as either a non-fungible token (NFT) or fungible token (FT) type collectible. This ensures that each individual fraction maintains a balance equal to or greater than one, and when combined, all fractions collectively reach the total supply of the asset.

Besides the total supply, each asset is defined by various other fields such as name, description, and more. These fields collectively form the metadata for the asset, and they remain consistent across all fractions of the asset.

NFTs vs FTs distinction

Each time a tokenized asset is minted, there's a possibility for it to be created with new metadata. If new metadata is incorporated, the tokenized asset is deemed unique, transforming it into an NFT. In this case, its balance is limited to one, signifying that only a single instance of this asset exists.

If there's no additional metadata, the tokenized asset is categorized as an FT, allowing its balance to exceed one, enabling multiple identical instances of the asset to exist.

FTs possess the capability to merge (join) among themselves or be split when the balance is greater than one. This functionality allows for the aggregation or division of units of the token, offering flexibility in handling varying quantities as needed.

As previously mentioned, all the collectibles of tokenized assets, whether NFTs or FTs, when combined, can amount to the maximum total supply of the asset.

Burnability

When you create the asset, you can define whether the fractions of the asset are eligible for removal or destruction from circulation. The process of removing or destroying assets is called burning.

If a tokenized asset is burnable, then burning a fraction causes the circulating supply to decrease by the balance of the burnt item. The total supply, however, remains constant, allowing you to mint the burned fractions again if needed, thus maintaining the predetermined total supply of the asset.

Move packages
As with all smart contracts on Sui, Move provides the logic that powers asset tokenization.

asset_tokenization package
INFO
This reference implementation uses the Kiosk primitive to ensure that TAs created operate within their creator's defined policy. We recommend you use the implementation as it is in order to have marketable TAs that support Rules (e.g: royalties, commissions etc). If operating within the Kiosk primitive is not a requirement, then the unlock module & some of the proxy's methods related to Transfer Policies can be excluded.

Select a module to view its details:

tokenized_asset
proxy
unlock
The tokenized_asset module operates in a manner similar to the coin library.

When it receives a new one-time witness type, it creates a unique representation of a fractional asset. This module employs similar implementations to some methods found in the Coin module. It encompasses functionalities pertinent to asset tokenization, including new asset creation, minting, splitting, joining, and burning.

Structs

AssetCap

An AssetCap should be generated for each new Asset we wish to represent as a fractional NFT. In most scenarios, it is recommended to be created as an owned object, which can then be transferred to the platform's administrator for access restricted method invocation.

struct AssetCap<phantom T> {
    id: UID,
    // the current supply in circulation
    supply: Supply<T>,
    // the total max supply allowed to exist at any time
    total_supply: u64,
    // Determines if the asset can be burned or not
    burnable: bool
}

AssetMetadata

The AssetMetadata struct defines the metadata representing the entire asset that we intend to fractionalize. It is recommended to be a shared object.

struct AssetMetadata<phantom T> has key, store {
        id: UID,
        /// Name of the asset
        name: String,
        // the total max supply allowed to exist at any time
        total_supply: u64,
        /// Symbol for the asset
        symbol: ascii::String,
        /// Description of the asset
        description: String,
        /// URL for the asset logo
        icon_url: Option<Url>
    }

TokenizedAsset

The TokenizedAsset will be minted with a specified balance where the balance is less than or equal to the remaining supply. If the VecMap of an asset is populated with values, indicating multiple unique entries, it is considered a NFT. Conversely, if the VecMap of an asset is not populated, indicating an absence of individual entries, it is considered an FT.

struct TokenizedAsset<phantom T> has key, store {
        id: UID,
        /// The balance of the tokenized asset
        balance: Balance<T>,
        /// If the VecMap is populated, it is considered an NFT, else the asset is considered an FT.
        metadata: VecMap<String, String>,
        /// URL for the asset image (optional)
        image_url: Option<Url>,
    }


PlatformCap

The PlatformCap refers to the capability issued to the individual who deploys the contract. This capability grants specific permissions or authority related to the platform's functionalities, allowing the deployer certain controlled actions or access rights within the deployed contract.

/// Capability that is issued to the one deploying the contract
struct PlatformCap has key, store { id: UID }

Functions

init

This function creates a PlatformCap and sends it to the sender.

fun init(ctx: &mut TxContext) {}

new_asset

This function holds the responsibility of creating a fresh representation of an asset, defining its crucial attributes. Upon execution, it returns two distinct objects: the AssetCap and AssetMetadata. These objects encapsulate the necessary information and characteristics defining the asset within the system.

public fun new_asset<T: drop>(
        witness: T,
        total_supply: u64,
        symbol: ascii::String,
        name: String,
        description: String,
        icon_url: Option<Url>,
        burnable: bool,
        ctx: &mut TxContext
    ): (AssetCap<T>, AssetMetadata<T>) {}

mint

The function performs the minting of a tokenized asset. If new metadata is introduced during this process, the resulting tokenized asset is considered unique, resulting in the creation of an NFT with a balance set to 1. Alternatively, if no new metadata is added, the tokenized asset is classified as an FT, permitting its balance to surpass 1, as specified by a provided argument. Upon execution, the function returns the tokenized asset object.

public fun mint<T>(
        cap: &mut AssetCap<T>,
        keys: vector<String>,
        values: vector<String>,
        value: u64,
        ctx: &mut TxContext
    ): TokenizedAsset<T> {}

split

This function, is provided with a tokenized asset of the FT type and a balance greater than 1, along with a value less than the object's balance, and performs a split operation on the tokenized asset. The operation divides the existing tokenized asset into two separate tokenized assets. The newly created tokenized asset will have a balance equal to the given value, while the balance of the provided object is reduced by the specified value. Upon completion, the function returns the newly created tokenized asset. This function does not accept or operate on tokenized assets of the NFT type.

public fun split<T>(
        self: &mut TokenizedAsset<T>,
        split_amount: u64,
        ctx: &mut TxContext
    ): TokenizedAsset<T> {}

join

This function is given two tokenized assets of the FT type and executes a merge operation on the tokenized assets. The operation involves increasing the balance of the first tokenized asset by the balance of the second one. Subsequently, the second tokenized asset will be burned or removed from circulation. After the process concludes, the function returns the ID of the burned tokenized asset.

This function does not accept or operate on tokenized assets of the NFT type.

public fun join<T>(
        self: &mut TokenizedAsset<T>,
        other: TokenizedAsset<T>
    ): ID {}

burn

This function requires the assetCap as a parameter, thereby restricting its invocation solely to the platform admin. Additionally, it accepts a tokenized asset that will be burned as part of its operation. Upon burning the provided tokenized asset, the circulating supply decreases by the balance of the burnt item. It necessitates a tokenized asset which is burnable.

public fun burn<T>(
        cap: &mut AssetCap<T>,
        tokenized_asset: TokenizedAsset<T>
    )

total_supply

This function retrieves and returns the value representing the total supply of the asset.

public fun total_supply<T>(cap: &AssetCap<T>): u64 {}

supply

This function retrieves and returns the value representing the current circulating supply of the asset.

public fun supply<T>(cap: &AssetCap<T>): u64 {}

value

This function takes a tokenized asset as input and retrieves its associated balance value.

public fun value<T>(tokenized_asset: &TokenizedAsset<T>): u64 {}

create_vec_map_from_arrays

This internal helper function is utilized to populate a VecMap<String, String>. It assists in the process of filling or setting key-value pairs within the VecMap data structure.

fun create_vec_map_from_arrays(
        keys: vector<String>,
        values: vector<String>
    ): VecMap<String, String> {}

template package
An example use case package, that enables utilization of Rust WASM functionality to support seamless asset creation on the browser. This is similar to the launchpad approach and will serve as the template package whenever a new asset requires representation as a tokenized asset. Effectively allowing users to edit fields of this template contract on the fly and publish it with the edits included. This package implements two essential modules, each catering to distinct functionalities required for asset tokenization. More details regarding how Rust WASM was implemented can be found in the Web Assembly section.

Modules

template

This is the module where a new asset can be defined.

When there's a necessity to represent a new asset as a fractional asset, this module will undergo modification to <template>::<TEMPLATE>, with the <template> (in capitals) being the OTW of this new asset.

This module is designed to call the asset_tokenization::tokenized_asset::new_asset(...) method, which facilitates the declaration of new fields for the asset:

witness The OTW NEW_ASSET
total_supply The total supply allowed to exist at any time
symbol The symbol for the asset
name The name of the asset
description The description of the asset
icon_url The URL for the asset logo (optional)
burnable Boolean: defines if the asset can be burned by an admin
genesis

A genesis type of module that should include a OTW so that the sender can claim the publisher.

Publish and mint tokenized sequence diagram
Blockchain
genesis
template
proxy
tokenized_asset
Kiosk
Asset Creator
Platform Admin
Blockchain
genesis
template
proxy
tokenized_asset
Kiosk
Asset Creator
Platform Admin
Publish asset_tokenization package (tokenized_asset, proxy, unlock modules)
tokenized_asset module is published
proxy module is published
Send Platform Cap (owned object)
Share Registry (shared object)
Pass Asset Info, AssetOTW as input
Pass PublisherOTW as input
Publish template package (template, genesis modules)
genesis module is published
template module is published
Send Publisher (owned object)
Create new asset using Asset Info as input
Send Asset Cap (owned object)
Share Asset Metadata (shared object)
Use Publisher as input to setup_tp
Use Registry as input to setup_tp
Share created Transfer Policy, ProtectedTP (shared objects)
Send created Transfer Policy Cap (owned object)
Define type of tokenized asset (FT, NFT) to mint
Return minted Tokenized Asset
Place Tokenized Asset
Join sequence diagram
The following sequence diagram presenting how the join flow would take place. The following flow assumes that:

Tokenized assets X & Y have already been minted by the creator of their type.
Tokenized assets X & Y are already placed and locked inside the user's Kiosk.
Everything is executed in the same programmable transaction block (PTB).
blockchain
tokenized asset module
unlock module
kiosk module
User's Kiosk
User
blockchain
tokenized asset module
unlock module
kiosk module
User's Kiosk
User
Borrow Tokenized Asset X
Returns Promise, Tokenized Asset X
List Tokenized Asset Y for zero price
Purchase Tokenized Asset Y
Returns Transfer Request, Tokenized Asset Y
Use Transfer Request, Tokenized Asset X, Y as input to asset_from_kiosk_to_join
Use Protected TP as input to asset_from_kiosk_to_join
Returns Join Promise, Tokenized Asset X,Y Objects
Use Tokenized Asset X,Y as input to join
Return Burn Proof, Tokenized Asset X
Use Burn Proof, Join Promise, Tokenized Asset X as input to prove_join
Return Tokenized Asset X
Resolve Promise by returning Tokenized Asset X in user's Kiosk
Burn sequence diagram
The following sequence diagram shows the burn flow and assumes that:

Tokenized asset has already been minted by the creator of its type.
Tokenized asset is already placed and locked inside the user's Kiosk.
Everything is executed in the same PTB.
blockchain
tokenized asset module
unlock module
kiosk module
User's Kiosk
User
blockchain
tokenized asset module
unlock module
kiosk module
User's Kiosk
User
List Tokenized Asset for zero price
Purchase Tokenized Asset
Returns Transfer Request, Tokenized Asset Object
Use Transfer Request, Tokenized Asset Object, Asset Cap as input to asset_from_kiosk_to_burn
Use Protected TP as Input to asset_from_kiosk_to_burn
Returns Burn Promise, Tokenized Asset Object, Asset Cap
Use Tokenized Asset Object, Asset Cap as input to burn
Returns Asset Cap
Use Burn Proof, Asset Cap as input to prove_burn
Returns Asset Cap
Variations
The packages and modules provided demonstrate how you could implement asset tokenization for your project. Your particular use case probably necessitates altering the contract for convenience or to introduce new features.

Example convenience alteration
Instead of implementing the unlock functionality in multiple steps inside of a PTB, it would also be possible to create a method that performs the purchase, borrowing, unlocking and joining of an asset all on one function. This is how that would look like for the joining operation:

public fun kiosk_join<T>(
	kiosk: &mut Kiosk,
  kiosk_cap: &KioskOwnerCap,
	protected_tp: &ProtectedTP<TokenizedAsset<T>>,
  ta1_id: ID,
  ta2_id: ID,
  ctx: &mut TxContext
) {

	kiosk::list<TokenizedAsset<T>>(kiosk, kiosk_cap, ta2_id, 0);
	let (ta1, promise_ta1) = kiosk::borrow_val(kiosk, kiosk_cap, ta1_id);
	let coin = coin::zero<SUI>(ctx);
	let (ta2, request) = kiosk::purchase(kiosk, ta2_id, coin);

	let tp_ref = proxy::transfer_policy(protected_tp);
	let (_item, _paid, _from) = transfer_policy::confirm_request(
	    tp_ref,
	    request
	);

	tokenized_asset::join(&mut ta1, ta2);

	kiosk::return_val(kiosk, ta1, promise_ta1);
}

Example alteration for use case
CAUTION
The following example splits (effectively replacing) the AssetCap<T> into two new objects: the Treasury<T> and the AdminCap<T>. The access to methods defined in the original package, should now be carefully re-designed as this change can introduce unwanted effects. This required re-design is not entirely contained in this example and only some methods are changed for demonstration purposes (or as a thorough exercise).

Assume you want to allow the users to also burn assets, not only admins. This still needs to be an authorized operation but it would allow the flexibility of consuming tokenized assets for a use case specific purpose (for example, burning all of the collectibles you've gathered to combine them). To achieve this, the admin can mint tickets that contain the ID of the asset they are allowed to burn. To support this functionality you must redesign the smart contract and separate the admin from the asset's treasury of each asset, which now holds only supply related information. Sample changes that need to happen follow:

Structs

Create a ticket that has only the key ability so that the receiver cannot trade it.

struct BurnTicket<phantom T> has key {
	id: UID,
	tokenized_asset_id: ID // the tokenized asset that this ticket gives access to burn
}


The struct that now only holds treasury related information (results from splitting the AssetCap, meaning it's no longer part of this design) is created as a shared object. Change functions like mint to also take as input both the Treasury object and the AdminCap object.

struct Treasury<phantom T> has key, store {
	id: UID,
	supply: Supply<T>,
  total_supply: u64,
}

The other half of the AssetCap functionality which retains the admin capability and the configuration of burnability is an owned object sent to the creator of type <T>.

struct AdminCap<phantom T> has key, store {
	id: UID,
	burnable: bool
}

Method Signatures

The AdminCap here acts both as an admin capability and a type insurance. Encoding the information of both the asset type that is allowed to be deleted with this ticket. This function should assert that the asset T is burnable and return a BurnTicket<T>.

public fun mint_burn_ticket<T>(
	cap: &AdminCap<T>,
	tokenized_asset_id: ID,
	ctx: &mut TxContext
): BurnTicket

Burning on the user side requires for them to access the shared Treasury object. This function burns the tokenized asset and decreases the supply.

public fun burn_with_ticket<T>(
	treasury: &mut Treasury<T>,
	self: TokenizedAsset<T>,
	ticket: BurnTicket<T>)

Deployment
INFO
See Publish a Package for a more detailed guide on publishing packages or Sui Client CLI for a complete reference of client commands in the Sui CLI.

Before publishing your code, you must first initialize the Sui Client CLI, if you haven't already. To do so, in a terminal or console at the root directory of the project enter sui client. If you receive the following response, complete the remaining instructions:

Config file ["<FILE-PATH>/.sui/sui_config/client.yaml"] doesn't exist, do you want to connect to a Sui Full node server [y/N]?


Enter y to proceed. You receive the following response:

Sui Full node server URL (Defaults to Sui Devnet if not specified) :

Leave this blank (press Enter). You receive the following response:

Select key scheme to generate keypair (0 for ed25519, 1 for secp256k1, 2: for secp256r1):

Select 0. Now you should have a Sui address set up.

Publishing
At this stage, you can choose to manually deploy the contracts or utilize the publish bash script that automatically deploys the contracts and sets up most of the .env Asset Tokenization related fields for you. The .env.template file denotes variables that the script automatically fills in. You can see a reference here:

SUI_NETWORK = rpc endpoint of the network of your choice | auto filled by publish script
ASSET_TOKENIZATION_PACKAGE_ID = Created by publishing `asset_tokenization` package | auto filled by publish script
REGISTRY = Created by publishing `asset_tokenization` package | auto filled by publish script

TEMPLATE_PACKAGE_ID = Created by publishing `template` package
ASSET_CAP_ID = Created by publishing `template` package
ASSET_METADATA_ID = Created by publishing `template` package
ASSET_PUBLISHER = Created by publishing `template` package

PROTECTED_TP = Created by calling `setup_tp` function
TRANSFER_POLICY = Created by calling `setup_tp` function

OWNER_MNEMONIC_PHRASE = your mnemonic | can be exported locally in the terminal before publishing
BUYER_MNEMONIC_PHRASE = buyer's mnemonic | can be exported locally in the terminal before publishing
TARGET_KIOSK = kiosk id
BUYER_KIOSK = kiosk id


TOKENIZED_ASSET = tokenized asset id (created by minting)
FT1 = tokenized asset id (to be joined)
FT2 = tokenized asset id (to be joined)


For more details on publishing, please check the setup folder's README.

Publishing packages
Select a package for specific instructions.

TIP
Beginning with the Sui v1.24.1 release, the --gas-budget flag is no longer required for CLI commands.

asset_tokenization
template
Manually
In a terminal or console at the move/asset_tokenization directory of the project enter:

sui client publish --gas-budget <GAS-BUDGET>

For the gas budget, use a standard value such as 20000000.

The package should successfully deploy, and you then see:

UPDATING GIT DEPENDENCY https://github.com/MystenLabs/sui.git
INCLUDING DEPENDENCY Sui
INCLUDING DEPENDENCY MoveStdlib
BUILDING asset_tokenization
Successfully verified dependencies on-chain against source.

You can also view a multitude of information and transactional effects.

You should choose and store the package ID and the registry ID from the created objects in the respective fields within your .env file.

Afterward, it's necessary to modify the Move.toml file. Under the [package] section, add published-at = <package ID>. Additionally, under the [addresses] section, replace 0x0 with the same package ID.

Automatically
The fields that are automatically filled are: SUI_NETWORK, ASSET_TOKENIZATION_PACKAGE_ID and REGISTRY.

To publish with the bash script run:

npm run publish-asset-tokenization

After publishing, you can now edit the Move.toml file like described in the Manual flow.

For more details regarding this process, please consult the setup folder's README.

WebAssembly (WASM) and template package
TIP
You can find a public facing reference to the WASM library in the move-binary-format-wasm Sui repo subfolder.

This feature was developed with the intent to enable Move bytecode serialization and deserialization on the web. In essence, this feature allows you to edit existing contracts in a web environment.

In the case of asset tokenization, these edits allow you to create and publish new types that represent physical or digital assets that we want to tokenize.

Bytecode manipulation
CAUTION
On modifications that are made to the template package this process needs to be repeated. Note that some alterations, like changing a constant name, do not affect the produced bytecode.

Before proceeding to how to make these edits, it's important to understand how the library exposes the template module bytecode. The process is currently manual. This requires that you build and retrieve the compiled bytecode. To do this, navigate inside the template folder and run the following command:

xxd -c 0 -p build/template/bytecode_modules/template.mv | head -n 1

Toggle response

Copy the output you receive and paste it in the return instruction of the getBytecode method, which is located inside the bytecode-template.ts file.

Additionally, because the template package contains two modules, and therefore has another dependency, you also need to retrieve the bytecode of the genesis module in a similar fashion. This module bytecode, however, is not edited and isn't used as is. This operation is not directly relevant to the WASM library, but is necessary to successfully deploy the edited template module. To acquire the bytecode for genesis, navigate to the template folder and run:

xxd -c 0 -p build/template/bytecode_modules/genesis.mv | head -n 1

The output format is similar to the template module but smaller in length. Similarly to what you did with the template module, you need to copy this output but this time paste it in the bytecode constant variable located in the genesis_bytecode.ts file.

With the above setup, the library can now manipulate the bytecode by deserializing it, editing it, and serializing it again so that you can publish it.

Closer view of the template module
Taking a look at the template module, you should see that a few constants have been defined:

...
const TOTAL_SUPPLY: u64 = 100;
const SYMBOL: vector<u8> = b"Symbol";
const NAME: vector<u8> = b"Name";
const DESCRIPTION: vector<u8> = b"Description";
const ICON_URL: vector<u8> = b"icon_url";
const BURNABLE: bool = true;
...

These constants act as a reference point that the WASM library is able to modify. If you take a look at the TypeScript code that performs the edit and deploys, you can see in action how these fields are identified and updated:

...
const template = getBytecode();

const compiledModule = new CompiledModule(
  JSON.parse(wasm.deserialize(template))
)
  .updateConstant(0, totalSupply, "100", "u64")
  .updateConstant(1, symbol, "Symbol", "string")
  .updateConstant(2, asset_name, "Name", "string")
  .updateConstant(3, description, "Description", "string")
  .updateConstant(4, iconUrl, "icon_url", "string")
  .updateConstant(5, burnable, "true", "bool")
  .changeIdentifiers({
    template: moduleName,
    TEMPLATE: moduleName.toUpperCase(),
  });

const bytesToPublish = wasm.serialize(JSON.stringify(compiledModule));
...

Examine the updateConstant method, which is used to update constants. This method takes four arguments:

An idx (index) that the declared constant would have in the constant pool. The order is sequential, starting from 0 for the first constant defined in the Move file and stepping plus one for each consecutive constant.
A value that contains an updated value of the constant you want to change.
An expectedValue that contains the current value of the constant.
An expectedType that contains the current type of the constant.
The last two arguments are requited to minimize the risk of accidentally updating the wrong constant since this library is directly manipulating complied bytecode, which is quite dangerous.

Additionally, the changeIdentifiers method updates identifiers, which in our case are the module name and the struct name. This method takes a JSON object as an argument with keys of the current identifier names in the module and values being the desired names you want to change them into.

Lastly, to deploy the changed template module, build and publish:

...
const tx = new Transaction();
  tx.setGasBudget(100000000);
  const [upgradeCap] = tx.publish({
    modules: [[...fromHEX(bytesToPublish)], [...fromHEX(genesis_bytecode)]],
    dependencies: [
      normalizeSuiObjectId("0x1"),
      normalizeSuiObjectId("0x2"),
      normalizeSuiObjectId(packageId),
    ],
  });

  tx.transferObjects(
    [upgradeCap],
    tx.pure(signer.getPublicKey().toSuiAddress(), "address")
  );
...

As mentioned in the Bytecode manipulation section, the modules that you need to publish are the template and the genesis, hence the reason you have two elements in the modules array. It's also important to include any dependencies defined in the Move.toml file of the involved packages. The packageId used previously is the address the asset_tokenization package has been deployed to.

TypeScript
Now, you can begin interacting with the deployed smart contract and your tokenized asset.

In a terminal or console within the project's setup directory, utilize the following commands:

Create Transfer Policy

First, create a TransferPolicy and a ProtectedTP with the following command:

npm run call create-tp

After executing the command, the console displays the effects of the transaction.

By searching the transaction digest on a Sui network explorer, you can locate the created objects. Subsequently, select and save the TransferPolicy ID and the ProtectedTP ID from these objects into the respective fields within your .env file.

Add Rules

In the project's file transferPolicyRules.ts located in the directory setup/src/functions, you can modify the code to include the desired rules for your transfer policy.

Code snippet to be modified:

// A demonstration of using all the available rule add/remove functions.
    // You can chain these commands.
    tpTx
        .addFloorPriceRule('1000')
        .addLockRule()
        .addRoyaltyRule(percentageToBasisPoints(10), 0)
        // .addPersonalKioskRule()
        // .removeFloorPriceRule()
        // .removeLockRule()
        // .removeRoyaltyRule()
        // .removePersonalKioskRule()

By running the command npm run call tp-rules, the rules will be added to your transfer policy.

Now, investors can trade the fractions of your asset according to the rules you've set.

Select Kiosk

You must place the tokenized assets within a kiosk if marketable assets are desired. Subsequently, you can list and sell them to other users. It's imperative to lock the objects in the kiosk to prevent any future unauthorized usage outside the defined policy that you set.

Best practices recommend a single, comprehensive kiosk for all operations. However, this might not always be the case. Therefore, this project requires the use of only one personal kiosk to ensure consistency and better management, even if you own multiple kiosks.

To enforce this rule, execute the command npm run call select-kiosk. This provides you with the specific kiosk ID to use for this project.

Then, store the provided Kiosk ID in the appropriate field within your .env file.

Mint

In the project's file mint.ts, found in the directory setup/src/functions, you can edit the code to mint the desired type (NFT/FT) and balance for your asset.

As previously mentioned, if additional metadata is provided, the tokenized asset is treated as an NFT with a value of one. However, if there is no extra metadata, the tokenized asset is regarded as an FT, and you have the flexibility to select its balance, which can exceed one.

Here is an example from the code that needs modification:

// example without metadata -> FT
function getVecMapValues() {

  const keys : string[] = [];
  const values : string[] = [];

  return { keys, values };
}

or

// example with metadata -> NFT
function getVecMapValues() {
	const keys = [
	  "Piece",
	  "Is it Amazing?",
	  "In a scale from 1 to 10, how good?",
  ];
  const values = ["8/100", "Yes", "11"];

  return { keys, values };
}

Upon executing the command npm run call mint, a new tokenized asset is minted. You can save the object's ID in the .env file for future reference.

Lock

Locking the objects within the kiosk is crucial to prevent any unauthorized usage beyond the established policy.

Upon executing the command npm run call lock, your newly minted tokenized asset is secured within your kiosk.

Before running the command, make sure that the field TOKENIZED_ASSET within your .env file is populated with the object you intend to lock.

Mint and Lock

Executing the command npm run call mint-lock performs both the mint and lock functions sequentially, ensuring the minted asset is created and immediately locked within the kiosk.

List

Now that your tokenized asset is placed and locked within your kiosk, you can proceed to list it for sale.

In the project's file listItem.ts, found in the directory setup/src/functions, you can adjust the code to specify the desired asset for listing.

Code snippet to be modified:

const SALE_PRICE = '100000';
  kioskTx
    .list({
        itemId,
        itemType,
        price: SALE_PRICE,
    })
    .finalize();

By running the command npm run call list, your tokenized asset is listed and made available for sale.

Purchase

When a user intends to purchase an item, it needs to be listed for sale. After the user selects the item to buy, they are required to modify the following snippet of code found in the file purchaseItem.ts, located in the setup/src/functions directory.

const item = {
    itemType: tokenizedAssetType,
    itemId: tokenized_asset ?? tokenizedAssetID,
    price: "100000",
    sellerKiosk: targetKioskId,
};

Apart from specifying the item and its type, the buyer must set the specific price and the seller's kiosk ID to execute the purchase transaction successfully, accomplished by running npm run call purchase.

Join

When you execute the command npm run call join, two specified tokenized assets of the FT type are merged together. Before running the command, make sure that the fields FT1 and FT2 within your .env file are populated with the objects you intend to merge.

Burn

When you intend to burn a tokenized asset, execute the command npm run call burn. Following this action, the specified asset is destroyed. Before running the command, make sure that the field TOKENIZED_ASSET within your .env file is populated with the object you intend to burn.

Get Balance

By executing the command npm run call get-balance, you can retrieve the balance value associated with the specified tokenized asset.

Get Supply

By executing the command npm run call get-supply, you can retrieve the value representing the current circulating supply of the asset.

Get Total Supply

Custom Indexer
You can build custom indexers using the Sui micro-data ingestion framework. To create an indexer, you subscribe to a checkpoint stream with full checkpoint content. This stream can be one of the publicly available streams from Mysten Labs, one that you set up in your local environment, or a combination of the two.

Establishing a custom indexer helps improve latency, allows pruning the data of your Sui Full node, and provides efficient assemblage of checkpoint data.

Interface and data format
To use the framework, implement a basic interface:

#[async_trait]
trait Worker: Send + Sync {
    async fn process_checkpoint(&self, checkpoint: CheckpointData) -> Result<()>;
}

In this example, the CheckpointData struct represents full checkpoint content. The struct contains checkpoint summary and contents, as well as detailed information about each individual transaction. The individual transaction data includes events and input/output objects. The full definition for this content is in the full_checkpoint_content.rs file of the sui-types crate.

Checkpoint stream sources
Data ingestion for your indexer supports several checkpoint stream sources.

Remote reader
The most straightforward stream source is to subscribe to a remote store of checkpoint contents. Mysten Labs provides the following buckets:

Testnet: https://checkpoints.testnet.sui.io
Mainnet: https://checkpoints.mainnet.sui.io
External
 Postgres
 BigQuery
 S3
 Cloud storage(S3, GCP)

Indexer
daemon
 Progress store
Local reader
Colocate the data ingestion daemon with a Full node and enable checkpoint dumping on the latter to set up a local stream source. After enabling, the Full node starts dumping executed checkpoints as files to a local directory, and the data ingestion daemon subscribes to changes in the directory through an inotify-like mechanism. This approach allows minimizing ingestion latency (checkpoint are processed immediately after a checkpoint executor on a Full node) and getting rid of dependency on an externally managed bucket.

To enable, add the following to your Full node configuration file:

checkpoint-executor-config:
  checkpoint-execution-max-concurrency: 200
  local-execution-timeout-sec: 30
  data-ingestion-dir: <path to a local directory>

Sui
Cloud storage
 Postgres
 BigQuery
 S3
 Full node
 Local directory

Indexer
daemon
 Progress store
Hybrid mode
Specify both a local and remote store as a fallback to ensure constant data flow. The framework always prioritizes locally available checkpoint data over remote data. It's useful when you want to start utilizing your own Full node for data ingestion but need to partially backfill historical data or just have a failover.

Examples
The Sui data ingestion framework provides a helper function to quickly bootstrap an indexer workflow.

struct CustomWorker;

#[async_trait]
impl Worker for CustomWorker {
    async fn process_checkpoint(&self, checkpoint: CheckpointData) -> Result<()> {
        // custom processing logic
        ...
        Ok(())
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    let (executor, term_sender) = setup_single_workflow(
        CustomWorker,
        "https://checkpoints.mainnet.sui.io".to_string(),
        0, /* initial checkpoint number */
        5, /* concurrency */
        None, /* extra reader options */
    ).await?;
    executor.await?;
    Ok(())
}

This is suitable for setups with a single ingestion pipeline where progress tracking is managed outside of the framework.

For more complex setups, refer to the following example:

struct CustomWorker;

#[async_trait]
impl Worker for CustomWorker {
    async fn process_checkpoint(&self, checkpoint: CheckpointData) -> Result<()> {
        // custom processing logic
        ...
        Ok(())
    }
}

#[tokio::main]
async fn main() -> Result<()> {
  let (exit_sender, exit_receiver) = oneshot::channel();
  let metrics = DataIngestionMetrics::new(&Registry::new());
  let progress_store = FileProgressStore::new("path_to_file");
  let mut executor = IndexerExecutor::new(progress_store, 1 /* number of workflow types */, metrics);
  let worker_pool = WorkerPool::new(CustomWorker, "custom worker", 100);
  executor.register(worker_pool).await?;
  executor.run(
      PathBuf::from("..."), // path to a local directory
      Some("https://checkpoints.mainnet.sui.io".to_string()),
      vec![], // optional remote store access options
      exit_receiver,
  ).await?;
  Ok(())
}


Let's highlight a couple lines of code:

let worker_pool = WorkerPool::new(CustomWorker, "custom worker", 100);
executor.register(worker_pool).await?;

The data ingestion executor can run multiple workflows simultaneously. For each workflow, you need to create a separate worker pool and register it in the executor. The WorkerPool requires an instance of the Worker trait, the name of the workflow (which is used for tracking the progress of the flow in the progress store and metrics), and concurrency.

The concurrency parameter specifies how many threads the workflow uses. Having a concurrency value greater than 1 is helpful when tasks are idempotent and can be processed in parallel and out of order. The executor only updates the progress/watermark to a certain checkpoint when all preceding checkpoints are processed.

Find more examples of custom ingestion pipelines in the Sui repository:

Sui data ingestion daemon that runs internal pipelines.
Sui Name Service's custom indexer.

On-Chain Randomness
Generating pseudo-random values in Move is similar to solutions in other languages. A Move function can create a new instance of RandomGenerator and use it for generating random values of different types, for example, generate_u128(&mut generator), generate_u8_in_range(&mut generator, 1, 6), or,

entry fun roll_dice(r: &Random, ctx: &mut TxContext): Dice {
  let generator = new_generator(r, ctx); // generator is a PRG
  Dice { value: random::generate_u8_in_range(&mut generator, 1, 6) }
}

Random has a reserved address 0x8. See random.move for the Move APIs for accessing randomness on Sui.

NOTE
Although Random is a shared object, it is inaccessible for mutable operations, and any transaction attempting to modify it fails.

Having access to random numbers is only one part of designing secure applications, you should also pay careful attention to how you use that randomness. To securely access randomness:

Define your function as (private) entry.
Prefer generating randomness using function-local RandomGenerator.
Make sure that the "unhappy path" of your function does not charge more gas than the "happy path".
Use (non-public) entry functions
While composition is very powerful for smart contracts, it opens the door to attacks on functions that use randomness. Consider for example the next module:

module games::dice {
...
  struct GuessedCorrectly has drop { ... };

  /// If you guess correctly the output you get a GuessedCorrectly object.
  public fun play_dice(guess: u8, fee: Coin<SUI>, r: &Random, ctx: &mut TxContext): Option<GuessedCorrectly> {
    // Pay for the turn
    assert!(coin::value(&fee) == 1000000, EInvalidAmount);
    transfer::public_transfer(fee, CREATOR_ADDRESS);
    // Roll the dice
    let generator = new_generator(r, ctx);
    if (guess == random::generate_u8_in_range(&mut generator, 1, 6)) {
      option::some(GuessedCorrectly {})
    } else {
      option::none()
    }
  }
...
}


An attacker can deploy the next function:

public fun attack(guess: u8, r: &Random, ctx: &mut TxContext): GuessedCorrectly {
  let output = dice::play_dice(guess, r, ctx);
  option::extract(output) // reverts the transaction if roll_dice returns option::none()
}

The attacker can now call attack with a guess, and always revert the fee transfer if the guess is incorrect.

To protect against composition attacks in this example, define play_dice as a private entry function so functions from other modules cannot call it, such as,

entry fun play_dice(guess: u8, fee: Coin<SUI>, r: &Random, ctx: &mut TxContext): Option<GuessedCorrectly> {
  ...
}


NOTE
The Move compiler enforces this behavior by rejecting public functions with Random as an argument.

Programmable transaction block (PTB) restrictions
A similar attack to the one previously described involves PTBs even when play_dice is defined as a private entry function. For example, consider the entry play_dice(guess: u8, fee: Coin<SUI>, r: &Random, ctx: &mut TxContext): Option<GuessedCorrectly> { … } function defined earlier, the attacker can publish the function

public fun attack(output: Option<GuessedCorrectly>): GuessedCorrectly {
  option::extract(output)
}

and send a PTB with commands play_dice(...), attack(Result(0)) where Result(0) is the output of the first command. As before, the attack takes advantage of the atomic nature of PTBs and always reverts the entire transaction if the guess was incorrect, without paying the fee. Sending multiple transactions can repeat the attck, each one executed with different randomness and reverted if the guess is incorrect.

NOTE
To protect against PTB-based composition attacks, Sui rejects PTBs that have commands that are not TransferObjects or MergeCoins following a MoveCall command that uses Random as an input.

Instantiating RandomGenerator
RandomGenerator is secure as long as it's created by the consuming module. If passed as an argument, the caller might be able to predict the outputs of that RandomGenerator instance (for example, by calling bcs::to_bytes(&generator) and parsing its internal state).

NOTE
The Move compiler enforces this behavior by rejecting public functions with RandomGenerator as an argument.

Limited resources and Random dependent flows
Developers should be aware that some resources that are available to transactions are limited. If a function that reads Random consumes more resources in the unhappy path flow than in the happy path flow, an attacker can use that difference to revert the transaction in the unhappy flow as previously demonstrated. Concretely, gas is such a resource. Consider the following code:

entry fun play(r: &Random, payment: Coin<SUI>, ...) {
  ...
  let generator = new_generator(r, ctx);
  let win = random::generate_bool(generator);
  if (win) { // happy flow
    ... cheap computation ...
  } else {
    ... very expensive computation ...
  }
}

Observe that the gas costs of a transaction that calls play depends on the value of win - An attacker could call this function with a gas object that has enough balance to cover the happy flow but not the unhappy one, resulting in it either winning or reverting the transaction (but never losing the payment).

In many cases this is not an issue, like when selecting a raffle winner, lottery numbers, or a random NFT. However, in the cases where it can be problematic, you can do one of the following:

Write the function in a way that the happy flow consumes more gas than the unhappy one.
Keep in mind that external functions or native ones can change in the future, potentially resulting in different costs compared to the time you conducted your tests.
Use profile-transaction on Testnet transactions to verify the costs of different flows.
Split the logic in two: one function that fetches a random value and stores it in an object, and another function that reads that stored value and completes the operation. The latter function might indeed fail, but now the random value is fixed and cannot be modified using repeated calls.
See random_nft for examples.

Other limited resources per transaction are:

The number of new objects.
The number of objects that can be used (including dynamic fields).
Accessing Random from TypeScript
If you want to call roll_dice(r: &Random, ctx: &mut TxContext) in module example, use the following code snippet:

const txb = new Transaction();
txb.moveCall({
  target: "${PACKAGE_ID}::example::roll_dice",
  arguments: [txb.object('0x8')]
});
...

Related Links
Sui Framework Reference
random.move

Randomness NFT example
Raffle example


By executing the command npm run call get-total-supply, you can retrieve the value representing the current circulating supply of the asset.

App Examples
The ever-growing number of examples in this section showcase packages for the Sui blockchain. Extract techniques used in these examples to apply to your own Sui projects as they are written by Sui and Move experts.

CAUTION
Use dedicated nodes/shared services rather than public endpoints for production apps. The public endpoints maintained by Mysten Labs (fullnode.<NETWORK>.sui.io:443) are rate-limited, and support only 100 requests per 30 seconds. Do not use public endpoints in production applications with high traffic volume.

You can either run your own Full nodes, or outsource this to a professional infrastructure provider (preferred for apps that have high traffic). You can find a list of reliable RPC endpoint providers for Sui on the Sui Dev Portal using the Node Service tag.

Examples
Sui is dedicated to providing a wide range of examples to guide you in proper programming techniques for the Sui blockchain. This list will continue to grow, so check back often.

Blackjack: This example demonstrates the logic behind an on-chain version of the popular casino card game, Blackjack.
Coin Flip: The Coin Flip app demonstrates on-chain randomness.
Distributed Counter: An end-to-end example that creates a basic decentralized counter that anyone can increment, but only the object owner can reset it. The example includes Move code to create the package and leverages the Sui TypeScript SDK to provide a basic frontend.
Plinko: This example puts the classic Plinko game on chain, demonstrating use of cryptography-based strategies to create a fair and transparent game of chance.
Tic-tac-toe: Three implementations of the classic tic-tac-toe game on the Sui network to demonstrate different approaches to user interaction.
Trustless Swap: This example demonstrates trustless swaps on the Sui blockchain using a shared object as an escrow account.
Weather Oracle: The Sui Weather Oracle demonstrates how to create a basic weather oracle that provides real-time weather data.
Reviews Rating: This example demonstrates implementing a reviews-rating platform for the food service industry on Sui.


Blackjack
The following documentation goes through an example implementation of the popular casino game blackjack on Sui. This guide walks through its components, providing a detailed look at the module's functions, structures, constants, and their significance in the overall gameplay mechanism.

A deployed version of the blackjack game is online at Mysten Blackjack.

Building an on-chain blackjack game shares a lot of similarities with a coin flip game. This example covers the smart contracts (Move modules), backend logic (using serverless functions), and frontend logic.

INFO
For more details on building a backend and deploying to Sui, check out the Coin Flip app example.

You can also find the full repository for this example here.

Gameplay
In this single-player version of blackjack, the player competes against a dealer, which is automated by the system. The dealer is equipped with a public BLS key that plays a central role in the game's mechanics. The dealer's actions are triggered by HTTP requests to serverless functions. Players generate randomness for the game by interacting with their mouse on the screen, after which they place their bet to start the game. Upon initiating the game, a request is made to the backend (dealer), which processes it by signing and subsequently dealing two cards to the player and one to themselves.

The player has the option to 'Hit' or 'Stand.' Selecting 'Stand' triggers the dealer to draw cards until the total reaches 17 or higher. After the dealer stops, the smart contract steps in to compare the totals and declare the winner. On the other hand, choosing 'Hit' prompts the dealer to draw an additional card for the player.

Note that more complex blackjack rules, such as splitting, are considered out of scope for this example, and are therefore not implemented.

Smart contracts
Game module
The single_player_blackjack.move module includes several constants that define game statuses and help track the game's progress:

IN_PROGRESS
PLAYER_WON_STATUS
HOUSE_WON_STATUS
TIE_STATUS
There are also constants for error handling, such as EInvalidBlsSig, EInsufficientBalance, and others, ensuring robust game mechanics.

Structs like GameCreatedEvent, GameOutcomeEvent, and HitDoneEvent capture the various events and actions within a game. The HitRequest and StandRequest structs ensure that a move (hit/stand) can be performed by the house only if the player has already requested it. HouseAdminCap and HouseData are crucial for maintaining the house's data, including balance and public key, while the Game struct contains all the necessary information about each game, such as player data, cards, and the current status.

The module's functions can be broadly categorized into initialization, game management, and utility functions. The init function sets up the house admin capability, while initialize_house_data prepares the house for the game by setting up the balance and public key. place_bet_and_create_game is the entry point for players to start a new game, involving a bet and random input. The functions first_deal, hit, and stand govern the core gameplay, handling the dealing of cards and player choices.

Utility functions like get_next_random_card and get_card_sum are essential for the game's mechanics, generating random cards and calculating hand values. The module also includes accessors for retrieving various pieces of game and house data.

For testing purposes, the module provides special functions like get_house_admin_cap_for_testing, player_won_post_handling_for_test and house_won_post_handling_for_test, ensuring that developers can thoroughly test the game mechanics and house data handling.

Counter module
The next module, counter_nft.move, introduces the Counter NFT, a key component in the game's mechanics. It serves as the verifiable random function (VRF) input, ensuring uniqueness in each game. The Counter NFT's value increases after each use, maintaining its distinctiveness for every new request. For first-time players, the creation of a Counter NFT is mandatory. To enhance user experience, the user interface can automate this process by integrating the Counter NFT's creation with the game initiation in a single transaction block. This seamless integration simplifies the process for the player, allowing them to focus on the gameplay. This counter serves the same purpose as the one in the Coin Flip example.

Backend
The backend is used for all the transactions that are executed by the dealer. The backend can be completely stateless, and for that reason serverless functions are utilized. As a result, the corresponding code lies under the app/src/app/api/ directory.

Directories structure
The backend code is split in the following sub directories:

games/: The main code of the backend endpoints. Each file that is named route.ts is served as an endpoint, in the path defined by the project structure (see Route Segments on NextJS App Router for details)
health/: A simple healthcheck endpoint to check the API availability
helpers/: Multiple helper functions used in various endpoints
services/: The core logic of the backend, that signs and executes the transactions on the Sui blockchain
utils/: Reusable methods for signing the transactions as the dealer, and sponsoring them with Shinami, to avoid gas coins equivocation
High-Level endpoints specification
HTTP Method	Path	Description	Request Body
GET	/api/health	A simple healthcheck endpoint to check the API availability	txDigest
POST	/api/games/{id}/deal	Executes the initial deal transaction after the game creation	txDigest
POST	/api/games/{id}/hit	Executes a hit move	txDigest, id of corresponding HitRequest object
POST	/api/games/{id}/stand	Executes a stand move	txDigest, id of corresponding StandRequest object
Need of usage of waitForTransaction
An interesting aspect of developing a dApp on Sui, that is coupled to using a full node with/without a load balancer, and requires attention by the developer, is the occurrence of read-after-write and write-after-write cases.

Initial deal transaction
As an example, in the blackjack game, just after the create-game transaction that the user executes, the dealer executes the initial-deal transaction. This one accepts an argument and modifies the game object, meaning that you are using an object that was just created.

To ensure that the game object is available in the Full node that the dealer is using, we need to call waitForTransaction after the create-game transaction.

Hit and stand transactions
In the same way, every time you re-fetch the game object in the frontend, make sure that the previous transaction that modified the game object is already available in the Full node.

This leads to the need of exchanging the txDigest between the frontend and the backend, and use waitForTransaction on each write-after-write or read-after-write case.

Frontend
The page component, a central element of the blackjack game's frontend module, is structured to create an interactive and responsive gaming experience. Written in React, it integrates several features and functions to handle the game's logic and user interactions effectively.

Directories structure
The frontend is a NextJS project, that follows the NextJS App Router project structure. The main code of the frontend lies under the app/src/ directory. The main sub-directories are:

app/: The main code of the pages and the API endpoints.
components/: The reusable components of the app, organized in sub-directories.
hooks/: The custom hooks used in the app.
helpers/, utils/, lib/: Multiple helper functions and utilities.
types/: The types/interfaces used in the app.
styles/: The global css files to style our app.
Components and custom hooks for state management
Custom Hooks: To keep the code as structured as possible, multiple custom hooks are utilized to manage the complex state of the game board at each step. The useBlackjackGame custom hook encapsulates the game state and logic, exposing all the required information (with fields such as game, isInitialDealLoading), and the required functionality (with methods such as handleCreateGame and handleHit) to display and play the game. Multiple additional custom hooks, such as useCreateBlackjackGame, and useMakeMoveInBlackjackGame are encapsulating their own piece of state and logic to make the code readable and maintainable.

Component for Game Initialization: The StartGame component is implemented to facilitate the creation of a new game. It renders the CollectMouseRandomness to capture the randomness and uses the handleCreateGame function of the useBlackjackGame hook to execute the create-game transaction.

Randomness Generation: Fair game outcomes are also ensured by the CollectMouseRandomness component. This component is using the useMouseRandomness custom hook, and is in charge of capturing some user's mouse movements and generating a random bytes array. This array is converted to a hexadecimal string (randomness) and used in the create-game transaction.

Card Displaying and Management: The DealerCards and the PlayerCards components are used to display the total points and the cards owned by the dealer and the player respectively.

Game Actions: The GameActions component is used to display the Hit and Stand buttons, and trigger the corresponding actions, as they are exported by the useBlackjackGame hook to execute the corresponding transactions.

BlackjackBanner: The BlackjackBanner component is used as a custom view to display when the player wins with a blackjack.

Comparison: Blackjack and Coin Flip
Similarities
Blockchain-Based Logic: Both games are built on Sui, leveraging its capabilities for decentralized applications. The core game logic for each resides in Move modules, ensuring secure and verifiable gameplay.

State Management: In both games, state management is crucial. For blackjack, this involves managing the player and dealer's hands and scores using React state hooks. In Satoshi Coin Flip, the state is managed through Move structs like HouseData, which track the house's balance and other game-related details.

Randomness and Fair Play: Both games emphasize randomness for fairness. Blackjack uses a Counter NFT and player mouse movements to generate randomness, while Satoshi Coin Flip only uses a Counter NFT as a unique input for the Verifiable Random Function (VRF) in each game.

Smart Contract Interactions: Each game involves smart contract interactions for game actions like placing bets, dealing cards (Blackjack), or making guesses (Coin Flip). These interactions are crucial for executing the game's logic on the blockchain.

Differences
Game Mechanics and Complexity: Blackjack is a more complex game with multiple actions (hit, stand, deal) and state updates, requiring a more dynamic frontend. In contrast, Satoshi Coin Flip has a simpler mechanic centered around a single bet and guess outcome.

User Interface (UI) Complexity: The Blackjack game involves a more intricate UI to display cards, manage game states, and player interactions. Satoshi Coin Flip, being simpler in gameplay, requires a less complex UI.

Backend Processing: In Blackjack, the dealer is automated (the machine), and the player's actions directly influence game outcomes. In the Coin Flip game, the house (smart contract) plays a more passive role, primarily in initializing and finalizing the game based on the player's guess.

Module Structure and Focus: The Blackjack game focuses more on frontend interactions and real-time updates. The Satoshi Coin Flip game, delves into backend logic, with structures like HouseCap and house_data for initializing and managing game data securely on the blockchain.

Multi-Version Implementation: The Satoshi Coin Flip game mentions two versions – one susceptible to MEV attacks and another that is resistant, indicating a focus on security and user experience variations. Such variations aren't implemented in Blackjack.


Coin Flip
This guide demonstrates writing a module (smart contract) in Move, deploying it on Devnet, and adding a TypeScript frontend to communicate with the module.

Satoshi Coin Flip is a dApp that utilizes verifiable random functions (VRFs) to create a fair coin game on the Sui blockchain. The user (human) plays against the house (module) and places a bet on either heads or tails. The user then either receives double their bet, or gets nothing, depending on the outcome of the game.

This guide assumes you have installed Sui and understand Sui fundamentals.

Backend
As with all Sui dApps, a Move package on chain powers the logic of Satoshi Coin Flip. The following instruction walks you through creating and publishing the module.

House module
This example uses several modules to create a package for the Satoshi Coin Flip game. The first module is house_data.move. You need to store the game’s data somewhere, and in this module you create a shared object for all house data.

INFO
The full source code for the Move modules, including comments and on overview of its cryptography, is available at the Satoshi Coin Flip repository.

Before you get started, you must initialize a Move package. Open a terminal or console in the directory you want to store the example and run the following command to create an empty package with the name satoshi_flip:

sui move new satoshi_flip

With that done, it's time to jump into some code. Create a new file in the sources directory with the name house_data.move and populate the file with the following code:

house_data.move
module satoshi_flip::house_data {

    use sui::balance::{Self, Balance};
    use sui::sui::SUI;
    use sui::coin::{Self, Coin};
    use sui::package::{Self};

    // Error codes
    const ECallerNotHouse: u64 = 0;
    const EInsufficientBalance: u64 = 1;


There are few details to take note of in this code:

The first line declares the module name as house_data within the package satoshi_flip.
Seven lines begin with the use keyword, which enables this module to use types and functions declared in other modules (in this case, they are all coming from the Sui standard library).
Two error codes. These codes are used in assertions and unit tests to ensure that the program is running as intended.
Next, add some more code to this module:

house_data.move
    /// Configuration and Treasury object, managed by the house.
    public struct HouseData has key {
        id: UID,
        balance: Balance<SUI>,
        house: address,
        public_key: vector<u8>,
        max_stake: u64,
        min_stake: u64,
        fees: Balance<SUI>,
        base_fee_in_bp: u16
    }

    /// A one-time use capability to initialize the house data; created and sent
    /// to sender in the initializer.
    public struct HouseCap has key {
        id: UID
    }

    /// Used as a one time witness to generate the publisher.
    public struct HOUSE_DATA has drop {}

    fun init(otw: HOUSE_DATA, ctx: &mut TxContext) {
        // Creating and sending the Publisher object to the sender.
        package::claim_and_keep(otw, ctx);

        // Creating and sending the HouseCap object to the sender.
        let house_cap = HouseCap {
            id: object::new(ctx)
        };

        transfer::transfer(house_cap, ctx.sender());
    }

The first struct, HouseData, stores the most essential information pertaining to the game.
The second struct, HouseCap, is a capability that initializes the house data.
The third struct, HOUSE_DATA, is a one-time witness that ensures only a single instance of this HouseData ever exists.
The init function creates and sends the Publisher and HouseCap objects to the sender.
So far, you've set up the data structures within the module. Now, create a function that initializes the house data and shares the HouseData object:

house_data.move
    public fun initialize_house_data(house_cap: HouseCap, coin: Coin<SUI>, public_key: vector<u8>, ctx: &mut TxContext) {
        assert!(coin.value() > 0, EInsufficientBalance);

        let house_data = HouseData {
            id: object::new(ctx),
            balance: coin.into_balance(),
            house: ctx.sender(),
            public_key,
            max_stake: 50_000_000_000, // 50 SUI, 1 SUI = 10^9.
            min_stake: 1_000_000_000, // 1 SUI.
            fees: balance::zero(),
            base_fee_in_bp: 100 // 1% in basis points.
        };

        let HouseCap { id } = house_cap;
        object::delete(id);

        transfer::share_object(house_data);
    }


With the house data initialized, you also need to add some functions that enable some important administrative tasks for the house to perform:

house_data.move
    public fun top_up(house_data: &mut HouseData, coin: Coin<SUI>, _: &mut TxContext) {
        coin::put(&mut house_data.balance, coin)
    }

    public fun withdraw(house_data: &mut HouseData, ctx: &mut TxContext) {
        // Only the house address can withdraw funds.
        assert!(ctx.sender() == house_data.house(), ECallerNotHouse);

        let total_balance = balance(house_data);
        let coin = coin::take(&mut house_data.balance, total_balance, ctx);
        transfer::public_transfer(coin, house_data.house());
    }

    public fun claim_fees(house_data: &mut HouseData, ctx: &mut TxContext) {
        // Only the house address can withdraw fee funds.
        assert!(ctx.sender() == house_data.house(), ECallerNotHouse);

        let total_fees = fees(house_data);
        let coin = coin::take(&mut house_data.fees, total_fees, ctx);
        transfer::public_transfer(coin, house_data.house());
    }

    public fun update_max_stake(house_data: &mut HouseData, max_stake: u64, ctx: &mut TxContext) {
        // Only the house address can update the base fee.
        assert!(ctx.sender() == house_data.house(), ECallerNotHouse);

        house_data.max_stake = max_stake;
    }

    public fun update_min_stake(house_data: &mut HouseData, min_stake: u64, ctx: &mut TxContext) {
        // Only the house address can update the min stake.
        assert!(ctx.sender() == house_data.house(), ECallerNotHouse);

        house_data.min_stake = min_stake;
    }


All of these functions contain an assert! call that ensures only the house can call them:

top_up: Add to the balance of the house to ensure that there is enough SUI for future games.
withdraw: Withdraw the entire balance of the house object.
claim_fees: Withdraw the accumulated fees of the house object.
update_max_stake, update_min_stake: Update the maximum and minimum stake allowed in the game, respectively.
You have established the data structure of this module, but without the appropriate functions this data is not accessible. Now add helper functions that return mutable references, read-only references, and test-only functions:

house_data.move
    // --------------- Mutable References ---------------

    public(package) fun borrow_balance_mut(house_data: &mut HouseData): &mut Balance<SUI> {
        &mut house_data.balance
    }

    public(package) fun borrow_fees_mut(house_data: &mut HouseData): &mut Balance<SUI> {
        &mut house_data.fees
    }

    public(package) fun borrow_mut(house_data: &mut HouseData): &mut UID {
        &mut house_data.id
    }

    // --------------- Read-only References ---------------

    /// Returns a reference to the house id.
    public(package) fun borrow(house_data: &HouseData): &UID {
        &house_data.id
    }

    /// Returns the balance of the house.
    public fun balance(house_data: &HouseData): u64 {
        house_data.balance.value()
    }

    /// Returns the address of the house.
    public fun house(house_data: &HouseData): address {
        house_data.house
    }

    /// Returns the public key of the house.
    public fun public_key(house_data: &HouseData): vector<u8> {
        house_data.public_key
    }

    /// Returns the max stake of the house.
    public fun max_stake(house_data: &HouseData): u64 {
        house_data.max_stake
    }

    /// Returns the min stake of the house.
    public fun min_stake(house_data: &HouseData): u64 {
        house_data.min_stake
    }

    /// Returns the fees of the house.
    public fun fees(house_data: &HouseData): u64 {
        house_data.fees.value()
    }

    /// Returns the base fee.
    public fun base_fee_in_bp(house_data: &HouseData): u16 {
        house_data.base_fee_in_bp
    }

    // --------------- Test-only Functions ---------------

    #[test_only]
    public fun init_for_testing(ctx: &mut TxContext) {
        init(HOUSE_DATA {}, ctx);
    }
}


And with that, your house_data.move code is complete.

Counter module
In the same sources directory, now create a file named counter_nft.move. A Counter object is used as the VRF input for every game that a player plays. First, populate the file with the following:

counter_nft.move
module satoshi_flip::counter_nft {

    use sui::bcs::{Self};

    public struct Counter has key {
        id: UID,
        count: u64,
    }

    entry fun burn(self: Counter) {
        let Counter { id, count: _ } = self;
        object::delete(id);
    }

    public fun mint(ctx: &mut TxContext): Counter {
        Counter {
            id: object::new(ctx),
            count: 0
        }
    }

    public fun transfer_to_sender(counter: Counter, ctx: &mut TxContext) {
        transfer::transfer(counter, tx_context::sender(ctx));
    }

This might look familiar from the house module. You set the module name, import functions from the standard library, and initialize the Counter object. The Counter object has the key ability, but does not have store - this prevents the object from being transferable.

In addition, you create mint and transfer_to_sender functions used when the game is set up to create the Counter object (with an initial count of 0) and transfer the object to the sender of the transaction. And finally a burn function to allow deletion of the Counter.

You have a Counter object, as well as functions that initialize and burn the object, but you need a way to increment the counter. Add the following code to the module:

counter_nft.move
    public fun get_vrf_input_and_increment(self: &mut Counter): vector<u8> {
        let mut vrf_input = object::id_bytes(self);
        let count_to_bytes = bcs::to_bytes(&count(self));
        vrf_input.append(count_to_bytes);
        self.increment();
        vrf_input
    }

    public fun count(self: &Counter): u64 {
        self.count
    }

    fun increment(self: &mut Counter) {
        self.count = self.count + 1;
    }

    #[test_only]
    public fun burn_for_testing(self: Counter) {
        self.burn();
    }
}

The get_vrf_input_and_increment function is the core of this module. The function takes a mutable reference to the Counter object that the mint function creates, then appends the Counter object's current count to its ID and returns the result as a vector<u8>. The function then calls the internal increment function to increment the count by one.

This code also adds a count function that returns the current count, and a test-only function that calls the burn function.

Game module
Lastly, you need a game module and object that can create a new game, distribute funds after the game, and potentially cancel games. Because this is a one-player game, create an address-owned object rather than a shared object.

Create the game module. In the sources directory, create a new file called single_player_satoshi.move and populate with the following:

single_player_satoshi.move
module satoshi_flip::single_player_satoshi {
    use std::string::String;

    use sui::coin::{Self, Coin};
    use sui::balance::Balance;
    use sui::sui::SUI;
    use sui::bls12381::bls12381_min_pk_verify;
    use sui::event::emit;
    use sui::hash::{blake2b256};
    use sui::dynamic_object_field::{Self as dof};

    use satoshi_flip::counter_nft::Counter;
    use satoshi_flip::house_data::HouseData;

    const EPOCHS_CANCEL_AFTER: u64 = 7;
    const GAME_RETURN: u8 = 2;
    const PLAYER_WON_STATE: u8 = 1;
    const HOUSE_WON_STATE: u8 = 2;
    const CHALLENGED_STATE: u8 = 3;
    const HEADS: vector<u8> = b"H";
    const TAILS: vector<u8> = b"T";

    const EStakeTooLow: u64 = 0;
    const EStakeTooHigh: u64 = 1;
    const EInvalidBlsSig: u64 = 2;
    const ECanNotChallengeYet: u64 = 3;
    const EInvalidGuess: u64 = 4;
    const EInsufficientHouseBalance: u64 = 5;
    const EGameDoesNotExist: u64 = 6;

    public struct NewGame has copy, drop {
        game_id: ID,
        player: address,
        vrf_input: vector<u8>,
        guess: String,
        user_stake: u64,
        fee_bp: u16
    }

    public struct Outcome has copy, drop {
        game_id: ID,
        status: u8
    }

This code follows the same pattern as the others. First, you include the respective imports, although this time the imports are not only from the standard library but also include modules created previously in this example. You also create several constants (in upper case), as well as constants used for errors (Pascal case prefixed with E).

Lastly in this section, you also create structs for two events to emit. Indexers consume emitted events, which enables you to track these events through API services, or your own indexer. In this case, the events are for when a new game begins (NewGame) and for the outcome of a game when it has finished (Outcome).

Add a struct to the module:

single_player_satoshi.move
    public struct Game has key, store {
        id: UID,
        guess_placed_epoch: u64,
        total_stake: Balance<SUI>,
        guess: String,
        player: address,
        vrf_input: vector<u8>,
        fee_bp: u16
    }

The Game struct represents a single game and all its information, including the epoch the player placed the bet (guess_placed_epoch), bet (total_stake), guess, address of the player, vrf_input, and the fee the house collects (fee_bp).

Now take a look at the main function in this game, finish_game:

single_player_satoshi.move
    public fun finish_game(game_id: ID, bls_sig: vector<u8>, house_data: &mut HouseData, ctx: &mut TxContext) {
        // Ensure that the game exists.
        assert!(game_exists(house_data, game_id), EGameDoesNotExist);

        let Game {
            id,
            guess_placed_epoch: _,
            mut total_stake,
            guess,
            player,
            vrf_input,
            fee_bp
        } = dof::remove<ID, Game>(house_data.borrow_mut(), game_id);

        object::delete(id);

        // Step 1: Check the BLS signature, if its invalid abort.
        let is_sig_valid = bls12381_min_pk_verify(&bls_sig, &house_data.public_key(), &vrf_input);
        assert!(is_sig_valid, EInvalidBlsSig);

        // Hash the beacon before taking the 1st byte.
        let hashed_beacon = blake2b256(&bls_sig);
        // Step 2: Determine winner.
        let first_byte = hashed_beacon[0];
        let player_won = map_guess(guess) == (first_byte % 2);

        // Step 3: Distribute funds based on result.
        let status = if (player_won) {
            // Step 3.a: If player wins transfer the game balance as a coin to the player.
            // Calculate the fee and transfer it to the house.
            let stake_amount = total_stake.value();
            let fee_amount = fee_amount(stake_amount, fee_bp);
            let fees = total_stake.split(fee_amount);
            house_data.borrow_fees_mut().join(fees);

            // Calculate the rewards and take it from the game stake.
            transfer::public_transfer(total_stake.into_coin(ctx), player);
            PLAYER_WON_STATE
        } else {
            // Step 3.b: If house wins, then add the game stake to the house_data.house_balance (no fees are taken).
            house_data.borrow_balance_mut().join(total_stake);
            HOUSE_WON_STATE
        };

        emit(Outcome {
            game_id,
            status
        });
    }


First, the function makes sure the Game object exists, then deletes it, as after the game concludes the metadata is no longer needed. Freeing up unnecessary storage is not only recommended, but incentivized through rebates on storage fees.
In step 1, the function checks to see if the BLS signature is valid. This is to ensure the game is truly random.
In step 2, the function checks to see if the player’s guess, heads (0) or tails (1), is the same as that of the house. This is done by taking the first byte of the randomized vector and checking to see if it’s divisible by two. If it is, it is heads, if it is not, it is tails.
In step 3, if the player won, meaning the player’s guess matched the results of the house, the logic transfers fees from the stake to the house, then distributes the rest of the principle plus an equal amount from the house’s balance back to the player. If the player loses, the logic transfers the entire stake to the house, and takes no fees.
Lastly, the game emits its outcome as an event.
Now add a function that handles game disputes:

single_player_satoshi.move
    public fun dispute_and_win(house_data: &mut HouseData, game_id: ID, ctx: &mut TxContext) {
        // Ensure that the game exists.
        assert!(game_exists(house_data, game_id), EGameDoesNotExist);

        let Game {
            id,
            guess_placed_epoch,
            total_stake,
            guess: _,
            player,
            vrf_input: _,
            fee_bp: _
        } = dof::remove(house_data.borrow_mut(), game_id);

        object::delete(id);

        let caller_epoch = ctx.epoch();
        let cancel_epoch = guess_placed_epoch + EPOCHS_CANCEL_AFTER;
        // Ensure that minimum epochs have passed before user can cancel.
        assert!(cancel_epoch <= caller_epoch, ECanNotChallengeYet);

        transfer::public_transfer(total_stake.into_coin(ctx), player);

        emit(Outcome {
            game_id,
            status: CHALLENGED_STATE
        });
    }


This function, dispute_and_win, ensures that no bet can live in “purgatory”. After a certain amount of time passes, the player can call this function and get all of their funds back.

The rest of the functions are accessors and helper functions used to retrieve values, check if values exist, initialize the game, and so on:

single_player_satoshi.move
    // --------------- Read-only References ---------------

    public fun guess_placed_epoch(game: &Game): u64 {
        game.guess_placed_epoch
    }

    public fun stake(game: &Game): u64 {
        game.total_stake.value()
    }

    public fun guess(game: &Game): u8 {
        map_guess(game.guess)
    }

    public fun player(game: &Game): address {
        game.player
    }

    public fun vrf_input(game: &Game): vector<u8> {
        game.vrf_input
    }

    public fun fee_in_bp(game: &Game): u16 {
        game.fee_bp
    }

    // --------------- Helper functions ---------------

    /// Public helper function to calculate the amount of fees to be paid.
    public fun fee_amount(game_stake: u64, fee_in_bp: u16): u64 {
        ((((game_stake / (GAME_RETURN as u64)) as u128) * (fee_in_bp as u128) / 10_000) as u64)
    }

    /// Helper function to check if a game exists.
    public fun game_exists(house_data: &HouseData, game_id: ID): bool {
        dof::exists_(house_data.borrow(), game_id)
    }

    /// Helper function to check that a game exists and return a reference to the game Object.
    /// Can be used in combination with any accessor to retrieve the desired game field.
    public fun borrow_game(game_id: ID, house_data: &HouseData): &Game {
        assert!(game_exists(house_data, game_id), EGameDoesNotExist);
        dof::borrow(house_data.borrow(), game_id)
    }

    /// Internal helper function used to create a new game.
    fun internal_start_game(guess: String, counter: &mut Counter, coin: Coin<SUI>, house_data: &mut HouseData, fee_bp: u16, ctx: &mut TxContext): (ID, Game) {
        // Ensure guess is valid.
        map_guess(guess);
        let user_stake = coin.value();
        // Ensure that the stake is not higher than the max stake.
        assert!(user_stake <= house_data.max_stake(), EStakeTooHigh);
        // Ensure that the stake is not lower than the min stake.
        assert!(user_stake >= house_data.min_stake(), EStakeTooLow);
        // Ensure that the house has enough balance to play for this game.
        assert!(house_data.balance() >= user_stake, EInsufficientHouseBalance);

        // Get the house's stake.
        let mut total_stake = house_data.borrow_balance_mut().split(user_stake);
        coin::put(&mut total_stake, coin);

        let vrf_input = counter.get_vrf_input_and_increment();

        let id = object::new(ctx);
        let game_id = object::uid_to_inner(&id);

        let new_game = Game {
            id,
            guess_placed_epoch: ctx.epoch(),
            total_stake,
            guess,
            player: ctx.sender(),
            vrf_input,
            fee_bp
        };

        emit(NewGame {
            game_id,
            player: ctx.sender(),
            vrf_input,
            guess,
            user_stake,
            fee_bp
        });

        (game_id, new_game)
    }

    /// Helper function to map (H)EADS and (T)AILS to 0 and 1 respectively.
    /// H = 0
    /// T = 1
    fun map_guess(guess: String): u8 {
        let heads = HEADS;
        let tails = TAILS;
        assert!(guess.bytes() == heads || guess.bytes() == tails, EInvalidGuess);

        if (guess.bytes() == heads) {
            0
        } else {
            1
        }
    }
}


This represents a basic example of a coin flip backend in Move. The game module, single_player_satoshi, is prone to MEV attacks, but the user experience for the player is streamlined. Another example game module, mev_attack_resistant_single_player_satoshi, exists that is MEV-resistant, but has a slightly downgraded user experience (two player-transactions per game).

You can read more about both versions of the game, and view the full source code for all the modules in the Satoshi Coin Flip repository.

Now that you have written our contracts, it's time to deploy them.

Deployment
INFO
See Publish a Package for a more detailed guide on publishing packages or Sui Client CLI for a complete reference of client commands in the Sui CLI.

Before publishing your code, you must first initialize the Sui Client CLI, if you haven't already. To do so, in a terminal or console at the root directory of the project enter sui client. If you receive the following response, complete the remaining instructions:

Config file ["<FILE-PATH>/.sui/sui_config/client.yaml"] doesn't exist, do you want to connect to a Sui Full node server [y/N]?


Enter y to proceed. You receive the following response:

Sui Full node server URL (Defaults to Sui Devnet if not specified) :

Leave this blank (press Enter). You receive the following response:

Select key scheme to generate keypair (0 for ed25519, 1 for secp256k1, 2: for secp256r1):

Select 0. Now you should have a Sui address set up.

Before being able to publish your package to Testnet, you need Testnet SUI tokens. To get some, join the Sui Discord, complete the verification steps, enter the #testnet-faucet channel and type !faucet <WALLET ADDRESS>. For other ways to get SUI in your Testnet account, see Get SUI Tokens.

Now that you have an account with some Testnet SUI, you can deploy your contracts. To publish your package, use the following command in the same terminal or console:

sui client publish --gas-budget <GAS-BUDGET>

For the gas budget, use a standard value such as 20000000.

The package should successfully deploy. Now, it's time to create a frontend that can interact with it.

Frontend
INFO
The full source code for the frontend is available at the Satoshi Coin Flip Frontend Example repository.

To expose the backend you have created to your users, you need a frontend (UI). In this section, you create a React frontend project using the Sui Typescript SDK and the Sui dApp Kit that interacts with the deployed smart contracts.

Initialize the project
INFO
The following instructions are using pnpm as the package manager. Follow the pnpm install instructions, if needed.

First, initialize your frontend project. To do this rapidly, use the create-dapp tool to bootstrap the project using dApp Kit. Run the following command in your terminal or console:

pnpm create @mysten/dapp

This CLI command prompts you through a couple of steps:

It asks you the starter template that you want to use. Currently, there are two variants:

react-client-dapp: This starter template contains the minimum dApp Kit template code that you can start with. This variant is meant for developers already familiar with the dApp Kit and who don't want unnecessary template code.
react-e2e-counter: This starter template contains a simple counter Sui Move smart contract with the frontend template code interacting with it. This variant is meant for developers trying to learn how to use dApp Kit.
It prompts you to name your project folder.

Done. Your project has all necessary code to get you started. Lastly, cd into your project folder and run pnpm install to install all dependencies.

User interface layout design
The user interface (UI) of this frontend example demonstrates how to use the dApp Kit instead of serving as a production-grade product, so the Player and the House features are in the same UI to simplify the process. In a production solution, your frontend would only contain functionality dedicated to the Player, with a backend service carrying out the interactions with House functions in the smart contracts.

The UI has two columns:

First column is dedicated to the Player, and all Player-related features live there
Second column is dedicated to the House, and all House-related features live there
Project folder structure
Structure the project folder according to the UI layout, meaning that all Player-related React components reside in the containers/Player folder, while all House-related React components reside in the containers/House folder.

Exploring the code
The UI interacts with the Single Player smart contract variant of the game. This section walks you through each step in the smart contract flow and the corresponding frontend code.

INFO
The following frontend code snippets include only the most relevant sections. Refer to the Satoshi Coin Flip Frontend Example repository for complete source code.

As is common in other React projects, App.tsx is where you implement the outer layout:

App.tsx
import { ConnectButton, useCurrentAccount } from '@mysten/dapp-kit';
import { InfoCircledIcon } from '@radix-ui/react-icons';
import { Box, Callout, Container, Flex, Grid, Heading } from '@radix-ui/themes';

import { HOUSECAP_ID, PACKAGE_ID } from './constants';
import { HouseSesh } from './containers/House/HouseSesh';
import { PlayerSesh } from './containers/Player/PlayerSesh';

function App() {
	const account = useCurrentAccount();
	return (
		<>
			<Flex
				position="sticky"
				px="4"
				py="2"
				justify="between"
				style={{
					borderBottom: '1px solid var(--gray-a2)',
				}}
			>
				<Box>
					<Heading>Satoshi Coin Flip Single Player</Heading>
				</Box>

				<Box>
					<ConnectButton />
				</Box>
			</Flex>
			<Container>
				<Heading size="4" m={'2'}>
					Package ID: {PACKAGE_ID}
				</Heading>
				<Heading size="4" m={'2'}>
					HouseCap ID: {HOUSECAP_ID}
				</Heading>

				<Callout.Root mb="2">
					<Callout.Icon>
						<InfoCircledIcon />
					</Callout.Icon>
					<Callout.Text>
						You need to connect to wallet that publish the smart contract package
					</Callout.Text>
				</Callout.Root>

				{!account ? (
					<Heading size="4" align="center">
						Please connect wallet to continue
					</Heading>
				) : (
					<Grid columns="2" gap={'3'} width={'auto'}>
						<PlayerSesh />
						<HouseSesh />
					</Grid>
				)}
			</Container>
		</>
	);
}

export default App;


Like other dApps, you need a "connect wallet" button to enable connecting users' wallets. dApp Kit contains a pre-made ConnectButton React component that you can reuse to help users onboard.

useCurrentAccount() is a React hook the dApp Kit also provides to query the current connected wallet; returning null if there isn't a wallet connection. Leverage this behavior to prevent a user from proceeding further if they haven’t connected their wallet yet.

There are two constants that you need to put into constants.ts to make the app work – PACKAGE_ID and HOUSECAP_ID. You can get these from the terminal or console after running the Sui CLI command to publish the package.

After ensuring that the user has connected their wallet, you can display the two columns described in the previous section: PlayerSesh and HouseSesh components.

Okay, that’s a good start to have an overview of the project. Time to move to initializing the HouseData object. All the frontend logic for calling this lives in the HouseInitialize.tsx component. The component includes UI code, but the logic that executes the transaction follows:

containers/House/HouseInitialize.tsx
<form
  onSubmit={(e) => {
    e.preventDefault();

    // Create new transaction
    const txb = new Transaction();
    // Split gas coin into house stake coin
    // SDK will take care for us abstracting away of up-front coin selections
    const [houseStakeCoin] = txb.splitCoins(txb.gas, [
      MIST_PER_SUI * BigInt(houseStake),
    ]);
    // Calling smart contract function
    txb.moveCall({
      target: `${PACKAGE_ID}::house_data::initialize_house_data`,
      arguments: [
        txb.object(HOUSECAP_ID),
        houseStakeCoin,
        // This argument is not an on-chain object, hence, we must serialize it using `bcs`
        // https://sdk.mystenlabs.com/typescript/transaction-building/basics#pure-values
        txb.pure(
          bcs
            .vector(bcs.U8)
            .serialize(curveUtils.hexToBytes(getHousePubHex())),
        ),
      ],
    });

    execInitializeHouse(
      {
        transaction: txb,
        options: {
          showObjectChanges: true,
        },
      },
      {
        onError: (err) => {
          toast.error(err.message);
        },
        onSuccess: (result: SuiTransactionBlockResponse) => {
          let houseDataObjId;


          result.objectChanges?.some((objCh) => {
            if (
              objCh.type === "created" &&
              objCh.objectType === `${PACKAGE_ID}::house_data::HouseData`
            ) {
              houseDataObjId = objCh.objectId;
              return true;
            }
          });

          setHouseDataId(houseDataObjId!);

          toast.success(`Digest: ${result.digest}`);
        },
      },
    );
  }}


To use a programmable transaction block (PTB) in Sui, create a Transaction. To initiate a Move call, you must know the global identifier of a public function in your smart contract. The global identifier usually takes the following form:

${PACKAGE_ID}::${MODULE_NAME}::${FUNCTION_NAME}

In this example, it is:

${PACKAGE_ID}::house_data::initialize_house_data

There are a few parameters that you need to pass into initialize_house_data() Move function: the HouseCap ID, the House stake, and the House BLS public key:

Import the HouseCap ID from constants.ts, which you set up in the previous section.
Use Transaction::splitCoin for the House stake to create a new coin with a defined amount split from the Gas Coin txb.gas. Think of the gas coin as one singular coin available for gas payment from your account (which might cover the entire remaining balance of your account). This is useful for Sui payments - instead of manually selecting the coins for gas payment or manually splitting/merging to have the coin with correct amount for your Move call, the gas coin is the single entry point for this, with all the heavy lifting delegated to the SDK behind the scenes.
Pass the BLS public key as bytes vector<u8>. When providing inputs that are not on-chain objects, serialize them as BCS using a combination of txb.pure and bcs imported from @mysten/sui/bcs.
Now sign and execute the transaction block. dApp Kit provides a React hook useSignAndExecuteTransaction() to streamline this process. This hook, when executed, prompts the UI for you to approve, sign, and execute the transaction block. You can configure the hook with the showObjectChanges option to return the newly-created HouseData shared object as the result of the transaction block. This HouseData object is important as you use it as input for later Move calls, so save its ID somewhere.

Great, now you know how to initialize the HouseData shared object. Move to the next function call.

In this game, the users must create a Counter object to start the game. So there should be a place in the Player column UI to list the existing Counter object information for the player to choose. It seems likely that you will reuse the fetching logic for the Counter object in several places in your UI, so it’s good practice to isolate this logic into a React hook, which you call useFetchCounterNft() in useFetchCounterNft.ts:

containers/Player/useFetchCounterNft.ts
import { useCurrentAccount, useSuiClientQuery } from '@mysten/dapp-kit';

import 'react';

import { PACKAGE_ID } from '../../constants';

// React hook to fetch CounterNFT owned by connected wallet
// This hook is to demonstrate how to use `@mysten/dapp-kit` React hook to query data
// besides using SuiClient directly
export function useFetchCounterNft() {
	const account = useCurrentAccount();

	if (!account) {
		return { data: [] };
	}

	// Fetch CounterNFT owned by current connected wallet
	// Only fetch the 1st one
	const { data, isLoading, isError, error, refetch } = useSuiClientQuery(
		'getOwnedObjects',
		{
			owner: account.address,
			limit: 1,
			filter: {
				MatchAll: [
					{
						StructType: `${PACKAGE_ID}::counter_nft::Counter`,
					},
					{
						AddressOwner: account.address,
					},
				],
			},
			options: {
				showOwner: true,
				showType: true,
			},
		},
		{ queryKey: ['CounterNFT'] },
	);

	return {
		data: data && data.data.length > 0 ? data?.data : [],
		isLoading,
		isError,
		error,
		refetch,
	};
}


This hook logic is very basic: if there is no current connected wallet, return empty data; otherwise, fetch the Counter object and return it. dApp Kit provides a React hook, useSuiClientQuery(), that enables interaction with Sui RPC methods. Different RPC methods require different parameters. To fetch the object owned by a known address, use the getOwnedObjects query.

Now, pass the address of the connected wallet, as well as the global identifier for the Counter. This is in similar format to the global identifier type for function calls:

${PACKAGE_ID}::counter_nft::Counter

That’s it, now put the hook into the UI component PlayerListCounterNft.tsx and display the data:

containers/Player/PlayerListCounterNft.tsx
export function PlayerListCounterNft() {
	const { data, isLoading, error, refetch } = useFetchCounterNft();
	const { mutate: execCreateCounterNFT } = useSignAndExecuteTransaction();

	return (
		<Container mb={'4'}>
			<Heading size="3" mb="2">
				Counter NFTs
			</Heading>

			{error && <Text>Error: {error.message}</Text>}

			<Box mb="3">
				{data.length > 0 ? (
					data.map((it) => {
						return (
							<Box key={it.data?.objectId}>
								<Text as="div" weight="bold">
									Object ID:
								</Text>
								<Text as="div">{it.data?.objectId}</Text>
								<Text as="div" weight="bold">
									Object Type:
								</Text>
								<Text as="div">{it.data?.type}</Text>
							</Box>
						);
					})
				) : (
					<Text>No CounterNFT Owned</Text>
				)}
			</Box>
		</Container>
	);
}


For the case when there is no existing Counter object, mint a new Counter for the connected wallet. Also add the minting logic into PlayerListCounterNft.tsx when the user clicks the button. You already know how to build and execute a Move call with TransactionBlock and initialize_house_data(), you can implement a similar call here.

As you might recall with Transaction, outputs from the transaction can be inputs for the next transaction. Call counter_nft::mint(), which returns the newly created Counter object, and use it as input for counter_nft::transfer_to_sender() to transfer the Counter object to the caller wallet:

containers/Player/PlayerListCounterNft.tsx
const txb = new Transaction();
const [counterNft] = txb.moveCall({
	target: `${PACKAGE_ID}::counter_nft::mint`,
});
txb.moveCall({
	target: `${PACKAGE_ID}::counter_nft::transfer_to_sender`,
	arguments: [counterNft],
});

execCreateCounterNFT(
	{
		transaction: txb,
	},
	{
		onError: (err) => {
			toast.error(err.message);
		},
		onSuccess: (result) => {
			toast.success(`Digest: ${result.digest}`);
			refetch?.();
		},
	},
);

Great, now you can create the game with the created Counter object. Isolate the game creation logic into PlayerCreateGame.tsx. There is one more thing to keep in mind - to flag an input as an on-chain object, you should use txb.object() with the corresponding object ID.

containers/Player/PlayerCreateGame.tsx
// Create new transaction
const txb = new Transaction();

// Player stake
const [stakeCoin] = txb.splitCoins(txb.gas, [MIST_PER_SUI * BigInt(stake)]);

// Create the game with CounterNFT
txb.moveCall({
	target: `${PACKAGE_ID}::single_player_satoshi::start_game`,
	arguments: [
		txb.pure.string(guess),
		txb.object(counterNFTData[0].data?.objectId!),
		stakeCoin,
		txb.object(houseDataId),
	],
});

execCreateGame(
	{
		transaction: txb,
	},
	{
		onError: (err) => {
			toast.error(err.message);
		},
		onSuccess: (result: SuiTransactionBlockResponse) => {
			toast.success(`Digest: ${result.digest}`);
		},
	},
);

One final step remains: settle the game. There are a couple of ways you can use the UI to settle the game:

Create a Settle Game button and pass all the necessary arguments to the single_player_satoshi::finish_game() Move call.
Settle the game automatically through an events subscription. This example uses this path to teache good practices on events and how to subscribe to them.
All of this logic is in HouseFinishGame.tsx:

containers/House/HouseFinishGame.tsx
// This component will help the House to automatically finish the game whenever new game is started
export function HouseFinishGame() {
	const suiClient = useSuiClient();
	const { mutate: execFinishGame } = useSignAndExecuteTransactionBlock();

	const [housePrivHex] = useContext(HouseKeypairContext);
	const [houseDataId] = useContext(HouseDataContext);

	useEffect(() => {
		// Subscribe to NewGame event
		const unsub = suiClient.subscribeEvent({
			filter: {
				MoveEventType: `${PACKAGE_ID}::single_player_satoshi::NewGame`,
			},
			onMessage(event) {
				console.log(event);
				const { game_id, vrf_input } = event.parsedJson as {
					game_id: string;
					vrf_input: number[];
				};

				toast.info(`NewGame started ID: ${game_id}`);

				console.log(housePrivHex);

				try {
					const houseSignedInput = bls.sign(
						new Uint8Array(vrf_input),
						curveUtils.hexToBytes(housePrivHex),
					);

					// Finish the game immediately after new game started
					const txb = new Transaction();
					txb.moveCall({
						target: `${PACKAGE_ID}::single_player_satoshi::finish_game`,
						arguments: [
							txb.pure.id(game_id),
							txb.pure(bcs.vector(bcs.U8).serialize(houseSignedInput)),
							txb.object(houseDataId),
						],
					});
					execFinishGame(
						{
							transaction: txb,
						},
						{
							onError: (err) => {
								toast.error(err.message);
							},
							onSuccess: (result: SuiTransactionBlockResponse) => {
								toast.success(`Digest: ${result.digest}`);
							},
						},
					);
				} catch (err) {
					console.error(err);
				}
			},
		});

		return () => {
			(async () => (await unsub)())();
		};
	}, [housePrivHex, houseDataId, suiClient]);

	return null;
}


To get the underlying SuiClient instance from the SDK, use useSuiClient(). You want to subscribe to events whenever the HouseFinishGame component loads. To do this, use the React hook useEffect() from the core React library.

SuiClient exposes a method called subscribeEvent() that enables you to subscribe to a variety of event types. SuiClient::subscribeEvent() is actually a thin wrapper around the RPC method suix_subscribeEvent.

The logic is that whenever a new game starts, you want to settle the game immediately. The necessary event to achieve this is the Move event type called single_player_satoshi::NewGame. If you inspect the parsed payload of the event through event.parsedJson, you can see the corresponding event fields declared in the smart contract. In this case, you just need to use two fields, the Game ID and the VRF input.

The next steps are similar to the previous Move calls, but you have to use the BLS private key to sign the VRF input and then pass the Game ID, signed VRF input and HouseData ID to the single_player_satoshi::finish_game() Move call.

Last but not least, remember to unsubscribe from the event whenever the HouseFinishGame component dismounts. This is important as you might not want to subscribe to the same event multiple times.

Congratulations, you completed the frontend. You can carry the lessons learned here forward when using the dApp Kit to build your next Sui project.


Distributed Counter
This example walks you through building a basic distributed counter app, covering the full end-to-end flow connecting your Move code to your client app. The app allows you to create counters that anyone can increment, but only the owner can reset. This example assumes you already have a React App set with dApp Kit, and it's required Providers as described in Client App with Sui TypeScript SDK.

INFO
You must use the pnpm or yarn package managers to create Sui project scaffolds. Follow the pnpm install or yarn install instructions, if needed.

If haven't followed Client App with Sui TypeScript SDK, run the following command in a terminal or console to scaffold a new app:

pnpm create @mysten/dapp --template react-client-dapp

or

yarn create @mysten/dapp --template react-client-dapp

To get a head start, you can automatically create this example using the following template value instead:

pnpm create @mysten/dapp --template react-e2e-counter

or

yarn create @mysten/dapp --template react-e2e-counter

Adding a Move module
The first element you need is a Move package to interact with. This example doesn't go in-depth on the Move code itself, but covers how to deploy it, and connect it to your dApp.

First, create a new move directory at the root of your project to place your Move code and then make it the active directory:

mkdir move
cd move

Next, use the Sui Client CLI to generate a new Move package. If you have Sui installed, the Sui CLI is on your system. Run the following command in your terminal or console:

sui move new counter

This creates a new, empty Move package in a new move/counter directory with a Move.toml file, and an empty sources directory.

Add your Move code under sources by creating a new counter.move file:

module counter::counter {
    /// A shared counter.
    public struct Counter has key {
        id: UID,
        owner: address,
        value: u64
    }

    /// Create and share a Counter object.
    public fun create(ctx: &mut TxContext) {
        transfer::share_object(Counter {
            id: object::new(ctx),
            owner: ctx.sender(),
            value: 0
        })
    }

    /// Increment a counter by 1.
    public fun increment(counter: &mut Counter) {
        counter.value = counter.value + 1;
    }

    /// Set value (only runnable by the Counter owner)
    public fun set_value(counter: &mut Counter, value: u64, ctx: &TxContext) {
        assert!(counter.owner == ctx.sender(), 0);
        counter.value = value;
    }
}

Now that you have your Move code, you need to publish it. The Client App with Sui TypeScript SDK example and the app template use testnet by default, so configure your code to match the network you want to deploy to.

First, update the Sui dependency in Move.toml by changing the rev from framework/testnet to framework/devnet.

...
[dependencies]
Sui = { git = "https://github.com/MystenLabs/sui.git", subdir = "crates/sui-framework/packages/sui-framework", rev = "framework/devnet" }
...


Next, configure the Sui CLI to use devnet as the active environment, as well. If you haven't already set up a devnet environment you can do so by running the following command in a terminal or console:

sui client new-env --alias devnet --rpc https://fullnode.devnet.sui.io:443

Run the following command to activate the devnet environment:

sui client switch --env devnet

Now, publish your Move code with the following command:

TIP
Beginning with the Sui v1.24.1 release, the --gas-budget flag is no longer required for CLI commands.

sui client publish --gas-budget 10000000 counter

INFO
See Sui Client CLI for more information about client commands in the Sui CLI.

The output of this command contains a packageId value that you need to save to use the package.

----- Object changes ----
Array [
    Object {
        ...
    },
    Object {
        ...
    },
    Object {
        "type": String("published"),
        "packageId": String("0xcd16d38ec30a4ad609336b51f6859a6b1014c50801b47845ac7a251e436cccf7"),
        "version": String("1"),
        "digest": String("4bCjupBDiaANmBySAtxuAdXEvGdKW4wrya6sbmRvynEe"),
        "modules": Array [
            String("counter"),
        ],
    },
]
----- Balance changes ----


Add the packageId value you receive in your own response to a new constants.ts file in your project:

export const COUNTER_PACKAGE_ID =
  "0xcd16d38ec30a4ad609336b51f6859a6b1014c50801b47845ac7a251e436cccf7";

Creating a counter
Now that you've published your Move code, you can start building your UI to use your Move package. You need a way to create a new Counter object. Do this by creating a new CreateCounter component:

export function CreateCounter(props: { onCreated: (id: string) => void }) {
	return (
		<div>
			<button
				onClick={() => {
					create();
				}}
			>
				Create Counter
			</button>
		</div>
	);

	function create() {
		props.onCreated('TODO');
	}
}

This component renders a button that enables the user to create a counter. Now, update your create function so that it calls the create function in your Move module.

To do this, you need to construct a Transaction, with the appropriate moveCall transaction, and then sign and execute the programmable transaction block (PTB).

First, import Transaction from @mysten/sui, COUNTER_PACKAGE_ID from your constants.ts file created previously, and useSignAndExecuteTransaction from @mysten/dapp-kit.

import { useSignAndExecuteTransaction } from '@mysten/dapp-kit';
import { Transaction } from '@mysten/sui/transactions';

import { COUNTER_PACKAGE_ID } from './constants';

Next, call the useSignAndExecuteTransaction hook in your component, which provides a mutate function you can use in your create function:

export function CreateCounter(props: { onCreated: (id: string) => void }) {
	const { mutate: signAndExecute } = useSignAndExecuteTransaction();
	return (
		<div>
			<button
				onClick={() => {
					create();
				}}
			>
				Create Counter
			</button>
		</div>
	);

	function create() {
		// TODO
	}
}

Finally, construct your Transaction:

function create() {
	const tx = new Transaction();
	tx.moveCall({
		arguments: [],
		target: `${COUNTER_PACKAGE_ID}::counter::create`,
	});

	signAndExecute(
		{
			transaction: tx,
		},
		{
			onSuccess: async ({ digest }) => {
				const tx = await suiClient.waitForTransaction({
					digest,
					options: {
						showEffects: true,
					},
				});

				// The first created object in this Transaction should be the new Counter
				const objectId = tx.effects?.created?.[0]?.reference?.objectId;
				if (objectId) {
					props.onCreated(objectId);
				}
			},
		},
	);
}


You now have a functional component that can create a new Counter object, but if you use it as is, you might run into some consistency issues where you successfully execute the Transaction, but the data isn't yet indexed to read from an RPC node. To ensure the Transaction is available, you can use the waitForTransaction method of SuiClient. To get an instance of SuiClient, you can use the useSuiClient hook from dApp Kit:

import { useSignAndExecuteTransaction, useSuiClient } from '@mysten/dapp-kit';

export function CreateCounter(props: { onCreated: (id: string) => void }) {
	const suiClient = useSuiClient();
	const { mutate: signAndExecute } = useSignAndExecuteTransaction();

	return <button />;
}

Now you can use the suiClient in your create function to wait until the Transaction is indexed:

function create() {
	const tx = new Transaction();
	tx.moveCall({
		arguments: [],
		target: `${COUNTER_PACKAGE_ID}::counter::create`,
	});

	signAndExecute(
		{
			transaction: tx,
		},
		{
			onSuccess: ({ digest }) => {
				suiClient
					.waitForTransaction({
						digest,
						options: {
							showEffects: true,
						},
					})
					.then((tx) => {
						const objectId = tx.effects?.created?.[0]?.reference?.objectId;
						if (objectId) {
							props.onCreated(objectId);
						}
					});
			},
		},
	);
}


Set up routing
Now that your users can create counters, you need a way to route to them. Routing in a React app can be complex, but this example keeps it basic. Set up your App so that you render the CreateCounter component by default, and if you want to display a specific counter you can put its ID into the hash portion of the URL.

import { ConnectButton, useCurrentAccount } from '@mysten/dapp-kit';
import { isValidSuiObjectId } from '@mysten/sui/utils';
import { useState } from 'react';

export default function App() {
	const currentAccount = useCurrentAccount();
	const [counterId, setCounter] = useState(() => {
		const hash = window.location.hash.slice(1);
		return isValidSuiObjectId(hash) ? hash : null;
	});

	return (
		<div>
			<nav>
				<ConnectButton />
			</nav>
			<section>
				{!currentAccount ? (
					'Please connect your wallet'
				) : counterId ? (
					<Counter id={counterId} />
				) : (
					<CreateCounter
						onCreated={(id) => {
							window.location.hash = id;
							setCounter(id);
						}}
					/>
				)}
			</section>
		</div>
	);
}

This sets up your app to read the hash from the URL, and get the counter's ID if the hash is a valid object ID. Then, it either renders a Counter (which you define in the next step) if you have a counter ID, or the CreateCounter button from the previous step. When a counter is created, you update the URL, and set the counter ID.

Building your counter user interface
For your counter, you want to display three elements:

The current count, which you fetch from the object using the getObject RPC method.
An increment button, which calls the increment Move function.
A reset button, which calls the set_value Move function with 0. This is only shown if the current user owns the counter.
import { useCurrentAccount, useSuiClientQuery } from '@mysten/dapp-kit';
import { SuiObjectData } from '@mysten/sui/client';

export function Counter({ id }: { id: string }) {
	const currentAccount = useCurrentAccount();
	const { data, refetch } = useSuiClientQuery('getObject', {
		id,
		options: {
			showContent: true,
		},
	});

	if (!data?.data) return <div>Not found</div>;

	const ownedByCurrentAccount = getCounterFields(data.data)?.owner === currentAccount?.address;

	return (
		<div>
			<div>Count: {getCounterFields(data.data)?.value}</div>

			<button onClick={() => executeMoveCall('increment')}>Increment</button>
			{ownedByCurrentAccount ? (
				<button onClick={() => executeMoveCall('reset')}>Reset</button>
			) : null}
		</div>
	);

	function executeMoveCall(method: 'increment' | 'reset') {
		// TODO
	}
}

function getCounterFields(data: SuiObjectData) {
	if (data.content?.dataType !== 'moveObject') {
		return null;
	}

	return data.content.fields as { value: number; owner: string };
}


This snippet has a few new concepts to examine. It uses the useSuiClientQuery hook to make the getObject RPC call. This returns a data object representing your counter. dApp Kit doesn't know which fields your counter object has, so define a getCounterFields helper that gets the counter fields, and adds a type-cast so that you can access the expected value and owner fields in your component.

The code also adds an executeMoveCall function that still needs implementing. This works just like the create function you used to create the counter. Instead of using a callback prop like you did for CreateCounter, you can use the refetch provided by useSuiClientQuery to reload your Counter object after you've executed your PTB.

import {
	useCurrentAccount,
	useSignAndExecuteTransaction,
	useSuiClient,
	useSuiClientQuery,
} from '@mysten/dapp-kit';
import { SuiObjectData } from '@mysten/sui/client';
import { Transaction } from '@mysten/sui/transactions';

import { COUNTER_PACKAGE_ID } from './constants';

export function Counter({ id }: { id: string }) {
	const currentAccount = useCurrentAccount();
	const suiClient = useSuiClient();
	const { mutate: signAndExecute } = useSignAndExecuteTransaction();

	// ...

	function executeMoveCall(method: 'increment' | 'reset') {
		const tx = new Transaction();

		if (method === 'reset') {
			tx.moveCall({
				arguments: [tx.object(id), tx.pure.u64(0)],
				target: `${COUNTER_PACKAGE_ID}::counter::set_value`,
			});
		} else {
			tx.moveCall({
				arguments: [tx.object(id)],
				target: `${COUNTER_PACKAGE_ID}::counter::increment`,
			});
		}

		signAndExecute(
			{
				transaction: tx,
			},
			{
				onSuccess: async (tx) => {
					await suiClient.waitForTransaction({ digest: tx.digest });
					refetch();
				},
			},
		);
	}
}


Your counter app is now ready to count. To learn more about dApp Kit, check out the dApp Kit docs.

Sui Weather Oracle
This guide demonstrates writing a module (smart contract) in Move, deploying it on Devnet, and adding a backend, which fetches the weather data from the OpenWeather API every 10 minutes and updates the weather conditions for each city. The dApp created in this guide is called Sui Weather Oracle and it provides real-time weather data for over 1,000 locations around the world.

You can access and use the weather data from the OpenWeather API for various applications, such as randomness, betting, gaming, insurance, travel, education, or research. You can also mint a weather NFT based on the weather data of a city, using the mint function of the SUI Weather Oracle smart contract.

This guide assumes you have installed Sui and understand Sui fundamentals.

Move smart contract
As with all Sui dApps, a Move package on chain powers the logic of Sui Weather Oracle. The following instruction walks you through creating and publishing the module.

Weather Oracle module
Before you get started, you must initialize a Move package. Open a terminal or console in the directory you want to store the example and run the following command to create an empty package with the name weather_oracle:

sui move new weather_oracle

With that done, it's time to jump into some code. Create a new file in the sources directory with the name weather.move and populate the file with the following code:

weather.move
// Copyright (c) Mysten Labs, Inc.
// SPDX-License-Identifier: Apache-2.0

module oracle::weather {
    use std::string::String;
    use sui::dynamic_object_field as dof;
    use sui::package;
}

There are few details to take note of in this code:

The fourth line declares the module name as weather within the package oracle.
Seven lines begin with the use keyword, which enables this module to use types and functions declared in other modules.
Next, add some more code to this module:

weather.move
/// Define a capability for the admin of the oracle.
public struct AdminCap has key, store { id: UID }

/// // Define a one-time witness to create the `Publisher` of the oracle.
public struct WEATHER has drop {}

// Define a struct for the weather oracle
public struct WeatherOracle has key {
    id: UID,
    /// The address of the oracle.
    address: address,
    /// The name of the oracle.
    name: String,
    /// The description of the oracle.
    description: String,
}

public struct CityWeatherOracle has key, store {
    id: UID,
    geoname_id: u32, // The unique identifier of the city
    name: String, // The name of the city
    country: String, // The country of the city
    latitude: u32, // The latitude of the city in degrees
    positive_latitude: bool, // Whether the latitude is positive (north) or negative (south)
    longitude: u32, // The longitude of the city in degrees
    positive_longitude: bool, // Whether the longitude is positive (east) or negative (west)
    weather_id: u16, // The weather condition code
    temp: u32, // The temperature in kelvin
    pressure: u32, // The atmospheric pressure in hPa
    humidity: u8, // The humidity percentage
    visibility: u16, // The visibility in meters
    wind_speed: u16, // The wind speed in meters per second
    wind_deg: u16, // The wind direction in degrees
    wind_gust: Option<u16>, // The wind gust in meters per second (optional)
    clouds: u8, // The cloudiness percentage
    dt: u32 // The timestamp of the weather update in seconds since epoch
}

fun init(otw: WEATHER, ctx: &mut TxContext) {
    package::claim_and_keep(otw, ctx); // Claim ownership of the one-time witness and keep it

    let cap = AdminCap { id: object::new(ctx) }; // Create a new admin capability object
    transfer::share_object(WeatherOracle {
        id: object::new(ctx),
        address: ctx.sender(),
        name: b"SuiMeteo".to_string(),
        description: b"A weather oracle.".to_string(),
    });
    transfer::public_transfer(cap, ctx.sender()); // Transfer the admin capability to the sender.
}


The first struct, AdminCap, is a capability.
The second struct, WEATHER, is a one-time witness that ensures only a single instance of this Weather ever exists.
The WeatherOracle struct works as a registry and stores the geoname_ids of the CityWeatherOracles as dynamic fields.
The init function creates and sends the Publisher and AdminCap objects to the sender. Also, it creates a shared object for all the CityWeatherOracles.
So far, you've set up the data structures within the module. Now, create a function that initializes a CityWeatherOracle and adds it as dynamic fields to the WeatherOracle object:

weather.move
public fun add_city(
    _: &AdminCap, // The admin capability
    oracle: &mut WeatherOracle, // A mutable reference to the oracle object
    geoname_id: u32, // The unique identifier of the city
    name: String, // The name of the city
    country: String, // The country of the city
    latitude: u32, // The latitude of the city in degrees
    positive_latitude: bool, // The whether the latitude is positive (north) or negative (south)
    longitude: u32, // The longitude of the city in degrees
    positive_longitude: bool, // The whether the longitude is positive (east) or negative (west)
    ctx: &mut TxContext // A mutable reference to the transaction context
) {
    dof::add(&mut oracle.id, geoname_id, // Add a new dynamic object field to the oracle object with the geoname ID as the key and a new city weather oracle object as the value.
        CityWeatherOracle {
            id: object::new(ctx), // Assign a unique ID to the city weather oracle object
            geoname_id, // Set the geoname ID of the city weather oracle object
            name,  // Set the name of the city weather oracle object
            country,  // Set the country of the city weather oracle object
            latitude,  // Set the latitude of the city weather oracle object
            positive_latitude,  // Set whether the latitude is positive (north) or negative (south)
            longitude,  // Set the longitude of the city weather oracle object
            positive_longitude,  // Set whether the longitude is positive (east) or negative (west)
            weather_id: 0, // Initialize the weather condition code to be zero
            temp: 0, // Initialize the temperature to be zero
            pressure: 0, // Initialize the pressure to be zero
            humidity: 0, // Initialize the humidity to be zero
            visibility: 0, // Initialize the visibility to be zero
            wind_speed: 0, // Initialize the wind speed to be zero
            wind_deg: 0, // Initialize the wind direction to be zero
            wind_gust: option::none(), // Initialize the wind gust to be none
            clouds: 0, // Initialize the cloudiness to be zero
            dt: 0 // Initialize the timestamp to be zero
        }
    );
}


The add_city function is a public function that allows the owner of the AdminCap of the Sui Weather Oracle smart contract to add a new CityWeatherOracle. The function requires the admin to provide a capability object that proves their permission to add a city. The function also requires a mutable reference to the oracle object, which is the main object that stores the weather data on the blockchain. The function takes several parameters that describe the city, such as the geoname ID, name, country, latitude, longitude, and positive latitude and longitude. The function then creates a new city weather oracle object, which is a sub-object that stores and updates the weather data for a specific city. The function initializes the city weather oracle object with the parameters provided by the admin, and sets the weather data to be zero or none. The function then adds a new dynamic object field to the oracle object, using the geoname ID as the key and the city weather oracle object as the value. This way, the function adds a new city to the oracle, and makes it ready to receive and update the weather data from the backend service.

If you want to delete a city from the Sui Weather Oracle, call the remove_city function of the smart contract. The remove_city function allows the admin of the smart contract to remove a city from the oracle. The function requires the admin to provide a capability object that proves their permission to remove a city. The function also requires a mutable reference to the oracle object, which is the main object that stores and updates the weather data on the blockchain. The function takes the geoname ID of the city as a parameter, and deletes the city weather oracle object for the city. The function also removes the dynamic object field for the city from the oracle object. This way, the function deletes a city from the oracle, and frees up some storage space on the blockchain.

weather.move
public fun remove_city(
    _: &AdminCap,
    oracle: &mut WeatherOracle,
    geoname_id: u32
    ) {
        let CityWeatherOracle {
            id,
            geoname_id: _,
            name: _,
            country: _,
            latitude: _,
            positive_latitude: _,
            longitude: _,
            positive_longitude: _,
            weather_id: _,
            temp: _,
            pressure: _,
            humidity: _,
            visibility: _,
            wind_speed: _,
            wind_deg: _,
            wind_gust: _,
            clouds: _,
            dt: _ } = dof::remove(&mut oracle.id, geoname_id);
        object::delete(id);
}

Now that you have implemented the add_city and remove_city functions, you can move on to the next step, which is to see how you can update the weather data for each city. The backend service fetches the weather data from the OpenWeather API every 10 minutes, and then passes the data to the update function of the Sui Weather Oracle smart contract. The update function takes the geoname ID and the new weather data of the city as parameters, and updates the city weather oracle object with the new data. This way, the weather data on the blockchain is always up to date and accurate.

weather.move
public fun update(
    _: &AdminCap,
    oracle: &mut WeatherOracle,
    geoname_id: u32,
    weather_id: u16,
    temp: u32,
    pressure: u32,
    humidity: u8,
    visibility: u16,
    wind_speed: u16,
    wind_deg: u16,
    wind_gust: Option<u16>,
    clouds: u8,
    dt: u32
) {
    let city_weather_oracle_mut = dof::borrow_mut<u32, CityWeatherOracle>(&mut oracle.id, geoname_id); // Borrow a mutable reference to the city weather oracle object with the geoname ID as the key
    city_weather_oracle_mut.weather_id = weather_id;
    city_weather_oracle_mut.temp = temp;
    city_weather_oracle_mut.pressure = pressure;
    city_weather_oracle_mut.humidity = humidity;
    city_weather_oracle_mut.visibility = visibility;
    city_weather_oracle_mut.wind_speed = wind_speed;
    city_weather_oracle_mut.wind_deg = wind_deg;
    city_weather_oracle_mut.wind_gust = wind_gust;
    city_weather_oracle_mut.clouds = clouds;
    city_weather_oracle_mut.dt = dt;
}


You have defined the data structure of the Sui Weather Oracle smart contract, but you need some functions to access and manipulate the data. Now, add some helper functions that read and return the weather data for a WeatherOracle object. These functions allow you to get the weather data for a specific city in the oracle. These functions also allow you to format and display the weather data in a user-friendly way.

weather.move
// --------------- Read-only References ---------------

/// Returns the `name` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_name(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): String {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.name
}
/// Returns the `country` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_country(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): String {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.country
}
/// Returns the `latitude` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_latitude(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): u32 {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.latitude
}
/// Returns the `positive_latitude` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_positive_latitude(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): bool {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.positive_latitude
}
/// Returns the `longitude` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_longitude(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): u32 {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.longitude
}
/// Returns the `positive_longitude` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_positive_longitude(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): bool {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.positive_longitude
}
/// Returns the `weather_id` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_weather_id(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): u16 {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.weather_id
}
/// Returns the `temp` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_temp(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): u32 {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.temp
}
/// Returns the `pressure` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_pressure(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): u32 {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.pressure
}
/// Returns the `humidity` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_humidity(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): u8 {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.humidity
}
/// Returns the `visibility` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_visibility(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): u16 {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.visibility
}
/// Returns the `wind_speed` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_wind_speed(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): u16 {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.wind_speed
}
/// Returns the `wind_deg` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_wind_deg(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): u16 {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.wind_deg
}
/// Returns the `wind_gust` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_wind_gust(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): Option<u16> {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.wind_gust
}
/// Returns the `clouds` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_clouds(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): u8 {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.clouds
}
/// Returns the `dt` of the `CityWeatherOracle` with the given `geoname_id`.
public fun city_weather_oracle_dt(
    weather_oracle: &WeatherOracle,
    geoname_id: u32
): u32 {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&weather_oracle.id, geoname_id);
    city_weather_oracle.dt
}


Finally, add an extra feature that allows anyone to mint a WeatherNFT with the current conditions of a city by passing the geoname ID. The mint function is a public function that allows anyone to mint a weather NFT based on the weather data of a city. The function takes the WeatherOracle shared object and the geoname ID of the city as parameters, and returns a new WeatherNFT object for the city. The WeatherNFT object is a unique and non-fungible token that represents the weather of the city at the time of minting. The WeatherNFT object has the same data as the CityWeatherOracle object, such as the geonameID, name, country, latitude, longitude, positive latitude and longitude, weather ID, temperature, pressure, humidity, visibility, wind speed, wind degree, wind gust, clouds, and timestamp. The function creates the WeatherNFT object by borrowing a reference to the CityWeatherOracle object with the geoname ID as the key, and assigning a unique ID (UID) to the WeatherNFT object. The function then transfers the ownership of the WeatherNFT object to the sender of the transaction. This way, the function allows anyone to mint a weather NFT and own a digital representation of the weather of a city. You can use this feature to create your own collection of weather NFTs, or to use them for other applications that require verifiable and immutable weather data.

weather.move
public struct WeatherNFT has key, store {
    id: UID,
    geoname_id: u32,
    name: String,
    country: String,
    latitude: u32,
    positive_latitude: bool,
    longitude: u32,
    positive_longitude: bool,
    weather_id: u16,
    temp: u32,
    pressure: u32,
    humidity: u8,
    visibility: u16,
    wind_speed: u16,
    wind_deg: u16,
    wind_gust: Option<u16>,
    clouds: u8,
    dt: u32
}

public fun mint(
    oracle: &WeatherOracle,
    geoname_id: u32,
    ctx: &mut TxContext
): WeatherNFT {
    let city_weather_oracle = dof::borrow<u32, CityWeatherOracle>(&oracle.id, geoname_id);
    WeatherNFT {
        id: object::new(ctx),
        geoname_id: city_weather_oracle.geoname_id,
        name: city_weather_oracle.name,
        country: city_weather_oracle.country,
        latitude: city_weather_oracle.latitude,
        positive_latitude: city_weather_oracle.positive_latitude,
        longitude: city_weather_oracle.longitude,
        positive_longitude: city_weather_oracle.positive_longitude,
        weather_id: city_weather_oracle.weather_id,
        temp: city_weather_oracle.temp,
        pressure: city_weather_oracle.pressure,
        humidity: city_weather_oracle.humidity,
        visibility: city_weather_oracle.visibility,
        wind_speed: city_weather_oracle.wind_speed,
        wind_deg: city_weather_oracle.wind_deg,
        wind_gust: city_weather_oracle.wind_gust,
        clouds: city_weather_oracle.clouds,
        dt: city_weather_oracle.dt
    }
}


And with that, your weather.move code is complete.

Deployment
INFO
See Publish a Package for a more detailed guide on publishing packages or Sui Client CLI for a complete reference of client commands in the Sui CLI.

Before publishing your code, you must first initialize the Sui Client CLI, if you haven't already. To do so, in a terminal or console at the root directory of the project enter sui client. If you receive the following response, complete the remaining instructions:

Config file ["<FILE-PATH>/.sui/sui_config/client.yaml"] doesn't exist, do you want to connect to a Sui Full node server [y/N]?


Enter y to proceed. You receive the following response:

Sui Full node server URL (Defaults to Sui Devnet if not specified) :

Leave this blank (press Enter). You receive the following response:

Select key scheme to generate keypair (0 for ed25519, 1 for secp256k1, 2: for secp256r1):

Select 0. Now you should have a Sui address set up.

Before being able to publish your package to Testnet, you need Testnet SUI tokens. To get some, join the Sui Discord, complete the verification steps, enter the #testnet-faucet channel and type !faucet <WALLET ADDRESS>. For other ways to get SUI in your Testnet account, see Get SUI Tokens.

Now that you have an account with some Testnet SUI, you can deploy your contracts. To publish your package, use the following command in the same terminal or console:

sui client publish --gas-budget <GAS-BUDGET>

For the gas budget, use a standard value such as 20000000.

Backend
You have successfully deployed the Sui Weather Oracle smart contract on the blockchain. Now, it's time to create an Express backend that can interact with it. The Express backend performs the following tasks:

Initialize the smart contract with 1,000 cities using the add_city function of the smart contract. The backend passes the geoname ID, name, country, latitude, longitude, and positive latitude and longitude of each city as parameters to the function.
Fetch the weather data for each city from the OpenWeather API every 10 minutes, using the API key that you obtained from the website. The backend parses the JSON response and extracts the weather data for each city, such as the weather ID, temperature, pressure, humidity, visibility, wind speed, wind degree, wind gust, clouds, and timestamp.
Update the weather data for each city on the blockchain, using the update function of the smart contract. The backend passes the geoname ID and the new weather data of each city as parameters to the function.
The Express backend uses the Sui Typescript SDK, a TypeScript library that enables you to interact with the Sui blockchain and smart contracts. With the Sui Typescript SDK, you can connect to the Sui network, sign and submit transactions, and query the state of the smart contract. You also use the OpenWeather API to fetch the weather data for each city and update the smart contract every 10 minutes. Additionally, you can mint weather NFTs, if you want to explore that feature of the smart contract.

Initialize the project
First, initialize your backend project. To do this, you need to follow these steps:

Create a new folder named weather-oracle-backend and navigate to it in your terminal.
Run npm init -y to create a package.json file with default values.
Run npm install express --save to install Express as a dependency and save it to your package.json file.
Run npm install @mysten/bcs @mysten/sui axios csv-parse csv-parser dotenv pino retry-axios --save to install the other dependencies and save them to your package.json file. These dependencies are:
@mysten/bcs: a library for blockchain services.
@mysten/sui: a library for smart user interfaces.
axios: a library for making HTTP requests.
csv-parse: a library for parsing CSV data.
csv-parser: a library for transforming CSV data into JSON objects.
dotenv: a library for loading environment variables from a .env file.
pino: a library for fast and low-overhead logging.
retry-axios: a library for retrying failed axios requests.
Create a new file named init.ts
init.ts
import { Connection, Ed25519Keypair, JsonRpcProvider, RawSigner, Transaction } from '@mysten/sui';
import * as dotenv from 'dotenv';

import { City } from './city';
import { get1000Geonameids } from './filter-cities';
import { latitudeMultiplier, longitudeMultiplier } from './multipliers';
import { getCities, getWeatherOracleDynamicFields } from './utils';
import { logger } from './utils/logger';

dotenv.config({ path: '../.env' });

const phrase = process.env.ADMIN_PHRASE;
const fullnode = process.env.FULLNODE!;
const keypair = Ed25519Keypair.deriveKeypair(phrase!);
const provider = new JsonRpcProvider(
	new Connection({
		fullnode: fullnode,
	}),
);
const signer = new RawSigner(keypair, provider);

const packageId = process.env.PACKAGE_ID;
const adminCap = process.env.ADMIN_CAP_ID!;
const weatherOracleId = process.env.WEATHER_ORACLE_ID!;
const moduleName = 'weather';

const NUMBER_OF_CITIES = 10;

async function addCityWeather() {
	const cities: City[] = await getCities();
	const thousandGeoNameIds = await get1000Geonameids();

	const weatherOracleDynamicFields = await getWeatherOracleDynamicFields(provider, weatherOracleId);
	const geonames = weatherOracleDynamicFields.map(function (obj) {
		return obj.name;
	});

	let counter = 0;
	let transaction = new Transaction();
	for (let c in cities) {
		if (
			!geonames.includes(cities[c].geonameid) &&
			thousandGeoNameIds.includes(cities[c].geonameid)
		) {
			transaction.moveCall({
				target: `${packageId}::${moduleName}::add_city`,
				arguments: [
					transaction.object(adminCap), // adminCap
					transaction.object(weatherOracleId), // WeatherOracle
					transaction.pure(cities[c].geonameid), // geoname_id
					transaction.pure(cities[c].asciiname), // asciiname
					transaction.pure(cities[c].countryCode), // country
					transaction.pure(cities[c].latitude * latitudeMultiplier), // latitude
					transaction.pure(cities[c].latitude > 0), // positive_latitude
					transaction.pure(cities[c].longitude * longitudeMultiplier), // longitude
					transaction.pure(cities[c].longitude > 0), // positive_longitude
				],
			});

			counter++;
			if (counter === NUMBER_OF_CITIES) {
				await signAndExecuteTransaction(transaction);
				counter = 0;
				transaction = new Transaction();
			}
		}
	}
	await signAndExecuteTransaction(transaction);
}

async function signAndExecuteTransaction(transaction: Transaction) {
	transaction.setGasBudget(5000000000);
	await signer
		.signAndExecuteTransaction({
			transaction,
			requestType: 'WaitForLocalExecution',
			options: {
				showObjectChanges: true,
				showEffects: true,
			},
		})
		.then(function (res) {
			logger.info(res);
		});
}

addCityWeather();


The code of init.ts does the following:

Imports the necessary modules and classes from the library, such as Connection, Ed25519Keypair, JsonRpcProvider, RawSigner, and Transaction.
Imports the dotenv module to load environment variables from a .env file.
Imports some custom modules and functions from the local files, such as City, get1000Geonameids, getCities, getWeatherOracleDynamicFields, and logger.
Derives a key pair from a phrase stored in the ADMIN_PHRASE environment variable.
Creates a provider object that connects to a Full node specified by the FULLNODE environment variable.
Creates a signer object that uses the key pair and the provider to sign and execute transactions on the blockchain.
Reads some other environment variables, such as PACKAGE_ID, ADMIN_CAP_ID, WEATHER_ORACLE_ID, and MODULE_NAME, which are used to identify the weather oracle contract and its methods.
Defines a constant NUMBER_OF_CITIES, which is the number of cities to be added to the weather oracle in each batch.
Defines an async function addCityWeather, which does the following:
Gets an array of cities from the getCities function.
Gets an array of 1,000 geonameids from the get1000Geonameids function.
Gets an array of weather oracle dynamic fields from the getWeatherOracleDynamicFields function, which contains the geonameids of the existing cities in the weather oracle.
Initializes a counter and a transaction block object.
Loops through the cities array and checks if the city's geonameid is not in the weather oracle dynamic fields array and is in the 1,000 geonameids array.
If the condition is met, adds a moveCall to the transaction block, which calls the add_city method of the weather oracle contract with the city's information, such as geonameid, asciiname, country, latitude, and longitude.
Increments the counter and checks if it reaches the NUMBER_OF_CITIES. If so, calls another async function, signAndExecuteTransaction, with the transaction block as an argument, which signs and executes the transaction block on the blockchain and logs the result. The code then resets the counter and the transaction block.
After the loop ends, calls the signAndExecuteTransaction function again with the remaining transaction block.
You have now initialized the WeatherOracle shared object. The next step is to learn how to update them every 10 minutes with the latest weather data from the OpenWeatherMap API.

index.ts
import { Connection, Ed25519Keypair, JsonRpcProvider, RawSigner, Transaction } from '@mysten/sui';
import * as dotenv from 'dotenv';

import { City } from './city';
import { tempMultiplier, windGustMultiplier, windSpeedMultiplier } from './multipliers';
import { getWeatherData } from './openweathermap';
import { getCities, getWeatherOracleDynamicFields } from './utils';
import { logger } from './utils/logger';

dotenv.config({ path: '../.env' });

const phrase = process.env.ADMIN_PHRASE;
const fullnode = process.env.FULLNODE!;
const keypair = Ed25519Keypair.deriveKeypair(phrase!);
const provider = new JsonRpcProvider(
	new Connection({
		fullnode: fullnode,
	}),
);
const signer = new RawSigner(keypair, provider);

const packageId = process.env.PACKAGE_ID;
const adminCap = process.env.ADMIN_CAP_ID!;
const weatherOracleId = process.env.WEATHER_ORACLE_ID!;
const appid = process.env.APPID!;
const moduleName = 'weather';

const CHUNK_SIZE = 25;
const MS = 1000;
const MINUTE = 60 * MS;
const TEN_MINUTES = 10 * MINUTE;

async function performUpdates(
	cities: City[],
	weatherOracleDynamicFields: {
		name: number;
		objectId: string;
	}[],
) {
	let startTime = new Date().getTime();

	const geonames = weatherOracleDynamicFields.map(function (obj) {
		return obj.name;
	});
	const filteredCities = cities.filter((c) => geonames.includes(c.geonameid));

	for (let i = 0; i < filteredCities.length; i += CHUNK_SIZE) {
		const chunk = filteredCities.slice(i, i + CHUNK_SIZE);

		let transaction = await getTransaction(chunk);
		try {
			await signer.signAndExecuteTransaction({
				transaction,
			});
		} catch (e) {
			logger.error(e);
		}
	}

	let endTime = new Date().getTime();
	setTimeout(
		performUpdates,
		TEN_MINUTES - (endTime - startTime),
		cities,
		weatherOracleDynamicFields,
	);
}

async function getTransaction(cities: City[]) {
	let transaction = new Transaction();

	let counter = 0;
	for (let c in cities) {
		const weatherData = await getWeatherData(cities[c].latitude, cities[c].longitude, appid);
		counter++;
		if (weatherData?.main?.temp !== undefined) {
			transaction.moveCall({
				target: `${packageId}::${moduleName}::update`,
				arguments: [
					transaction.object(adminCap), // AdminCap
					transaction.object(weatherOracleId), // WeatherOracle
					transaction.pure(cities[c].geonameid), // geoname_id
					transaction.pure(weatherData.weather[0].id), // weather_id
					transaction.pure(weatherData.main.temp * tempMultiplier), // temp
					transaction.pure(weatherData.main.pressure), // pressure
					transaction.pure(weatherData.main.humidity), // humidity
					transaction.pure(weatherData.visibility), // visibility
					transaction.pure(weatherData.wind.speed * windSpeedMultiplier), // wind_speed
					transaction.pure(weatherData.wind.deg), // wind_deg
					transaction.pure(
						weatherData.wind.gust === undefined ? [] : [weatherData.wind.gust * windGustMultiplier],
						'vector<u16>',
					), // wind_gust
					transaction.pure(weatherData.clouds.all), // clouds
					transaction.pure(weatherData.dt), // dt
				],
			});
		} else logger.warn(`No weather data for ${cities[c].asciiname} `);
	}
	return transaction;
}

async function run() {
	const cities: City[] = await getCities();
	const weatherOracleDynamicFields: {
		name: number;
		objectId: string;
	}[] = await getWeatherOracleDynamicFields(provider, weatherOracleId);
	performUpdates(cities, weatherOracleDynamicFields);
}

run();


The code in index.ts does the following:

Uses dotenv to load some environment variables from a .env file, such as ADMIN_PHRASE, FULLNODE, PACKAGE_ID, ADMIN_CAP_ID, WEATHER_ORACLE_ID, APPID, and MODULE_NAME. These variables are used to configure some parameters for the code, such as the key pair, the provider, the signer, and the target package and module.
Defines some constants, such as CHUNK_SIZE, MS, MINUTE, and TEN_MINUTES. These constants are used to control the frequency and size of the updates that the code performs.
Defines an async function called performUpdates, which takes two arguments: cities and weatherOracleDynamicFields. This function is the main logic of the code, and it does the following:
Filters the cities array based on the weatherOracleDynamicFields array, which contains the names and object IDs of the weather oracle dynamic fields that the code needs to update.
Loops through the filtered cities in chunks of CHUNK_SIZE, and for each chunk, it calls another async function called getTransaction, which returns a transaction block that contains the Move calls to update the weather oracle dynamic fields with the latest weather data from the OpenWeatherMap API.
Tries to sign and execute the transaction block using the signer, and catches any errors that may occur.
Calculates the time it took to perform the updates, and sets a timeout to call itself again after TEN_MINUTES minus the elapsed time.
The code defines another async function called getTransaction, which takes one argument: cities. This function does the following:
Creates a new transaction block object.
Loops through the cities array, and for each city, it calls another async function called getWeatherData, which takes the latitude, longitude, and appid as arguments, and returns the weather data for the city from the OpenWeatherMap API.
Checks if the weather data is valid, and if so, adds a Move call to the transaction block, which calls the update function of the target package and module, and passes the admin cap, the weather oracle id, the geoname id, and the weather data as arguments.
Returns the transaction block object.
An async run function is defined, which does the following:
Calls another async function called getCities, which returns an array of city objects that contain information such as name, geoname id, latitude, and longitude.
Calls another async function called getWeatherOracleDynamicFields, which takes the package id, the module name, and the signer as arguments, and returns an array of weather oracle dynamic field objects that contain information such as name and object id.
Calls the performUpdates function with the cities and weather oracle dynamic fields arrays as arguments.
Congratulations, you completed the Sui Weather Oracle tutorial. You can carry the lessons learned here forward when building your next Sui project.

Plinko
Plinko is an example implementation of the popular casino game. The Plinko game on Sui incorporates advanced cryptographic techniques to ensure fairness and transparency. Players drop Plinko balls onto a pegged board, where they randomly fall into slots representing different multipliers. This document details the game's mechanics, cryptographic features, and the methodology for calculating trace paths and verifying signatures.

Building an on-chain Plinko game shares a lot of similarities with the Coin Flip game and Blackjack game. For that reason, this example covers only the smart contracts (Move modules) and frontend logic.

INFO
You can find the source files for this example in the Plinko repo on GitHub.

A version of the game is also deployed at Mysten Plinko.

Gameplay
The Plinko game, implemented through smart contracts on the Sui blockchain, incorporates cryptographic techniques to ensure fairness and transparency. Utilizing a blend of BLS signatures, hash functions, and verifiable random function (VRF) inputs, the game calculates the trace path for each ball, determining the game's outcome based on the number of Plink balls a player chooses to drop.

The game mechanics involve a player starting a game by specifying the number of balls and staking a certain amount. The backend generates a BLS signature for the game's randomness source, which is verified on-chain to ensure it's untampered. The game uses a Counter NFT for each round to generate a unique VRF input, ensuring each game's randomness is distinct and cannot be predicted or repeated. The number of Plinko balls, chosen by the player, directly influences the game's complexity and potential payout, as each ball's final position is determined by traversing a cryptographic trace path generated from the hashed BLS signature extended to accommodate the total number of balls.

Sequence diagram
Sui Blockchain
Backend API
Next.js Application
Player
Sui Blockchain
Backend API
Next.js Application
Player
Plinko Game Interaction Flow
Checks stakes, balances, creates and increments the counter, emits 'NewGame' event
Reads from the 'NewGame' event gameId, vrfInput
Signs vrfInput with house's private key
Verifies signature, calculates outcome (payments, balls' trace paths), emits Outcome event
Places bet, selects number of balls, presses play
Displays game as pending, awaiting outcome
Sends bet and number of balls
Calls counter_nft::mint to produce vrf_input, calls plinko::start_game
Returns gameId, vrfInput
POST /game/plinko/end with { gameId, vrfInput, numberOfBalls }
Calls plinko::finish_game with signed vrfInput
Returns game outcome event (trace paths, winnings)
Sends game outcome (trace paths, winnings)
Displays game result, balls' descend, and winnings
Move modules
Follow the comments in each module's code to understand the logic each creates.

plinko::plinko
The plinko::plinko module combines various Sui blockchain features, such as coin handling, event emissions, and dynamic object fields, to create on-chain Plinko games.

plinko.move
module plinko::plinko {
// === Imports ===
use sui::coin::{Self, Coin};
use sui::balance::Balance;
use sui::sui::SUI;
use sui::bls12381::bls12381_min_pk_verify;
use sui::event::emit;
use sui::hash::{blake2b256};
use sui::dynamic_object_field::{Self as dof};

// Import Counter NFT module
use plinko::counter_nft::Counter;

// Import HouseData module
use plinko::house_data::HouseData;

// === Errors ===
const EStakeTooLow: u64 = 0;
const EStakeTooHigh: u64 = 1;
const EInvalidBlsSig: u64 = 2;
const EInsufficientHouseBalance: u64 = 5;
const EGameDoesNotExist: u64 = 6;

// === Structs ===

/// Represents a game and holds the accrued stake.
public struct Game has key, store {
    id: UID,
    game_start_epoch: u64,
    stake: Balance<SUI>,
    player: address,
    // The VRF input used to generate the extended beacon
    vrf_input: vector<u8>,
    fee_bp: u16
}

// === Events ===

/// Emitted when a new game has started.
public struct NewGame has copy, drop {
    game_id: ID,
    player: address,
    vrf_input: vector<u8>,
    user_stake: u64,
    fee_bp: u16
}

/// Emitted when a game has finished.
public struct Outcome has copy, drop {
    game_id: ID,
    result: u64,
    player: address,
    // The trace path of the extended beacon
    trace: vector<u8>
}

// === Public Functions ===

/// Function used to create a new game. The player must provide a Counter NFT and the number of balls.
public fun start_game(counter: &mut Counter, num_balls: u64, coin: Coin<SUI>, house_data: &mut HouseData, ctx: &mut TxContext): ID {
    let fee_bp = house_data.base_fee_in_bp();
    let (id, new_game) = internal_start_game(counter, num_balls, coin, house_data, fee_bp, ctx);
    dof::add(house_data.borrow_mut(), id, new_game);
    id
}

/// finish_game Completes the game by calculating the outcome and transferring the funds to the player.
/// The player must provide a BLS signature of the VRF input and the number of balls to calculate the outcome.
/// It emits an Outcome event with the game result and the trace path of the extended beacon.
public fun finish_game(game_id: ID, bls_sig: vector<u8>, house_data: &mut HouseData, num_balls: u64, ctx: &mut TxContext): (u64, address, vector<u8>) {
    // Ensure that the game exists.
    assert!(game_exists(house_data, game_id), EGameDoesNotExist);

    // Retrieves and removes the game from HouseData, preparing for outcome calculation.
    let Game {
        id,
        game_start_epoch: _,
        stake,
        player,
        vrf_input,
        fee_bp: _
    } = dof::remove<ID, Game>(house_data.borrow_mut(), game_id);

    object::delete(id);

    // Validates the BLS signature against the VRF input.
    let is_sig_valid = bls12381_min_pk_verify(&bls_sig, &house_data.public_key(), &vrf_input);
    assert!(is_sig_valid, EInvalidBlsSig);

    // Initialize the extended beacon vector and a counter for hashing.
    let mut extended_beacon = vector[];
    let mut counter: u8 = 0;

    // Extends the beacon until it has enough data for all ball outcomes.
    while (extended_beacon.length() < (num_balls * 12)) {
        // Create a new vector combining the original BLS signature with the current counter value.
        let mut hash_input = vector[];
        hash_input.append(bls_sig);
        hash_input.push_back(counter);
        // Generate a new hash block from the unique hash input.
        let block = blake2b256(&hash_input);
        // Append the generated hash block to the extended beacon.
        extended_beacon.append(block);
        // Increment the counter for the next iteration to ensure a new unique hash input.
        counter = counter + 1;
    };

    // Initializes variables for calculating game outcome.
    let mut trace = vector[];
    // Calculate the stake amount per ball
    let stake_per_ball = stake.value<SUI>() / num_balls;
    let mut total_funds_amount: u64 = 0;

    // Calculates outcome for each ball based on the extended beacon.
    let mut ball_index = 0;
    while (ball_index < num_balls) {
        let mut state: u64 = 0;
        let mut i = 0;
        while (i < 12) {
            // Calculate the byte index for the current ball and iteration.
            let byte_index = (ball_index * 12) + i;
            // Retrieve the byte from the extended beacon.
            let byte = extended_beacon[byte_index];
            // Add the byte to the trace vector
            trace.push_back<u8>(byte);
            // Count the number of even bytes
            // If even, add 1 to the state
            // Odd byte -> 0, Even byte -> 1
            // The state is used to calculate the multiplier index
            state = if (byte % 2 == 0) { state + 1 } else { state };
            i = i + 1;
        };

    // Calculate multiplier index based on state
    let multiplier_index = state % house_data.multiplier().length();
    // Retrieve the multiplier from the house data
    let result = house_data.multiplier()[multiplier_index];

    // Calculate funds amount for this particular ball
    // Divide by 100 to adjust for multiplier scale and SUI units
    let funds_amount_per_ball = (result * stake_per_ball)/100;
    // Add the funds amount to the total funds amount
    total_funds_amount = total_funds_amount + funds_amount_per_ball;
    ball_index = ball_index + 1;
};

// Processes the payout to the player and returns the game outcome.
let payout_balance_mut = house_data.borrow_balance_mut();
let payout_coin: Coin<SUI> = coin::take(payout_balance_mut, total_funds_amount, ctx);

payout_balance_mut.join(stake);

// transfer the payout coins to the player
transfer::public_transfer(payout_coin, player);
// Emit the Outcome event
emit(Outcome {
    game_id,
    result: total_funds_amount,
    player,
    trace
});

// return the total amount to be sent to the player, (and the player address)
(total_funds_amount, player, trace)


// === Public-View Functions ===

/// Returns the epoch in which the game started.
public fun game_start_epoch(game: &Game): u64 {
    game.game_start_epoch
}

/// Returns the total stake.
public fun stake(game: &Game): u64 {
    game.stake.value()
}

/// Returns the player's address.
public fun player(game: &Game): address {
    game.player
}

/// Returns the player's vrf_input bytes.
public fun vrf_input(game: &Game): vector<u8> {
    game.vrf_input
}

/// Returns the fee of the game.
public fun fee_in_bp(game: &Game): u16 {
    game.fee_bp
}

// === Admin Functions ===

/// Helper function to check if a game exists.
public fun game_exists(house_data: &HouseData, game_id: ID): bool {
    dof::exists_(house_data.borrow(), game_id)
}

/// Helper function to check that a game exists and return a reference to the game Object.
/// Can be used in combination with any accessor to retrieve the desired game field.
public fun borrow_game(game_id: ID, house_data: &HouseData): &Game {
    assert!(game_exists(house_data, game_id), EGameDoesNotExist);
    dof::borrow(house_data.borrow(), game_id)
}

// === Private Functions ===

/// Internal helper function used to create a new game.
/// The player must provide a guess and a Counter NFT.
/// Stake is taken from the player's coin and added to the game's stake.
fun internal_start_game(counter: &mut Counter, num_balls: u64, coin: Coin<SUI>, house_data: &HouseData, fee_bp: u16, ctx: &mut TxContext): (ID, Game) {
    let user_stake = coin.value();
    // Ensure that the stake is not higher than the max stake.
    assert!(user_stake <= house_data.max_stake(), EStakeTooHigh);
    // Ensure that the stake is not lower than the min stake.
    assert!(user_stake >= house_data.min_stake(), EStakeTooLow);
    // Ensure that the house has enough balance to play for this game.
    assert!(house_data.balance() >= (user_stake*(house_data.multiplier()[0]))/100, EInsufficientHouseBalance);

    // Get the VRF input and increment the counter
    let vrf_input = counter.get_vrf_input_and_increment(num_balls);

    let id = object::new(ctx);
    let game_id = object::uid_to_inner(&id);

    // Create a new game object and emit a NewGame event.
    let new_game = Game {
        id,
        game_start_epoch: ctx.epoch(),
        stake: coin.into_balance<SUI>(),
        player: ctx.sender(),
        vrf_input,
        fee_bp
    };
    // Emit a NewGame event
    emit(NewGame {
        game_id,
        player: ctx.sender(),
        vrf_input,
        user_stake,
        fee_bp
    });

    (game_id, new_game)
}
}


Error codes
Error handling is integral to the module, with specific codes indicating various failure states or invalid operations:

EStakeTooLow: Indicates that the stake provided is below the minimum threshold.
EStakeTooHigh: Indicates that the stake exceeds the maximum allowed limit.
EInvalidBlsSig: Denotes an invalid BLS signature.
EInsufficientHouseBalance: Indicates the house does not have enough balance to cover the game's outcome.
EGameDoesNotExist: Used when a referenced game cannot be found.
Events
NewGame: Emitted when a new game starts, capturing essential details like game ID, player address, VRF input, stake, and fee basis points.
Outcome: Emitted upon the conclusion of a game, detailing the outcome, including the game ID, result, player address, and a trace of the game's execution.
Structures
Game: Represents an individual game session, holding information such as the game ID, epoch of game start, stake amount, player address, VRF input, and the fee basis points.
Entry functions
start_game: Initiates a new Plinko game session, accepting parameters like a counter NFT, the number of balls selected by the player, stake, house data, and transaction context.
finish_game: Calculates and finalizes the game outcome, traces the path the balls travel, and distributes the total funds to the player based on outcomes.
Accessors
Provide read-only access to the game's properties, such as:

game_start_epoch
stake
player
vrf_input
fee_in_bp
Public helper functions
Include utilities like:

fee_amount: Calculates the fee amount based on the stake and fee basis points.
game_exists: Checks if a game exists within the house data.
borrow_game: Retrieves a reference to a game object for further processing.
Internal helper functions
internal_start_game: A core utility that facilitates the creation of a new game, ensuring compliance with stake limits, house balance sufficiency, and the generation of a unique game ID.
plinko::house_data
The plinko::house_data module in the Plinko game is designed to manage the game's treasury and configurations. It's responsible for storing the house funds, setting the game parameters (like maximum and minimum stakes), and handling game fees. It also stores the house public key for verifying game outcomes. The module provides functions to adjust game settings, manage the house funds, and ensure the integrity and fairness of the game through cryptographic verification.

house_data.move
module plinko::house_data {
// === Imports ===
use sui::balance::{Self, Balance};
use sui::sui::SUI;
use sui::coin::{Self, Coin};
use sui::package::{Self};

// === Errors ===
const ECallerNotHouse: u64 = 0;
const EInsufficientBalance: u64 = 1;


// === Structs ===

/// Configuration and Treasury shared object, managed by the house.
public struct HouseData has key {
    id: UID,
    // House's balance which also contains the accrued winnings of the house.
    balance: Balance<SUI>,
    // Address of the house or the game operator.
    house: address,
    // Public key used to verify the beacon produced by the back-end.
    public_key: vector<u8>,
    // Maximum stake amount a player can bet in a single game.
    max_stake: u64,
    // Minimum stake amount required to play the game.
    min_stake: u64,
    // The accrued fees from games played.
    fees: Balance<SUI>,
    // The default fee in basis points. 1 basis point = 0.01%.
    base_fee_in_bp: u16,
    // Multipliers used to calculate winnings based on the game outcome.
    multiplier: vector<u64>
}

/// A one-time use capability to initialize the house data;
/// created and sent to sender in the initializer.
public struct HouseCap has key {
    id: UID
}

/// Used as a one time witness to generate the publisher.
public struct HOUSE_DATA has drop {}

fun init(otw: HOUSE_DATA, ctx: &mut TxContext) {
    // Creating and sending the Publisher object to the sender.
    package::claim_and_keep(otw, ctx);

    // Creating and sending the HouseCap object to the sender.
    let house_cap = HouseCap {
        id: object::new(ctx)
    };

    transfer::transfer(house_cap, ctx.sender());
}

/// Initializer function that should only be called once and by the creator of the contract.
/// Initializes the house data object with the house's public key and an initial balance.
/// It also sets the max and min stake values, that can later on be updated.
/// Stores the house address and the base fee in basis points.
/// This object is involved in all games created by the same instance of this package.
public fun initialize_house_data(house_cap: HouseCap, coin: Coin<SUI>, public_key: vector<u8>, multiplier: vector<u64>, ctx: &mut TxContext) {
    assert!(coin.value() > 0, EInsufficientBalance);

    let mut house_data = HouseData {
        id: object::new(ctx),
        balance: coin.into_balance(),
        house: ctx.sender(),
        public_key,
        max_stake: 10_000_000_000, // 10 SUI = 10^9.
        min_stake: 1_000_000_000, // 1 SUI.
        fees: balance::zero(),
        base_fee_in_bp: 100, // 1% in basis points.
        multiplier: vector[]
    };

    house_data.set_multiplier_vector(multiplier);

    let HouseCap { id } = house_cap;
    object::delete(id);

    transfer::share_object(house_data);
}

// === Public-Mutative Functions ===

public fun update_multiplier_vector(house_data: &mut HouseData, v: vector<u64>, ctx: &mut TxContext) {
    assert!(ctx.sender() == house_data.house(), ECallerNotHouse);
    house_data.multiplier = vector[];
    house_data.set_multiplier_vector(v);
}

/// Function used to top up the house balance. Can be called by anyone.
/// House can have multiple accounts so giving the treasury balance is not limited.
public fun top_up(house_data: &mut HouseData, coin: Coin<SUI>, _: &mut TxContext) {
    coin::put(&mut house_data.balance, coin)
}

/// A function to withdraw the entire balance of the house object.
/// It can be called only by the house
public fun withdraw(house_data: &mut HouseData, ctx: &mut TxContext) {
    // Only the house address can withdraw funds.
    assert!(ctx.sender() == house_data.house(), ECallerNotHouse);

    let total_balance = house_data.balance();
    let coin = coin::take(&mut house_data.balance, total_balance, ctx);
    transfer::public_transfer(coin, house_data.house());
}

/// House can withdraw the accumulated fees of the house object.
public fun claim_fees(house_data: &mut HouseData, ctx: &mut TxContext) {
    // Only the house address can withdraw fee funds.
    assert!(ctx.sender() == house_data.house(), ECallerNotHouse);

    let total_fees = house_data.fees();
    let coin = coin::take(&mut house_data.fees, total_fees, ctx);
    transfer::public_transfer(coin, house_data.house());
}

/// House can update the max stake. This allows larger stake to be placed.
public fun update_max_stake(house_data: &mut HouseData, max_stake: u64, ctx: &mut TxContext) {
    // Only the house address can update the base fee.
    assert!(ctx.sender() == house_data.house(), ECallerNotHouse);

    house_data.max_stake = max_stake;
}

/// House can update the min stake. This allows smaller stake to be placed.
public fun update_min_stake(house_data: &mut HouseData, min_stake: u64, ctx: &mut TxContext) {
    // Only the house address can update the min stake.
    assert!(ctx.sender() == house_data.house(), ECallerNotHouse);

    house_data.min_stake = min_stake;
}

// === Public-View Functions ===

/// Returns the balance of the house.
public fun balance(house_data: &HouseData): u64 {
    house_data.balance.value()
}

/// Returns the address of the house.
public fun house(house_data: &HouseData): address {
    house_data.house
}

/// Returns the public key of the house.
public fun public_key(house_data: &HouseData): vector<u8> {
    house_data.public_key
}

/// Returns the max stake of the house.
public fun max_stake(house_data: &HouseData): u64 {
    house_data.max_stake
}

/// Returns the min stake of the house.
public fun min_stake(house_data: &HouseData): u64 {
    house_data.min_stake
}

/// Returns the fees of the house.
public fun fees(house_data: &HouseData): u64 {
    house_data.fees.value()
}

/// Returns the base fee.
public fun base_fee_in_bp(house_data: &HouseData): u16 {
    house_data.base_fee_in_bp
}

/// Returns the multiplier vector
public fun multiplier(house_data: &HouseData): vector<u64> {
    house_data.multiplier
}

// === Public-Friend Functions ===

/// Returns a reference to the house id.
public(package) fun borrow(house_data: &HouseData): &UID {
    &house_data.id
}

    /// Returns a mutable reference to the balance of the house.
public(package) fun borrow_balance_mut(house_data: &mut HouseData): &mut Balance<SUI> {
    &mut house_data.balance
}

/// Returns a mutable reference to the fees of the house.
public(package) fun borrow_fees_mut(house_data: &mut HouseData): &mut Balance<SUI> {
    &mut house_data.fees
}

/// Returns a mutable reference to the house id.
public(package) fun borrow_mut(house_data: &mut HouseData): &mut UID {
    &mut house_data.id
}

// === Private Functions ===

fun set_multiplier_vector(house_data: &mut HouseData, v: vector<u64>) {
    house_data.multiplier.append(v);
}

// === Test Functions ===

#[test_only]
public fun init_for_testing(ctx: &mut TxContext) {
    init(HOUSE_DATA {}, ctx);
}
}


Error codes
The module defines specific error codes to handle exceptional scenarios:

ECallerNotHouse: Ensures that only the house (game operator) can perform certain operations.
EInsufficientBalance: Indicates an insufficient balance for operations requiring a minimum fund level.
Structures
HouseData: A key configuration object storing the house's operational parameters, including its balance, public key, stake limits, accumulated fees, base fee rate, and multiplier settings for game outcomes.
HouseCap: A unique capability indicating the authority to initialize the house data.
HOUSE_DATA: A one time witness for initializing house data, used once during the setup phase.
Initialization function
init: Prepares the environment for the house, generating essential capabilities and objects for house data management.
Public functions
initialize_house_data: Sets up the initial configuration for the house, including balance, public key, stake limits, and multipliers.
top_up: Allows adding funds to the house's balance to support game operations.
withdraw: Enables the house to withdraw its balance, a critical function with implications for the house's operational capacity.
claim_fees: Permits the house to collect accumulated fees from game activities.
update_max_stake: Adjusts the maximum stake limit for games.
update_min_stake: Modifies the minimum stake requirement.
update_multiplier_vector: Updates the multiplier vector used to calculate game outcomes.
Internal helper functions
set_multiplier_vector: Internally used to set the initial multiplier vector.
Accessors
Provide read-only and mutable access to house data properties, enabling operations like querying balance, stake limits, fees, and modifying configurations within authorized contexts:

balance: Returns the house's current balance.
house: Retrieves the house's address.
public_key: Fetches the public key associated with the house.
max_stake, min_stake: Access the current stake limits.
fees: Shows the accumulated fees from game operations.
base_fee_in_bp: Provides the base fee rate in basis points.
multiplier: Returns the multiplier vector used in game outcome calculations.
Test utilities
init_for_testing: A utility function facilitating module testing by initializing house data within a test environment.
plinko::counter_nft
The plinko::counter_nft module introduces a unique, non-transferable Counter NFT. This Counter object is pivotal for generating a distinct VRF input for each round of the game, thereby ensuring the randomness and fairness of game outcomes. It includes functionalities to create, increment, and destroy these Counter objects. Each Counter is tied to a unique game round and increments its count with each use, providing a fresh input for the game's randomness mechanism.

Unlike traditional NFTs, the Counter NFT is non-transferable, ensuring it remains tied to its original owner and serves its purpose without the risk of duplication or unauthorized transfer.

counter_nft.move
module plinko::counter_nft {
// === Imports ===
use sui::bcs::{Self};

// === Structs ===

/// A Counter object serves as a unique, NFT
/// that increments with each use. It's designed to provide a unique
/// Verifiable Random Function (VRF) input for each round of the game,
/// ensuring the randomness and fairness of game outcomes.
public struct Counter has key {
    id: UID,
    // A numerical value that increments with each use of the Counter.
    // This incrementing behavior is critical for ensuring that each game round
    // receives a fresh, unique input for randomness generation.
    count: u64,
}

/// Deletes a counter object.
entry fun burn(self: Counter) {
    let Counter { id, count: _ } = self;
    object::delete(id);
}

/// Creates a new counter object. Used in combination with the transfer_to_sender method to provide the same
/// UX when creating a Counter NFT for the first time.
public fun mint(ctx: &mut TxContext): Counter {
    Counter {
        id: object::new(ctx),
        count: 0
    }
}

/// Transfers a counter object to the sender.
public fun transfer_to_sender(counter: Counter, ctx: &mut TxContext) {
    transfer::transfer(counter, ctx.sender());
}

/// Generates a unique VRF input by concatenating the Counter's ID, its current count, and the number of balls
/// selected by the player. This composite input ensures each game round has a distinct random seed.
/// The count is incremented after use to maintain uniqueness for subsequent rounds.
public fun get_vrf_input_and_increment(self: &mut Counter, num_balls: u64): vector<u8> {
    let mut vrf_input = object::id_bytes(self);
    let count_to_bytes = bcs::to_bytes(&self.count());
    let num_balls_to_bytes = bcs::to_bytes(&num_balls);
    vrf_input.append(count_to_bytes);
    vrf_input.append(num_balls_to_bytes);
    self.increment();
    vrf_input
}

/// Returns the current count of the counter object.
public fun count(self: &Counter): u64 {
    self.count
}

/// Internal function to increment the counter by 1.
fun increment(self: &mut Counter) {
    self.count = self.count + 1;
}

// === Test Functions ===

#[test_only]
public fun burn_for_testing(self: Counter) {
    self.burn();
}

#[test_only]
public fun get_vrf_input_for_testing(self: &mut Counter): vector<u8> {
    let vrf_input: vector<u8> = self.get_vrf_input_and_increment(1);
    vrf_input
}
}


Structures
Counter: The core structure representing the Counter NFT, which includes a unique identifier (ID) and a count attribute. The count is instrumental in generating a unique VRF input for each game round, incrementing with each use to maintain uniqueness.
Key functions
mint: Creates a new Counter NFT with an initial count of zero. This function is crucial for players initiating their first game, enabling the generation of a fresh VRF input.
transfer_to_sender: Facilitates the transfer of a newly minted Counter NFT to the player's account, ensuring the player has control over their unique game input.
get_vrf_input_and_increment: Generates the VRF input by combining the Counter NFT's ID and current count into a byte vector, then increments the count to prepare for the next game round. This function is central to the game's randomness mechanism, providing a dynamic and unpredictable input for each round.
burn: Allows for the deletion of a Counter NFT. Use this function to remove a Counter NFT from the game ecosystem, ensuring that its unique contribution to game randomness is conclusively retired.
Internal functions
increment: A helper function that increments the count of a Counter NFT by one. This internal mechanism ensures that each Counter NFT's count is always moving forward, reinforcing the uniqueness of each VRF input generated.
Testing utilities
burn_for_testing: A test-only function that facilitates the burning of a Counter NFT within test environments. This utility supports the testing framework by allowing the simulation of Counter NFT lifecycle events without affecting the production environment.
Deployment
Navigate to the setup folder of the Plinko repository and execute the publish.sh script. Refer to the README instructions for deploying the smart contracts and testing them locally.

Frontend
The Plinko component, a central element of the Plinko game's frontend module, is structured to create an interactive and responsive gaming experience. Written in React, it integrates several features and functions to handle the game's logic and user interactions effectively.

State management and setup
State hooks: The module uses React's useState to manage various game states, including finalPaths, isPlaying, totalWon, and more. These states are vital for tracking the current game status and updating the UI accordingly.

Modal for game initialization: A modal is implemented to facilitate the creation of a new game. It captures the randomness and uses handlePlayClick to initiate the game with the backend.

UI components and styling
The MatterSim and PlinkoSettings components are the foundation for the Plinko frontend. To see code for all components and source files, see the Plinko repo.

Simulation component
The MatterSim component plays a pivotal role in the Plinko game by rendering the game board with a realistic physical representation of the dropping Plinko balls. It leverages the robust capabilities of Matter.js, a renowned physics engine, to simulate the intricate dynamics of the Plinko game's environment.

...
import Matter, {
  Engine,
  Render,
  Runner,
  Bodies,
  Composite,
  Vector,
  Events,
  Body,
  Common,
} from "matter-js";
...

The randomness integral to the game's fairness and unpredictability, as detailed in the counter_nft module, dictates the path of each ball dropped by the player. To align the Plinko balls' movement with the predetermined paths derived from on-chain data, MatterSim applies physics principles, such as gravity, to ensure natural ball descent. Additionally, to accurately guide the balls along these specific trajectories, MatterSim introduces subtle, custom forces. These adjustments are calibrated to not only ensure compliance with the paths determined by the game's underlying blockchain mechanics but also to maintain a visually coherent and physically plausible ball movement, to better simulate realism.

Plinko settings component
The PlinkoSettings component is an integral part of the user interface in the Plinko game, enabling players to customize their gameplay experience according to their preferences. This React component allows users to select the number of Plinko balls they want to drop, set the bet size for each ball, and initiate the game round by pressing the Play button.

Customization options
betSize (per ball): Players can specify the amount they want to bet on each ball. This is a crucial feature that allows users to manage their risk and potential rewards.
numberOfBalls: This setting lets players choose how many balls they want to play in a single round, adding a strategic layer to the game as the total bet size is a multiplication of the bet size per ball and the number of balls.
User interaction and feedback
Game Initiation: After selecting the desired number of balls and setting the bet size for each, players can initiate a new game by pressing the Play button. This action starts the game, with the button becoming disabled during gameplay to prevent new games from being initiated until the current game concludes and the last ball has reached the end. Links are also provided for players to view game details on a Sui network explorer for transparency and engagement.

Related links
Plinko repository: The Plinko GitHub repository contains all the source files for this example.
Mysten Plinko: A hosted version of the Plinko game.


Review Rating
The following documentation goes through an example implementation of a review rating platform for the food service industry on Sui. Unlike traditional review rating platforms that often do not disclose the algorithm used to rate reviews, this example uses an algorithm that is published on-chain for everyone to see and verify. The low gas cost of computation on Sui make it financially feasible to submit, score, and order all reviews on-chain.

Personas
There are four actors in the typical workflow of the Reviews Rating example.

Service: Review requester.
Dashboard: Review hub.
Reviewer: Review creator.
Moderator: Review list editor.
Moderator
Review reader
Reviewer
Dashboard
Service
Moderator
Review reader
Reviewer
Dashboard
Service
Add service to dashboard
Send proof of experience
Send review
Send reward
Vote on review
Remove abused review
Service owners
Service owners are entities like restaurants that list their services on the platform. They want to attract more customers by receiving high-rated reviews for their services.

Service owners allocate a specific amount of SUI as a reward pool. Assets from the pool are used to provide rewards for high-rated reviews. A proof of experience (PoE) NFT confirms a reviewer used the service, which the reviewer can burn later to provide a verified review. Service owners provide their customers with unique identifiers (perhaps using QR codes) to identify individual reviewers.

Reviewers
Reviewers are consumers of services that use the review system. Reviewers provide feedback in the form of comments that detail specific aspects of the service as well as a star rating to inform others. The reviews are rated, with the most effective reviews getting the highest rating. Service owners award the 10 highest rated reviews for their service. How often the rewards are distributed is up to the service owner's discretion; for example, the rewards can be distributed once a week or once a month.

Review readers
Review readers access reviews to make informed decisions on selecting services. Readers rate reviews by casting votes. The review readers' ratings are factored into the algorithm that rates the reviews, with the authors of the highest-rated reviews getting rewarded. Although it is not implemented as part of this guide, this example could be extended to award review readers a portion of the rewards for casting votes for reviews.

Moderators
Moderators monitor content of the reviews and can delete any reviews that contain inappropriate content.

The incentive mechanism for moderators is not implemented for this guide, but service owners can all pay into a pool that goes to moderators on a rolling basis. People can stake moderators to influence what portion of the reward each moderator gets, up to a limit (similar to how validators are staked on chain), and moderator decisions are decided by quorum of stake weight. This process installs incentives for moderators to perform their job well.

How reviews are scored
The reviews are scored on chain using the following criteria:

Intrinsic score (IS): Length of review content.
Extrinsic score (ES): Number of votes a review receives.
Verification multiplier (VM): Reviews with PoE receive a multiplier to improve rating.
Total Score = (IS + ES) * VM

Smart contracts
There are several modules that create the backend logic for the example.

dashboard.move
The dashboard.move module defines the Dashboard struct that groups services.

/// Dashboard is a collection of services
public struct Dashboard has key, store {
    id: UID,
    service_type: String
}

The services are grouped by attributes, which can be cuisine type, geographical location, operating hours, Google Maps ID, and so on. To keep it basic, the example stores only service_type (for example, fast food, Chinese, Italian).

/// Creates a new dashboard
public fun create_dashboard(
    service_type: String,
    ctx: &mut TxContext,
) {
    let db = Dashboard {
        id: object::new(ctx),
        service_type
    };
    transfer::share_object(db);
}

/// Registers a service to a dashboard
public fun register_service(db: &mut Dashboard, service_id: ID) {
    df::add(&mut db.id, service_id, service_id);
}

A Dashboard is a shared object, so any service owner can register their service to a dashboard. A service owner should look for dashboards that best match their service attribute and register. A dynamic field stores the list of services that are registered to a dashboard. A service may be registered to multiple dashboards at the same time. For example, a Chinese-Italian fusion restaurant may be registered to both the Chinese and Italian dashboards.

INFO
See Shared versus Owned Objects for more information on the differences between object types.

review.move
This module defines the Review struct.

/// Represents a review of a service
public struct Review has key, store {
    id: UID,
    owner: address,
    service_id: ID,
    content: String,
    // intrinsic score
    len: u64,
    // extrinsic score
    votes: u64,
    time_issued: u64,
    // proof of experience
    has_poe: bool,
    total_score: u64,
    overall_rate: u8,
}

/// Updates the total score of a review
fun update_total_score(rev: &mut Review) {
    rev.total_score = rev.calculate_total_score();
}

/// Calculates the total score of a review
fun calculate_total_score(rev: &Review): u64 {
    let mut intrinsic_score: u64 = rev.len;
    intrinsic_score = math::min(intrinsic_score, 150);
    let extrinsic_score: u64 = 10 * rev.votes;
    // VM = either 1.0 or 2.0 (if user has proof of experience)
    let vm: u64 = if (rev.has_poe) { 2 } else { 1 };
    (intrinsic_score + extrinsic_score) * vm
}

In addition to the content of a review, all the elements that are required to compute total score are stored in a Review object.

A Review is a shared object, so anyone can cast a vote on a review and update its total_score field. After total_score is updated, the update_top_reviews function can be called to update the top_reviews field of the Service object.

service.move
This module defines the Service struct that service owners manage.

const MAX_REVIEWERS_TO_REWARD: u64 = 10;

/// Represents a service
public struct Service has key, store {
    id: UID,
    reward_pool: Balance<SUI>,
    reward: u64,
    top_reviews: vector<ID>,
    reviews: ObjectTable<ID, Review>,
    overall_rate: u64,
    name: String
}

Reward distribution
The same amount is rewarded to top reviewers, and the reward is distributed to 10 participants at most. The pool of SUI tokens to be distributed to reviewers is stored in the reward_pool field, and the amount of SUI tokens awarded to each participant is configured in reward field.

Storage for reviews
Because anyone can submit a review for a service, Service is defined as a shared object. All the reviews are stored in the reviews field, which has ObjectTable<ID, Review> type. The reviews are stored as children of the shared object, but they are still accessible by their ID. In other words, anyone can go to a transaction explorer and find a review object by its object ID, but they won't be able to use a review as an input to a transaction by its object ID.

INFO
See Table and Bag for more information on the differences between Table and ObjectTable.

The top rated reviews are stored in top_reviews field, which has vector<ID> type. A simple vector can store the top rated reviews because the maximum number of reviews that can be rewarded is 10. The elements of top_reviews are sorted by the total_score of the reviews, with the highest rated reviews coming first. The vector contains the ID of the reviews, which can be used to retrieve content and vote count from the relevant reviews.

Casting votes
A reader can cast a vote on a review to rate it as follows:

/// Upvotes a review and reorders top_reviews
public fun upvote(service: &mut Service, review_id: ID) {
    let review = &mut service.reviews[review_id];
    review.upvote();
    service.reorder(review_id, review.get_total_score());
}

/// Reorders top_reviews after a review is updated
/// If the review is not in top_reviews, it will be added if it is in the top 10
/// Otherwise, it will be reordered
fun reorder(
    service: &mut Service,
    review_id: ID,
    total_score: u64
) {
    let (contains, idx) = service.top_reviews.index_of(&review_id);
    if (!contains) {
        service.update_top_reviews(review_id, total_score);
    } else {
        service.top_reviews.remove(idx);
        let idx = service.find_idx(total_score);
        service.top_reviews.insert(review_id, idx);
    }
}

/// Updates top_reviews if necessary
fun update_top_reviews(
    service: &mut Service,
    review_id: ID,
    total_score: u64
) {
    if (service.should_update_top_reviews(total_score)) {
        let idx = service.find_idx(total_score);
        service.top_reviews.insert(review_id, idx);
        service.prune_top_reviews();
    };
}

/// Finds the index of a review in top_reviews
fun find_idx(service: &Service, total_score: u64): u64 {
    let mut i = service.top_reviews.length();
    while (0 < i) {
        let review_id = service.top_reviews[i - 1];
        if (service.get_total_score(review_id) > total_score) {
            break
        };
        i = i - 1;
    };
    i
}

/// Prunes top_reviews if it exceeds MAX_REVIEWERS_TO_REWARD
fun prune_top_reviews(
    service: &mut Service
) {
    let len = service.top_reviews.length();
    if (len > MAX_REVIEWERS_TO_REWARD) {
        service.top_reviews.pop_back();
    };
}

Whenever someone casts a vote on a review, the total_score of the review is updated and the update_top_reviews function updates the top_reviews field, as needed. Casting a vote also triggers a reordering of the top_reviews field to ensure that the top rated reviews are always at the top.

Authorization
/// A capability that can be used to perform admin operations on a service
struct AdminCap has key, store {
    id: UID,
    service_id: ID
}

/// Represents a moderator that can be used to delete reviews
struct Moderator has key {
    id: UID,
}

This example follows a capabilities pattern to manage authorizations. For example, SERVICE OWNERS are given AdminCap and MODERATORS are given Moderator such that only they are allowed to perform privileged operations.

To learn more about the capabilities pattern, see The Move Book.

Deployment
Navigate to the setup folder of the repository and execute the publish.sh script. Refer to the README instructions for deploying the smart contracts.

Frontend
The frontend module is written in React, and is structured to provide a responsive user experience for interacting with a review rating platform. The page component supports user log in as a SERVICE OWNER, a MODERATOR, or a REVIEWER. A REVIEW READER role is not implemented for this example, but a REVIEWER can also read reviews and cast votes.

Directories structure
The frontend is a NextJS project, that follows the NextJS App Router project structure. The main code of the frontend is located in the app/src/ directory.

The main sub-directories are:

app/: The main code of the pages and the global styles.
components/: The reusable components of the app, organized in sub-directories.
hooks/: The custom hooks used in the app.
moderator/: The pages for MODERATOR.
serviceOwner/: The pages for SERVICE OWNER.
types/: The types/interfaces used in the app.
user/: The pages for REVIEWER.
Connect button
The Wallet Kit comes with a pre-built React.js component called ConnectButton that displays a button to connect and disconnect a wallet. The component handles connecting and disconnecting wallet logic.

Place the ConnectButton in the navigation bar for users to connect their wallets:

src/app/components/navbar/Navbar.tsx
import { ConnectButton } from '@mysten/wallet-kit';
import { usePathname } from 'next/navigation';

import { useAuthentication } from '@/app/hooks/useAuthentication';

export const Navbar = () => {
	const pathname = usePathname();
	console.log(pathname);
	const { user, handleLogout } = useAuthentication();

	return (
		<div
			className="grid grid-cols-12 w-full items-center p-[8px] h-[80px] border-b-gray-400 border-b-[1px] sticky top-0"
			style={{
				background: 'white',
			}}
		>
			<div className="col-span-3 flex space-x-3 items-center">
				<div className="text-red-600 text-2xl font-bold cursor-pointer" onClick={handleLogout}>
					Restaurant Reviews
				</div>
			</div>

			<div className="col-span-6 flex space-x-3 justify-center">
				{pathname !== '/' && (
					<h6 className="mb-4 text-2xl leading-none tracking-tight text-gray-400">
						logged in as{' '}
						<span className="underline underline-offset-3 decoration-8 decoration-blue-400 dark:decoration-blue-600">
							{user.role === 'user' && 'USER'}
							{user.role === 'serviceOwner' && 'SERVICE OWNER'}
							{user.role === 'moderator' && 'MODERATOR'}
						</span>
					</h6>
				)}
			</div>

			<div className="col-span-3 flex justify-end gap-[14px]">
				<ConnectButton />
			</div>
		</div>
	);
};


Type definitions
All the type definitions are in src/app/types/.

Review and Service represent the review and service objects.

src/app/types/Review.ts
export interface Review {
	id: string;
	owner: string;
	service_id: string;
	content: string;
	len: number;
	votes: number;
	time_issued: number;
	has_poe: boolean;
	total_score: number;
}

src/app/types/Service.ts
export interface Service {
	id: string;
	name: string;
	stars: number;
	reward?: number;
	pool?: number;
}

Execute transaction hook
In the frontend, you might need to execute a transaction block in multiple places, hence it's better to extract the transaction execution logic and reuse it everywhere. Let's examine the execute transaction hook.

src/app/hooks/useSignAndExecuteTransaction.ts
import { Transaction } from '@mysten/sui/transactions';
import { useWalletKit } from '@mysten/wallet-kit';
import { toast } from 'react-hot-toast';

import { useSui } from './useSui';

export const useSignAndExecuteTransaction = () => {
	const { executeSignedTransaction } = useSui();
	const { signTransaction } = useWalletKit();
	const handleSignAndExecuteTransaction = async (
		tx: Transaction,
		operation: String,
		setIsLoading: any,
	) => {
		return signTransaction({
			transaction: tx,
		})
			.then((signedTx: any) => {
				return executeSignedTransaction({
					signedTx,
					requestType: 'WaitForLocalExecution',
					options: {
						showEffects: true,
						showEvents: true,
					},
				})
					.then((resp) => {
						setIsLoading(false);
						console.log(resp);
						if (resp.effects?.status.status === 'success') {
							console.log(`${operation} operation successful`);
							toast.success(`${operation} operation successful`);
							return;
						} else {
							console.log(`${operation} operation failed`);
							toast.error(`${operation} operation failed.`);
							return;
						}
					})
					.catch((err) => {
						setIsLoading(false);
						console.log(`${operation} operation failed`);
						console.log(`${operation} error : `, err);
						toast.error(`Something went wrong, ${operation} operation failed.`);
					});
			})
			.catch((err) => {
				setIsLoading(false);
				console.log(`signing goes wrong ${operation} error : `, err);
				toast.error(`signing goes wrong, ${operation} operation failed.`);
			});
	};
	return { handleSignAndExecuteTransaction };
};


A Transaction is the input, sign it with the current connected wallet account, execute the transaction block, return the execution result, and finally display a basic toast message to indicate whether the transaction is successful or not.

Use the useWalletKit() hook from the Wallet Kit to retrieve the Sui client instance configured in WalletKitProvider. The signTransaction() function is another hook that helps to sign the transaction block using the currently connected wallet. It displays the UI for users to review and sign their transactions with their selected wallet. To execute a transaction block, the executeSignedTransaction() on the Sui client instance of the Sui TypeScript SDK. Use react-hot-toast as another dependency to toast transaction status to users.

Components and custom hooks for state management
Custom hooks: To keep the code as structured as possible, multiple custom hooks are utilized to manage the list of reviews associated with a service. The useGetReviews custom hook encapsulates the service, exposing all the required information (with fields such as nameOfService, listOfReviews, listOfStars) to display the reviews in a table. Multiple additional custom hooks, such as useDashboardCreation, and useServiceReview are encapsulating their own piece of state and logic to make the code readable and maintainable.

Component for adding a new review: The AddReview component is implemented to facilitate the creation of a new review. It is rendered by the servicePage to collect a review entry from a USER and uses the signAndExecuteTransaction function of the [useWalletKit] hook to execute the transaction.

Proof of experience generation: PoE is an NFT that is minted by SERVICE OWNER for customers after they dine at the restaurant; customers can then burn the PoE to write a high-rated review later. Minting an NFT is facilitated by the ownedServicePage component. This component is using the useServicePoEGeneration custom hook.

Delete a review: The moderator can delete a review that contains inappropriate content. moderatorRemovePage component is used to delete a review.

Tic-Tac-Toe
This guide covers three different implementations of the game tic-tac-toe on Sui. The first example utilizes a centralized admin that marks the board on the users’ behalf. The second example utilizes a shared object that both users can mutate. And the third example utilizes a multisig, where instead of sharing the game board, it's in a 1-of-2 multisig of both users’ accounts. This guide compares and contrasts the design philosophies behind the three different games, as well as the pros and cons of each.

tic_tac_toe.move
In this first example of tic-tac-toe, the game object, including the game board, is controlled by a game admin.

public struct TicTacToe has key {
    id: UID,
    gameboard: vector<vector<Option<Mark>>>,
    cur_turn: u8,
    game_status: u8,
    x_address: address,
    o_address: address,
}

Because the players don’t own the game board, they cannot directly mutate it. Instead, they indicate their move by creating a marker object with their intended placement and send it to the admin.

public struct Mark has key, store {
    id: UID,
    player: address,
    row: u64,
    col: u64,
}

The main logic of the game is in the following create_game function.

/// `x_address` and `o_address` are the account address of the two players.
public entry fun create_game(x_address: address, o_address: address, ctx: &mut TxContext) {
    // TODO: Validate sender address, only GameAdmin can create games.

    let id = object::new(ctx);
    let game_id = id.to_inner();
    let gameboard = vector[
        vector[option::none(), option::none(), option::none()],
        vector[option::none(), option::none(), option::none()],
        vector[option::none(), option::none(), option::none()],
    ];
    let game = TicTacToe {
        id,
        gameboard,
        cur_turn: 0,
        game_status: IN_PROGRESS,
        x_address: x_address,
        o_address: o_address,
    };
    transfer::transfer(game, ctx.sender());
    let cap = MarkMintCap {
        id: object::new(ctx),
        game_id,
        remaining_supply: 5,
    };
    transfer::transfer(cap, x_address);
    let cap = MarkMintCap {
        id: object::new(ctx),
        game_id,
        remaining_supply: 5,
    };
    transfer::transfer(cap, o_address);
}


Some things to note:

The game exists as an owned object in the game admin’s account.
The board is initialized as a 3x3 vector of vectors, instantiated via option::none().
Both players get five MarkMintCaps each, giving them the capability to place a maximum of five marks each.
When playing the game, the admin operates a service that keeps track of these placement requests. When a request is received (send_mark_to_game), the admin tries to place the marker on the board (place_mark). Each move requires two steps (thus two transactions): one from the player and one from the admin. This setup relies on the admin's service to keep the game moving.

/// Generate a new mark intended for location (row, col).
/// This new mark is not yet placed, just transferred to the game.
public entry fun send_mark_to_game(
    cap: &mut MarkMintCap,
    game_address: address,
    row: u64,
    col: u64,
    ctx: &mut TxContext,
) {
    if (row > 2 || col > 2) {
        abort EInvalidLocation
    };
    let mark = mint_mark(cap, row, col, ctx);
    // Once an event is emitted, it should be observed by a game server.
    // The game server will then call `place_mark` to place this mark.
    event::emit(MarkSentEvent {
        game_id: *&cap.game_id,
        mark_id: object::id(&mark),
    });
    transfer::public_transfer(mark, game_address);
}

public entry fun place_mark(game: &mut TicTacToe, mark: Mark, ctx: &mut TxContext) {
    // If we are placing the mark at the wrong turn, or if game has ended,
    // destroy the mark.
    let addr = game.get_cur_turn_address();
    if (game.game_status != IN_PROGRESS || &addr != &mark.player) {
        mark.delete();
        return
    };
    let cell = get_cell_mut_ref(game, mark.row, mark.col);
    if (cell.is_some()) {
        // There is already a mark in the desired location.
        // Destroy the mark.
        mark.delete();
        return
    };
    cell.fill(mark);
    game.update_winner();
    game.cur_turn = game.cur_turn + 1;

    if (game.game_status != IN_PROGRESS) {
        // Notify the server that the game ended so that it can delete the game.
        event::emit(GameEndEvent { game_id: object::id(game) });
        if (game.game_status == X_WIN) {
            transfer::transfer(Trophy { id: object::new(ctx) }, *&game.x_address);
        } else if (game.game_status == O_WIN) {
            transfer::transfer(Trophy { id: object::new(ctx) }, *&game.o_address);
        }
    }
}

To view the entire source code, see the tic_tac_toe.move source file. You can find the rest of the logic, including how to check for a winner, as well as deleting the gameboard after the game concludes there.

An alternative version of this game, shared tic-tac-toe, uses shared objects for a more straightforward implementation that doesn't use a centralized service. This comes at a slightly increased cost, as using shared objects is more expensive than transactions involving wholly owned objects.

shared_tic_tac_toe.move
In the previous version, the admin owned the game object, preventing players from directly changing the gameboard, as well as requiring two transactions for each marker placement. In this version, the game object is a shared object, allowing both players to access and modify it directly, enabling them to place markers in just one transaction. However, using a shared object generally incurs extra costs because Sui needs to sequence the operations from different transactions. In the context of this game, where players are expected to take turns, this shouldn't significantly impact performance. Overall, this shared object approach simplifies the implementation compared to the previous method.

As the following code demonstrates, the TicTacToe object in this example is almost identical to the one before it. The only difference is that the gameboard is represented as vector<vector<u8>> instead of vector<vector<Option<Mark>>>. The reason for this approach is explained following the code.

public struct TicTacToe has key {
    id: UID,
    gameboard: vector<vector<u8>>,
    cur_turn: u8,
    game_status: u8,
    x_address: address,
    o_address: address,
}

Take a look at the create_game function:

/// `x_address` and `o_address` are the account address of the two players.
public entry fun create_game(x_address: address, o_address: address, ctx: &mut TxContext) {
    // TODO: Validate sender address, only GameAdmin can create games.

    let id = object::new(ctx);
    let gameboard = vector[
        vector[MARK_EMPTY, MARK_EMPTY, MARK_EMPTY],
        vector[MARK_EMPTY, MARK_EMPTY, MARK_EMPTY],
        vector[MARK_EMPTY, MARK_EMPTY, MARK_EMPTY],
    ];
    let game = TicTacToe {
        id,
        gameboard,
        cur_turn: 0,
        game_status: IN_PROGRESS,
        x_address: x_address,
        o_address: o_address,
    };
    // Make the game a shared object so that both players can mutate it.
    transfer::share_object(game);
}


As the code demonstrates, each position on the board is replaced with MARK_EMPTY instead of option::none(). Instead of the game being sent to the game admin, it is instantiated as a shared object. The other notable difference is that there is no need to mint MarkMintCaps to the two players anymore, because the only two addresses that can play this game are x_address and o_address, and this is checked in the next function, place_mark:

public entry fun place_mark(game: &mut TicTacToe, row: u8, col: u8, ctx: &mut TxContext) {
    assert!(row < 3 && col < 3, EInvalidLocation);
    assert!(game.game_status == IN_PROGRESS, EGameEnded);
    let addr = game.get_cur_turn_address();
    assert!(addr == ctx.sender(), EInvalidTurn);

    let cell = &mut game.gameboard[row as u64][col as u64];
    assert!(*cell == MARK_EMPTY, ECellOccupied);

    *cell = game.cur_turn % 2;
    game.update_winner();
    game.cur_turn = game.cur_turn + 1;

    if (game.game_status != IN_PROGRESS) {
        // Notify the server that the game ended so that it can delete the game.
        event::emit(GameEndEvent { game_id: object::id(game) });
        if (game.game_status == X_WIN) {
            transfer::transfer(Trophy { id: object::new(ctx) }, game.x_address);
        } else if (game.game_status == O_WIN) {
            transfer::transfer(Trophy { id: object::new(ctx) }, game.o_address);
        }
    }
}


You can find the full source code in shared_tic_tac_toe.move

multisig_tic_tac_toe.move
In this implementation of the game, the game is in a 1-of-2 multisig account that acts as the game admin. In this particular case, because there are only two players, the previous example is a more convenient use case. However, this example illustrates that in some cases, a multisig can replace shared objects, thus allowing transactions to bypass consensus when using such an implementation.

Examine the two main objects in this game, TicTacToe, and Mark:

/// TicTacToe struct should be owned by the game-admin.
/// This should be the multisig 1-out-of-2 account for both players to make moves.
public struct TicTacToe has key {
    id: UID,
    /// Column major 3x3 game board
    gameboard: vector<u8>,
    /// Index of current turn
    cur_turn: u8,
    x_addr: address,
    o_addr: address,
    /// 0 not finished, 1 X Winner, 2 O Winner, 3 Draw
    finished: u8
}

/// Mark is passed between game-admin (Multisig 1-out-of-2), x-player and o-player.
public struct Mark has key {
    id: UID,
    /// Column major 3x3 placement
    placement: Option<u8>,
    /// Flag that sets when the Mark is owned by a player
    during_turn: bool,
    /// Multi-sig account to place the mark
    game_owners: address,
    /// TicTacToe object this mark is part of
    game_id: ID
}

The biggest difference in this TicTacToe object is that gameboard is a vector<u8>, but otherwise the main functionality of the gameboard is the same. The Mark object makes a reappearance in this version, as we need a way to identify the current player’s turn (this was accomplished in the shared version of the game in the TicTacToe object itself).

The create_game function is fairly similar to one in the previous two versions:

/// This should be called by a multisig (1 out of 2) address.
/// x_addr and o_addr should be the two addresses part-taking in the multisig.
public fun create_game(x_addr: address, o_addr: address, ctx: &mut TxContext) {
    let id = object::new(ctx);
    let game_id = id.to_inner();

    let tic_tac_toe = TicTacToe {
        id,
        gameboard: vector[MARK_EMPTY, MARK_EMPTY, MARK_EMPTY,
                           MARK_EMPTY, MARK_EMPTY, MARK_EMPTY,
                           MARK_EMPTY, MARK_EMPTY, MARK_EMPTY],
        cur_turn: 0,
        x_addr,
        o_addr,
        finished: 0
    };
    let mark = Mark {
        id: object::new(ctx),
        placement: option::none(),
        during_turn: true, // Mark is passed to x_addr
        game_owners: ctx.sender(),
        game_id
    };

    transfer::transfer(tic_tac_toe, ctx.sender());
    transfer::transfer(mark, x_addr);
}

Now take a look at send_mark_to_game and place_mark:

/// This is called by the one of the two addresses participating in the multisig, but not from
/// the multisig itself.
/// row: [0 - 2], col: [0 - 2]
public fun send_mark_to_game(mark: Mark, row: u8, col: u8) {
    // Mark.during_turn prevents multisig-acc from editing mark.placement after it has been sent to it.
    assert!(mark.during_turn, ETriedToCheat);

    mark.placement.fill(get_index(row, col));
    mark.during_turn = false;
    let game_owners = mark.game_owners;
    transfer::transfer(mark, game_owners);
}

/// This is called by the multisig account to execute the last move by the player who used
/// `send_mark_to_game`.
public fun place_mark(game: &mut TicTacToe, mark: Mark, ctx: &mut TxContext) {
    assert!(mark.game_id == game.id.to_inner(), EMarkIsFromDifferentGame);

    let addr = get_cur_turn_address(game);
    // Note here we empty the option
    let placement: u8 = mark.placement.extract();
    if (game.gameboard.get_cell_by_index(placement) != MARK_EMPTY) {
        mark.during_turn = true;
        transfer::transfer(mark, addr);
        return
    };

    // Apply turn
    let mark_symbol = if (addr == game.x_addr) {
        MARK_X
    } else {
        MARK_O
    };
    * &mut game.gameboard[placement as u64] = mark_symbol;

    // Check for winner
    let winner = game.get_winner();

    // Game ended!
    if (winner.is_some()) {
        let played_as = winner.extract();
        let (winner, loser, finished) = if (played_as == MARK_X) {
            (game.x_addr, game.o_addr, 1)
        } else {
            (game.o_addr, game.x_addr, 2)
        };

        transfer::transfer(
            TicTacToeTrophy {
                id: object::new(ctx),
                winner,
                loser,
                played_as,
                game_id: game.id.to_inner()
            },
            winner
        );

        mark.delete();
        * &mut game.finished = finished;
        return
    } else if (game.cur_turn >= 8) {    // Draw
        make.delete();
        * &mut game.finished = 3;
        return
    };

    // Next turn
    * &mut game.cur_turn = game.cur_turn + 1;
    addr = game.get_cur_turn_address();
    mark.during_turn = true;
    transfer::transfer(mark, addr);
}


The first function is straightforward. The player sends the location of the mark to the multisig account. Then in the next function, the multisig actually places down the mark the player requested, as well as all the logic to check to see if there is a winner, end the game, and award a player a trophy if so, or to advance to the next player’s turn if not. See the multisig_tic-tac-toe repo for the full source code on this version of the game.


Sui Developer Cheat Sheet
Quick reference on best practices for Sui Network developers.

Move
General
Read about package upgrades and write upgrade-friendly code:
Packages are immutable, so buggy package code can be called forever. Add protections at the object level instead.
If you upgrade a package P to P', other packages and clients that depend on P will continue using P, not auto-update to P'. Both dependent packages and client code must be explicitly updated to point at P'.
Packages that expect to be extended by dependent packages can avoid breaking their extensions with each upgrade by providing a standard (unchanging) interface that all versions conform to. See this example for message sending across a bridge from Wormhole. Extension packages that produce messages to send can use prepare_message from any version of the Wormhole package to produce a MessageTicket while client code to send the message must pass that MessageTicket into publish_message in the latest version of the package.
public function signatures cannot be deleted or changed, but public(friend) functions can. Use public(friend) or private visibility liberally unless you are exposing library functions that will live forever.
It is not possible to delete struct types, add new fields (though you can add dynamic fields), or add new abilities via an upgrade. Introduce new types carefully—they will live forever!
Use vector-backed collections (vector, VecSet, VecMap, PriorityQueue) with a known maximum size of ≤ 1000 items.
Use dynamic field-backed collections (Table, Bag, ObjectBag, ObjectTable, LinkedTable) for any collection that allows third-party addition, larger collections, and collections of unknown size.
Move objects have a maximum size of 250KB—any attempt to create a larger object leads to an aborted transaction. Ensure that your objects do not have an ever-growing vector-backed collection.
If your function f needs a payment in (e.g.) SUI from the caller, use fun f(payment: Coin<SUI>) not fun f(payment: &mut Coin<SUI>, amount: u64). This is safer for callers—they know exactly how much they are paying, and do not need to trust f to extract the right amount.
Don't micro-optimize gas usage. Sui computation costs are rounded up to the closest bucket, so only very drastic changes will make a difference. In particular, if your transaction is already in the lowest cost bucket, it can't get any cheaper.
Follow the Move coding conventions for consistent style.
Composability
Use the display standard to customize how your objects show up in wallets, apps, and explorers
Avoid “self-transfers”—whenever possible, instead of writing transfer::transfer(obj, tx_context::sender(ctx)), return obj from the current function. This allows a caller or programmable transaction block to use obj.
Testing
Use sui::test_scenario to mimic multi-transaction, multi-sender test scenarios.
Use the sui::test_utils module for better test error messages via assert_eq, debug printing via print, and test-only destruction via destroy.
Use sui move test --coverage to compute code coverage information for your tests, and sui move coverage source --module <name> to see uncovered lines highlighted in red. Push coverage all the way to 100% if feasible.
Apps
For optimal performance and data consistency, apps should submit writes and reads for the same full node. In the TS SDK, this means that apps should use the wallet's signTransactionBlock API, then submit the transaction via a call to execute_transactionBlock on the app's full node, not use the wallet's signAndExecuteTransactionBlock API. This ensures read-after-write-consistency--reads from the app's full node will reflect writes from the transaction right away instead of waiting for a checkpoint.
For lower latency, use executeTransactionBlock with "showEffects": false and "showEvents": false if your app needs to know that a transaction was confirmed, but does not immediately need to see the transaction effects or read the objects/events written by the transaction.
Apps should implement a local cache for frequently read data rather than over-fetching from the full node.
Whenever possible, use programmable transaction blocks to compose existing on-chain functionality rather than publishing new smart contract code. Programmable transaction blocks allow large-scale batching and heterogeneous composition, driving already-low gas fees down even further.
Apps should leave gas budget, gas price, and coin selection to the wallet. This gives wallets more flexibility, and it's the wallet's responsibility to dry run a transaction to ensure it doesn't fail.
Signing
Never sign two concurrent transactions that are touching the same owned object. Either use independent owned objects, or wait for one transaction to conclude before sending the next one. Violating this rule might lead to client equivocation, which locks up the owned objects involved in the two transactions until the end of the current epoch.
Any sui client command that crafts a transaction (e.g., sui client publish, sui client call) can accept the --serialize-output flag to output a base64 transaction to be signed.
Sui supports several signature schemes for transaction signing, including native multisig.
zkLogin
Call the proving service as sparingly as possible. Design your app flows such that you call the proving service only when the user is about to perform a real transaction.
Beware of how you cache the ephemeral private key. Treat the private key akin to a piece of highly sensitive data, e.g., password. If an (unexpired) ephemeral private key and its corresponding ZK proof are leaked, then an attacker can steal user's assets.

Operator Guides
Operator guides demonstrate how to run Full nodes on Sui, whether as a validator or operator of a Full node to support your dApp, as well as how to integrate SUI into an exchange.

Sui Full node operators
Guides that inform Full node operators include:

Sui Full Node Configuration
Sui validators
Guides that inform validators how to operate on Sui include:

Validator Committee
Validator Configuration
Validator Tasks
Sui Full node operators and validators
Guides that benefit both Full node operators and validators include:

Data Management
Genesis
Snapshots
Archives
Exchange integration guide
The Sui Exchange Integration Guide provides step-by-step instructions on how to integrate SUI into a cryptocurrency exchange.

Sui Full Node Configuration
INFO
These instructions are for advanced users. If you just need a local development environment, you should instead follow the instructions in Create a Local Sui Network to create a local Full node, validators, and faucet.

Sui Full nodes validate blockchain activities, including transactions, checkpoints, and epoch changes. Each Full node stores and services the queries for the blockchain state and history.

This role enables validators to focus on servicing and processing transactions. When a validator commits a new set of transactions (or a block of transactions), the validator pushes that block to all connected Full nodes that then service the queries from clients.

Features
Sui Full nodes:

Track and verify the state of the blockchain, independently and locally.
Serve read requests from clients.
State synchronization
Sui Full nodes sync with validators to receive new transactions on the network.

A transaction requires a few round trips to 2f+1 validators to form a transaction certificate (TxCert).

This synchronization process includes:

Following 2f+1 validators and listening for newly committed transactions.
Making sure that 2f+1 validators recognize the transaction and that it reaches finality.
Executing the transaction locally and updating the local DB.
This synchronization process requires listening to at a minimum 2f+1 validators to ensure that a Full node has properly processed all new transactions. Sui will improve the synchronization process with the introduction of checkpoints and the ability to synchronize with other Full nodes.

Architecture
A Sui Full node is essentially a read-only view of the network state. Unlike validator nodes, Full nodes cannot sign transactions, although they can validate the integrity of the chain by re-executing transactions that a quorum of validators previously committed.

Today, a Sui Full node maintains the full history of the chain.

Validator nodes store only the latest transactions on the frontier of the object graph (for example, transactions with >0 unspent output objects).

Full node setup
Follow the instructions here to run your own Sui Full.

Hardware requirements
Suggested minimum hardware to run a Sui Full node:

CPUs: 8 physical cores / 16 vCPUs
RAM: 128 GB
Storage (SSD): 4 TB NVMe drive
Software requirements
Sui recommends running Sui Full nodes on Linux. Sui supports the Ubuntu and Debian distributions. You can also run a Sui Full node on macOS.

Make sure to update Rust.

Use the following command to install additional Linux dependencies.

sudo apt-get update \
&& sudo apt-get install -y --no-install-recommends \
tzdata \
libprotobuf-dev \
ca-certificates \
build-essential \
libssl-dev \
libclang-dev \
libpq-dev \
pkg-config \
openssl \
protobuf-compiler \
git \
clang \
cmake

Configure a Full node
You can configure a Sui Full node either using Docker or by building from source.

Using Docker Compose
Follow the instructions in the Full node Docker Readme to run a Sui Full node using Docker, including resetting the environment.

Setting up a local Sui repository
You must get the latest source files from the Sui GitHub repository.

Set up your fork of the Sui repository:
Go to the Sui repository on GitHub and click the Fork button in the top right-hand corner of the screen.
Clone your personal fork of the Sui repository to your local machine (ensure that you insert your GitHub username into the URL): git clone https://github.com/<YOUR-GITHUB-USERNAME>/sui.git
cd into your sui repository: cd sui
Set up the Sui repository as a git remote: git remote add upstream https://github.com/MystenLabs/sui
Sync your fork: git fetch upstream
Check out the branch associated with the network version you want to run (for example, devnet to run a Devnet Full node): git checkout --track upstream/<BRANCH-NAME>
Setting up a Full node from source
Open a terminal or console to the sui directory you downloaded in the previous steps to complete the following:

Install the required prerequisites.

Make a copy of the Full node YAML template: cp crates/sui-config/data/fullnode-template.yaml fullnode.yaml

Download the genesis blob for the network to use:

Devnet genesis blob: curl -fLJO https://github.com/MystenLabs/sui-genesis/raw/main/devnet/genesis.blob
Testnet genesis blob: curl -fLJO https://github.com/MystenLabs/sui-genesis/raw/main/testnet/genesis.blob
Mainnet genesis blob: curl -fLJO https://github.com/MystenLabs/sui-genesis/raw/main/mainnet/genesis.blob
For Testnet or Mainnet: Edit the fullnode.yaml file to include peer nodes for state synchronization. Append the following to the end of the current configuration:

Mainnet
Testnet
p2p-config:
  seed-peers:
    - address: /dns/mel-00.mainnet.sui.io/udp/8084
      peer-id: d32b55bdf1737ec415df8c88b3bf91e194b59ee3127e3f38ea46fd88ba2e7849
    - address: /dns/ewr-00.mainnet.sui.io/udp/8084
      peer-id: c7bf6cb93ca8fdda655c47ebb85ace28e6931464564332bf63e27e90199c50ee
    - address: /dns/ewr-01.mainnet.sui.io/udp/8084
      peer-id: 3227f8a05f0faa1a197c075d31135a366a1c6f3d4872cb8af66c14dea3e0eb66
    - address: /dns/lhr-00.mainnet.sui.io/udp/8084
      peer-id: c619a5e0f8f36eac45118c1f8bda28f0f508e2839042781f1d4a9818043f732c
    - address: /dns/sui-mainnet-ssfn-1.nodeinfra.com/udp/8084
      peer-id: 0c52ca8d2b9f51be4a50eb44ace863c05aadc940a7bd15d4d3f498deb81d7fc6
    - address: /dns/sui-mainnet-ssfn-2.nodeinfra.com/udp/8084
      peer-id: 1dbc28c105aa7eb9d1d3ac07ae663ea638d91f2b99c076a52bbded296bd3ed5c
    - address: /dns/sui-mainnet-ssfn-ashburn-na.overclock.run/udp/8084
      peer-id: 5ff8461ab527a8f241767b268c7aaf24d0312c7b923913dd3c11ee67ef181e45
    - address: /dns/sui-mainnet-ssfn-dallas-na.overclock.run/udp/8084
      peer-id: e1a4f40d66f1c89559a195352ba9ff84aec28abab1d3aa1c491901a252acefa6
    - address: /dns/ssn01.mainnet.sui.rpcpool.com/udp/8084
      peer-id: fadb7ccb0b7fc99223419176e707f5122fef4ea686eb8e80d1778588bf5a0bcd
    - address: /dns/ssn02.mainnet.sui.rpcpool.com/udp/8084
      peer-id: 13783584a90025b87d4604f1991252221e5fd88cab40001642f4b00111ae9b7e

Optional: Skip this step to accept the default paths to resources. Edit the fullnode.yaml file to use custom paths.

Update the db-path field with the path to the Full node database. db-path: "/db-files/sui-fullnode"

Update the genesis-file-location with the path to genesis.blob.

genesis:
    genesis-file-location: "/sui-fullnode/genesis.blob"

Starting services
At this point, your Sui Full node is ready to connect to the Sui network.

Open a terminal or console to the sui directory.
Start the Sui Full node: cargo run --release --bin sui-node -- --config-path fullnode.yaml
Optional: Publish/subscribe to notifications using JSON-RPC via websocket.
If your setup is successful, your Sui Full node is now connected to the appropriate network.

Your Full node serves the read endpoints of the Sui JSON-RPC API at: http://127.0.0.1:9000.

Troubleshooting
If you receive a cannot find -lpq error, you are missing the libpq library. Use sudo apt-get install libpq-dev to install on Linux, or brew install libpq on MacOS. After you install on MacOS, create a Homebrew link using brew link --force libpq. For further context, reference the issue on Stack Overflow.

If you receive the following error:

panicked at error binding to 0.0.0.0:9184: error creating server listener: Address already in use (os error 98)


Then update the metrics address in your fullnode.yaml file to use port 9180.

metrics-address: "0.0.0.0:9180"

Monitoring
Monitor your Full node using the instructions at Logging, Tracing, Metrics, and Observability.

The default metrics port is 9184. To change the port, edit your fullnode.yaml file.

Update your Full node
Whenever Sui releases a new version, you must update your Full node with the release to ensure compatibility with the network it connects to. For example, if you use Sui Testnet you should install the version of Sui running on Sui Testnet.

Update with Docker Compose
Follow the instructions to reset the environment, namely by running the command:

docker-compose down --volumes

Update from source
If you followed the instructions for Building from Source, use the following steps to update your Full node:

Shut down your running Full node.
cd into your local Sui repository:
cd sui

Remove the database and 'genesis.blob' file:
rm -r suidb genesis.blob

Fetch the source from the latest release:
git fetch upstream

Reset your branch:
git checkout -B <BRANCH-NAME> --track upstream/<BRANCH-NAME>

Download the latest genesis blob:
Devnet genesis blob:
curl -fLJO https://github.com/MystenLabs/sui-genesis/raw/main/devnet/genesis.blob

Testnet genesis blob:
curl -fLJO https://github.com/MystenLabs/sui-genesis/raw/main/testnet/genesis.blob

Update your fullnode.yaml configuration file, if needed.
Restart your Sui Full node:
cargo run --release --bin sui-node -- --config-path fullnode.yaml

Your Full node starts on: http://127.0.0.1:9000.

Object pruning
Sui adds new object versions to the database as part of transaction execution. This makes previous versions ready for garbage collection. However, without pruning, this can result in database performance degradation and requires large amounts of storage space. Sui identifies the objects that are eligible for pruning in each checkpoint, and then performs the pruning in the background.

You can enable pruning for a Sui node by adding the authority-store-pruning-config config to fullnode.yaml file:

authority-store-pruning-config:
  # Number of epoch dbs to keep 
  # Not relevant for object pruning
  num-latest-epoch-dbs-to-retain: 3
  # The amount of time, in seconds, between running the object pruning task.
  # Not relevant for object pruning
  epoch-db-pruning-period-secs: 3600
  # Number of epochs to wait before performing object pruning.
  # When set to 0, Sui prunes old object versions as soon
  # as possible. This is also called *aggressive pruning*, and results in the most effective
  # garbage collection method with the lowest disk usage possible. 
  # This is the recommended setting for Sui Validator nodes since older object versions aren't
  # necessary to execute transactions.
  # When set to 1, Sui prunes only object versions from transaction checkpoints
  # previous to the current epoch. In general, when set to N (where N >= 1), Sui prunes  
  # only object versions from checkpoints up to `current - N` epoch. 
  # It is therefore possible to have multiple versions of an object present 
  # in the database. This setting is recommended for Sui Full nodes as they might need to serve 
  # RPC requests that require looking up objects by ID and Version (rather than just latest
  # version). However, if your Full node does not serve RPC requests you should then also enable  
  # aggressive pruning.
  num-epochs-to-retain: 0
  # Advanced setting: Maximum number of checkpoints to prune in a batch. The default
  # settings are appropriate for most use cases.
  max-checkpoints-in-batch: 10
  # Advanced setting: Maximum number of transactions in one batch of pruning run. The default
  # settings are appropriate for most use cases.
  max-transactions-in-batch: 1000


Transaction pruning
Transaction pruning removes previous transactions and effects from the database. Sui periodically creates checkpoints. Each checkpoint contains the transactions that occurred during the checkpoint and their associated effects.

Sui performs transaction pruning in the background after checkpoints complete.

You can enable transaction pruning for your Full node or Validator node by adding num-epochs-to-retain-for-checkpoints to the authority-store-pruning-config config for the node:

authority-store-pruning-config:
  num-latest-epoch-dbs-to-retain: 3
  epoch-db-pruning-period-secs: 3600
  num-epochs-to-retain: 0
  max-checkpoints-in-batch: 10
  max-transactions-in-batch: 1000
  # Number of epochs to wait before performing transaction pruning.
  # When this is N (where N >= 2), Sui prunes transactions and effects from 
  # checkpoints up to the `current - N` epoch. Sui never prunes transactions and effects from the current and
  # immediately prior epoch. N = 2 is a recommended setting for Sui Validator nodes and Sui Full nodes that don't 
  # serve RPC requests.
  num-epochs-to-retain-for-checkpoints: 2
  # Ensures that individual database files periodically go through the compaction process.
  # This helps reclaim disk space and avoid fragmentation issues
  periodic-compaction-threshold-days: 1


INFO
If you prune transactions, Archival nodes can help ensure lagging peer nodes don't lose any information. For more information, see Sui Archives.

Sui Validator Node Configuration
Validators on the Sui network run special nodes and have additional tasks and responsibilities beyond those of Full node operators.

Requirements to run a validator on Sui
To run a Sui validator, you must set up and configure a Sui Validator node. After you have a running node, you must have a minimum of 30 million SUI in your staking pool to join the validator set on the Sui network.

To learn how to set up and configure a Sui Validator node, see Sui for Node Operators on GitHub. The guide includes all of the information you need to configure your Validator node. It also provides guidance on the tasks you must perform after you join the validator set.

Specific steps you must take include:

Install and configure Sui
Configure Port and Protocol settings
Key management
Storage configuration
Software updates
On-chain commands
Update the Gas Price Survey
Reporting other validators
Validator staking pool requirements
There are minimum staking requirements a validator must satisfy to become active and to stay in the active validator set.

More precisely:

A validator candidate must accrue at least 30M SUI of stake before they can request to join the validator set.
If an active validator’s stake falls below 20M SUI, they have seven epochs of grace period to gain back the stake before being removed from the validator set.
If an active validator’s stake falls below 15M SUI, they are removed from the validator set at the end of the current epoch boundary. Sui uses 24-hour epochs.
Hardware requirements to run a Validator node
Suggested minimum hardware specifications to run a Sui Validator node:

CPU: 24 physical cores (or 48 virtual cores)
Memory: 128 GB
Storage: 4 TB NVME
Network: 1 Gbps
Validator consensus and voting power
The total voting power on Sui is always 10,000, regardless of the amount staked. Therefore, the quorum threshold is 6,667. There is no limit to the amount of SUI users can stake with a validator. Each validator has consensus voting power proportional to SUI in its staking pool, with one exception: the voting power of an individual validator is capped at 1,000 (10% of the total). If a validator accumulates more than 10% of total stake, the validator's voting power remains fixed at 10%, and the remaining voting power is spread across the rest of the validator set.

User staking and withdrawals
When users stake SUI tokens, these SUI objects are wrapped into StakedSUI objects. The calculation to determine each user's relative ownership of the staking pool is done directly with the timestamp of the StakedSUI object (which determines the moment at which the deposit took place) and the change in the exchange rates between the deposit epoch and the withdrawal epoch. Each staking pool's data structure contains a time series with that pool's exchange rates. These exchange rates can be used to determine the withdrawals of any of the pool's stakers.

Stake withdrawals are processed immediately with the exchange rate prevailing at the previous epoch's exchange rate. Withdrawals do not have to wait for the current epoch to close. Withdrawals include both the original stake the user deposited and all the stake rewards accumulated up to the previous epoch. Stakers do not earn the rewards accruing to their stake during the epoch at which they withdraw. Since there is no way to know how many stake rewards will be accumulated during the current epoch until the epoch closes, these cannot be included in the withdrawal. Hence, any user can withdraw their stake immediately and receive:

SUI withdrawn at E' = ( SUI deposited at E ) * ( Exchange Rate at E'-1 / Exchange Rate at E )

Find the exchange rate
Each epoch change emits a 0x2::validator_set::ValidatorEpochInfo event per validator with the exchange rate information. You can use the Events API to query events.

Staking rewards
Within a given validator staking pool, all stakers receive the same proportion of rewards through the pool's exchange rate appreciation. In addition, since validators earn commissions over the stake they manage, validators receive additional StakedSUI objects at the end of each epoch in proportion to the amount of commissions their staking pool earns.

Staking rewards are funded by transaction gas fees collected during the current epoch and by stake subsidies released at the end of the epoch.

StakeRewards = StakeSubsidies + GasFees

Stake subsidies are intended to subsidize the network during its early phases and are funded by a 10% allocation of SUI tokens. After this allocation depletes, the entirety of stake rewards will be made up of gas fees collected through regular network operations.

Stake rewards are made up of gas fees and stake subsidies. The total amount distributed throughout each epoch is determined as follows:

Stake Subsidies: The amount distributed in each epoch is determined prior to the beginning of the epoch according to a predefined schedule.
Gas Fees: Each epoch's amount depends on the total gas fees collected throughout the epoch. Each Sui transaction pays gas fees depending on two variables, the amount of executed gas units and the gas price: _GasFee = GasPrice _ GasUnits*
The total amount of gas fees collected corresponds to the sum of gas fees across all transactions processed in the epoch. During regular market conditions, the vast majority of transactions should have a GasPrice equal to the ReferenceGasPrice.

User staking and rewards
A stake deposit request goes into a pending state immediately in the staking pool as soon as it is made. Sui Wallet reflects any pending stake deposit requests for the user's account. However, pending stake deposit requests do not take effect until the end of the epoch during which the request is made.

A withdrawal (un-stake) request is processed immediately as soon as it is received. The staker obtains the originally deposited SUI together with all accrued stake rewards up to the previous epoch boundary – in other words, they do not include stake rewards for the current epoch.

Users can't withdraw a portion of their active stake. They must withdraw all staked SUI at the same time. Users can, however, stake using multiple StakedSui objects by splitting their SUI into multiple coins. They can then perform a partial withdrawal from a validator by un-staking only some of the StakedSUI objects.

Reference gas price
Sui is designed such that end-users can expect the gas price to be stable and predictable during regular network operations. This is achieved by having validators set the network's reference gas price at the beginning of each epoch.

Operationally this is achieved through a gas price survey that occurs as follows:

During each epoch E, each validator submits what they think the optimal reference gas price should be for the next epoch E+1.
At the epoch boundary, when Sui transitions from epoch E to epoch E+1, the network observes the gas price quotes across the validator set and sets the 2/3 percentile weighted by stake as the epoch's reference gas price. Hence the reference gas price is constant throughout each epoch and is only updated when the epoch changes.
For example, assume that there are seven validators with equal stake, and the price quotes they submit are {15, 1, 4, 2, 8, 3, 23}. The protocol sets the reference gas price at 8.

In practice, the process for submitting a gas price quote for the Gas Price Survey is a straightforward one. Each validator owns an object that contains their quote for the reference gas price. To change their response, they must update the value in that object.

For example, to set the price quote for the next epoch to 42, run:

TIP
Beginning with the Sui v1.24.1 release, the --gas-budget flag is no longer required for CLI commands.

sui client call --package <PACKAGE-ID> --module sui_system --function request_set_gas_price --args 0x5 \"42\" --gas-budget <GAS-AMOUNT>


Importantly, the gas object's value persists across epochs so that a validator who does not update and submit a new quote uses the same quote from the previous epoch. Hence, a validator seeking to optimize its own operations should update its quote every epoch in response to changes in network operations and market conditions.

Validator slashing and tallying rule
Sui is designed to encourage and enforce community monitoring of the validator set. This is done through the Tallying Rule by which each validator monitors and scores every other validator in order to ensure that everyone is operating efficiently and in the network's best interest. Validators that receive a low score can be penalized with slashed stake rewards.

The protocol only computes the global Tallying Rule score at the epoch boundary and so relies on validators monitoring actively and changing their individual scores whenever they detect changes in other validator behavior. In general, the Tallying Rule default option should always be a score of one for all validators and only be changed to zero upon determining bad operations. In practice, the Tallying Rule consists of a set of objects each validator owns that default to scores of one and thus a validator will generally be passive and only update the object corresponding to another validator's score whenever needed.

For example, to report a validator whose Sui address is 0x44840a79dd5cf1f5efeff1379f5eece04c72db13512a2e31e8750f5176285446 as bad or non-performant, run:

sui client call --package <PACKAGE-ID> --module sui_system --function report_validator --args 0x5 0x44840a79dd5cf1f5efeff1379f5eece04c72db13512a2e31e8750f5176285446 --gas-budget <GAS-AMOUNT>


The Tallying Rule should be implemented through a social equilibrium. The validator set should actively monitor itself and if one validator is clearly non-performant, then the other validators should score that validator with a 0 and slash its rewards. Community members can launch public dashboards tracking validator performance and that can be used as further signal into a validator's operations. There is no limit on the number of validators that can receive a 0 tallying score in an epoch.

Data Management
Managing the data on your Sui Full node is critical to ensuring a healthy Sui network. This topic provides a high-level description of data management on Sui Full nodes that you can use to optimize your Full node configuration. For more information about Sui Full nodes, such as pruning policies and archival settings, see Run a Sui Full Node.

Basic Sui Full node functionality
The minimal version of a Sui Full node executes all of the transactions Sui validators commit. Sui Full nodes also orchestrate the submitting of new transactions to the system:

Basic Sui Full node functionality

The preceding image shows how data flows through a Full node:

State sync protocol: A Sui Full node performs the following to achieve state synchronization:
Retrieves the information about the committed checkpoints via the p2p gossip-like protocol
Executes the transactions locally to verify that effects match the effects certified by the quorum of the validators
Updates the local state with the latest object values accordingly.
RPCs: A Sui Full node exposes Sui RPC endpoints for querying the latest state of the system, including both the latest state metadata (such as, sui_getProtocolConfig), and the latest state object data (sui_getObject).
Transaction submission: Each Sui Full node orchestrates transaction submission to the quorum of the Sui Validators, and, optionally if configured, locally executes the finalized transactions (called fast path execution), which circumvents the wait for checkpoint synchronization.
Sui Full node Data and RPC types
A Sui Full Node stores multiple categories of data in its permanent store.

INFO
The per-epoch Sui store is beyond the scope of this topic. Sui uses the per-epoch store (resets at the start of each epoch) internally for authority and consensus operations.

Sui Full nodes store the following types of data:

Transactions with associated effects and events: Sui uses a unique transaction digest to retrieve information about a transaction, including its effects and emitted events. Sui Full nodes don't require the historic transaction information for basic Full node operations. To conserve drive space, you can enable pruning to remove this historical data.
Checkpoints: Sui groups committed transactions in checkpoints, and then uses those checkpoints to achieve state synchronization. Checkpoints keep transaction digests that contain additional integrity metadata. Sui Full nodes don't require data from checkpoints to execute and submit transactions, so you can configure pruning for this data as well.
Objects: Transactions that mutate objects create new object versions. Each object has a unique pair of (objectId, version) used to identify the object. Sui Full nodes don't require historic object versions to execute and submit transactions, so you can configure your Full node to also prune this data.
Indexing information: A Full node default configuration is to post-process the committed transactions: it indexes the committed information to enable efficient aggregation and filtering queries. For example, the indexing can be useful for retrieving all the historic transactions of a given sender, or finding all the objects owned by an address.
Sui Full nodes support more than 40 RPC types that includes the following categories:

General metadata, such as sui_getProtocolConfig and sui_getChainIdentier. These requests don't depend on additional indexing and don't require historic data to process.
Direct lookups, such as sui_getObject, sui_getEvents. These requests don't depend on additional indexing, but require historic data in some cases, such as sui_tryGetPastObject and sui_getTransactionBlock.
Accumulation and filtering queries,such as suix_getOwnedObjects and suix_getCoins. These requests depend on additional indexing, and require historic data in some cases, such as suix_queryTransactionBlocks.
INFO
Sui plans to migrate the RPC endpoints that require additional indexing away from Sui Full nodes in the near future. This plan decouples the storage that is backing transaction execution from the storage that is better suited for data indexing.

Sui Archival data
A Sui archive instance stores the full Sui transaction history since genesis in a database agnostic format. This includes information about transactions (with client authentication), effects, events, and checkpoints. As such, archival storage can be used for data auditing and for replaying historic transactions.

INFO
The current archival storage format doesn't include historic object versions.

As a Full node operator, you can enable archival fallback for your Full node by specifying the URL to upload archival data. Currently, Mysten Labs manages a Sui archive and stores it in AWS S3. To ensure a healthy network, we encourage the Sui community to set up additional archives to ensure archival data availability across the network. In a typical configuration, an archive trails behind the latest checkpoint by approximately 10 minutes.

A Full Node that starts from scratch can replay (and thus re-verify) transactions that occurred since Sui genesis from the given archive via configuring Archival Fallback in the fullnode.yaml configuration file to point to the S3 bucket that stores the archive.

A Sui Full node that fails to retrieve checkpoints from its peers via state sync protocol falls back to downloading the missing checkpoints from its pre-configured archive. This fallback enables a Full node to catch up with the rest of the system regardless of the pruning policies of its peers.

Sui Full node pruning policies
As described previously, sustainable disk usage requires Sui Full nodes to prune the information about historic object versions as well as historic transactions with the corresponding effects and events, including old checkpoint data.

Both transaction and object pruners run in the background. The logical deletion of entries from RocksDB ultimately triggers the physical compaction of data on disk, which is governed by RocksDB background jobs: the pruning effect on disk usage is not immediate and might take multiple days.

To learn more about object pruning policies, see Object pruning. You can configure the pruner in two modes:

aggressive pruning (num-epochs-to-retain: 0): Preferred option. Sui prunes old object versions as soon as possible.
epoch-based pruning (num-epochs-to-retain: X): Sui prunes old object versions after X epochs.
TIP
Testing indicates that aggressive pruning results in more efficient Full Node operation.

To learn more about transaction pruning policies, see Transaction pruning. To configure transaction pruning, specify the num-epochs-to-retain-for-checkpoints: X config option. The checkpoints, including their transactions, effects and events are pruned up to X epochs ago. We suggest setting transaction pruning to 2 epochs.

Set an archiving watermark
In case your Full node is configured to upload committed information to an archive, you should ensure that pruning doesn't occur until after the corresponding data is uploaded. To do so, set the use-for-pruning-watermark: true in the Fullnode.yaml file as described in Archival fallback.

Sui Full node key-value store backup
To enable historic data queries for the Sui Full nodes that prune old transactional data, Full node RPC implementation is configured to fallback for querying missing transactional data from a remote store.

If the information about the transaction digest, effects, events, or checkpoints is not available locally, a Full node automatically retrieves the historical data from a cloud-based key-value store (currently managed by MystenLabs). Note that the current key-value store implementation keeps historic transactional data only: we plan to provide support for a similar setup for retrieving the historic object versions in a future release.

Pruning policy examples
Use the examples in this section to configure your Sui Full node. You can copy the examples, and then, optionally, modify the values as appropriate for your environment.

Validator and minimal Full node
This configuration keeps disk usage to a minimum. It is suitable for most validators. A Full node with this configuration cannot answer queries that require indexing or historic data.

# Do not generate or maintain indexing of Sui data on the node
enable-index-processing: false

authority-store-pruning-config:
  # default values
  num-latest-epoch-dbs-to-retain: 3
  epoch-db-pruning-period-secs: 3600
  max-checkpoints-in-batch: 10
  max-transactions-in-batch: 1000
  # end of default values

  # Prune historic object versions as soon as possible.
  num-epochs-to-retain: 0
  # Prune historic transactions of the past epochs
  num-epochs-to-retain-for-checkpoints: 2
  periodic-compaction-threshold-days: 1
  # Smooth pruning traffic throughout an epoch
  smooth: true

Full node with indexing but no history
This setup manages secondary indexing in addition to the latest state, but aggressively prunes historic data. A Full node with this configuration:

Answers RPC queries that require indexing, like suix_getBalance().
Answers RPC queries that require historic transactions via a fallback to retrieve the data from a remote key-value store: sui_getTransactionBlock().
Cannot answer RPC queries that require historic object versions: sui_tryGetPastObject().
The showBalanceChanges filter of sui_getTransactionBlock() query relies on historic object versions, so it can't work with this configuration.
authority-store-pruning-config:
  # default values
  num-latest-epoch-dbs-to-retain: 3
  epoch-db-pruning-period-secs: 3600
  max-checkpoints-in-batch: 10
  max-transactions-in-batch: 1000
  # end of default values

  # Prune historic object versions
  num-epochs-to-retain: 0
  # Prune historic transactions of the past epochs
  num-epochs-to-retain-for-checkpoints: 2
  periodic-compaction-threshold-days: 1
  # Smooth pruning traffic throughout an epoch
  smooth: true

Full node with full object history but pruned transaction history
This configuration manages the full object history while still pruning historic transactions. A Full node with this configuration can answer all historic and indexing queries (using the transaction query fallback for transactional data), including the ones that require historic objects such as the showBalanceChanges filter of sui_getTransactionBlock().

The main caveat is that the current setup enables transaction pruner to go ahead of object pruner. The object pruner might not be able to properly clean up the objects modified by the transactions that have been already pruned. You should closely monitor the disk space growth on a Full node with this configuration.

In addition to the regular (pruned) snapshots, Mysten Labs also maintains special RocksDB snapshots with full history of object versions available for the operators using this configuration.

authority-store-pruning-config:
  # default values
  num-latest-epoch-dbs-to-retain: 3
  epoch-db-pruning-period-secs: 3600
  max-checkpoints-in-batch: 10
  max-transactions-in-batch: 1000
  # end of default values

  # No pruning of object versions (use u64::max for num of epochs)
  num-epochs-to-retain: 18446744073709551615
  # Prune historic transactions of the past epochs
  num-epochs-to-retain-for-checkpoints: 2
  periodic-compaction-threshold-days: 1
  # Smooth pruning traffic throughout an epoch
  smooth: true


  Data Management
Managing the data on your Sui Full node is critical to ensuring a healthy Sui network. This topic provides a high-level description of data management on Sui Full nodes that you can use to optimize your Full node configuration. For more information about Sui Full nodes, such as pruning policies and archival settings, see Run a Sui Full Node.

Basic Sui Full node functionality
The minimal version of a Sui Full node executes all of the transactions Sui validators commit. Sui Full nodes also orchestrate the submitting of new transactions to the system:

Basic Sui Full node functionality

The preceding image shows how data flows through a Full node:

State sync protocol: A Sui Full node performs the following to achieve state synchronization:
Retrieves the information about the committed checkpoints via the p2p gossip-like protocol
Executes the transactions locally to verify that effects match the effects certified by the quorum of the validators
Updates the local state with the latest object values accordingly.
RPCs: A Sui Full node exposes Sui RPC endpoints for querying the latest state of the system, including both the latest state metadata (such as, sui_getProtocolConfig), and the latest state object data (sui_getObject).
Transaction submission: Each Sui Full node orchestrates transaction submission to the quorum of the Sui Validators, and, optionally if configured, locally executes the finalized transactions (called fast path execution), which circumvents the wait for checkpoint synchronization.
Sui Full node Data and RPC types
A Sui Full Node stores multiple categories of data in its permanent store.

INFO
The per-epoch Sui store is beyond the scope of this topic. Sui uses the per-epoch store (resets at the start of each epoch) internally for authority and consensus operations.

Sui Full nodes store the following types of data:

Transactions with associated effects and events: Sui uses a unique transaction digest to retrieve information about a transaction, including its effects and emitted events. Sui Full nodes don't require the historic transaction information for basic Full node operations. To conserve drive space, you can enable pruning to remove this historical data.
Checkpoints: Sui groups committed transactions in checkpoints, and then uses those checkpoints to achieve state synchronization. Checkpoints keep transaction digests that contain additional integrity metadata. Sui Full nodes don't require data from checkpoints to execute and submit transactions, so you can configure pruning for this data as well.
Objects: Transactions that mutate objects create new object versions. Each object has a unique pair of (objectId, version) used to identify the object. Sui Full nodes don't require historic object versions to execute and submit transactions, so you can configure your Full node to also prune this data.
Indexing information: A Full node default configuration is to post-process the committed transactions: it indexes the committed information to enable efficient aggregation and filtering queries. For example, the indexing can be useful for retrieving all the historic transactions of a given sender, or finding all the objects owned by an address.
Sui Full nodes support more than 40 RPC types that includes the following categories:

General metadata, such as sui_getProtocolConfig and sui_getChainIdentier. These requests don't depend on additional indexing and don't require historic data to process.
Direct lookups, such as sui_getObject, sui_getEvents. These requests don't depend on additional indexing, but require historic data in some cases, such as sui_tryGetPastObject and sui_getTransactionBlock.
Accumulation and filtering queries,such as suix_getOwnedObjects and suix_getCoins. These requests depend on additional indexing, and require historic data in some cases, such as suix_queryTransactionBlocks.
INFO
Sui plans to migrate the RPC endpoints that require additional indexing away from Sui Full nodes in the near future. This plan decouples the storage that is backing transaction execution from the storage that is better suited for data indexing.

Sui Archival data
A Sui archive instance stores the full Sui transaction history since genesis in a database agnostic format. This includes information about transactions (with client authentication), effects, events, and checkpoints. As such, archival storage can be used for data auditing and for replaying historic transactions.

INFO
The current archival storage format doesn't include historic object versions.

As a Full node operator, you can enable archival fallback for your Full node by specifying the URL to upload archival data. Currently, Mysten Labs manages a Sui archive and stores it in AWS S3. To ensure a healthy network, we encourage the Sui community to set up additional archives to ensure archival data availability across the network. In a typical configuration, an archive trails behind the latest checkpoint by approximately 10 minutes.

A Full Node that starts from scratch can replay (and thus re-verify) transactions that occurred since Sui genesis from the given archive via configuring Archival Fallback in the fullnode.yaml configuration file to point to the S3 bucket that stores the archive.

A Sui Full node that fails to retrieve checkpoints from its peers via state sync protocol falls back to downloading the missing checkpoints from its pre-configured archive. This fallback enables a Full node to catch up with the rest of the system regardless of the pruning policies of its peers.

Sui Full node pruning policies
As described previously, sustainable disk usage requires Sui Full nodes to prune the information about historic object versions as well as historic transactions with the corresponding effects and events, including old checkpoint data.

Both transaction and object pruners run in the background. The logical deletion of entries from RocksDB ultimately triggers the physical compaction of data on disk, which is governed by RocksDB background jobs: the pruning effect on disk usage is not immediate and might take multiple days.

To learn more about object pruning policies, see Object pruning. You can configure the pruner in two modes:

aggressive pruning (num-epochs-to-retain: 0): Preferred option. Sui prunes old object versions as soon as possible.
epoch-based pruning (num-epochs-to-retain: X): Sui prunes old object versions after X epochs.
TIP
Testing indicates that aggressive pruning results in more efficient Full Node operation.

To learn more about transaction pruning policies, see Transaction pruning. To configure transaction pruning, specify the num-epochs-to-retain-for-checkpoints: X config option. The checkpoints, including their transactions, effects and events are pruned up to X epochs ago. We suggest setting transaction pruning to 2 epochs.

Set an archiving watermark
In case your Full node is configured to upload committed information to an archive, you should ensure that pruning doesn't occur until after the corresponding data is uploaded. To do so, set the use-for-pruning-watermark: true in the Fullnode.yaml file as described in Archival fallback.

Sui Full node key-value store backup
To enable historic data queries for the Sui Full nodes that prune old transactional data, Full node RPC implementation is configured to fallback for querying missing transactional data from a remote store.

If the information about the transaction digest, effects, events, or checkpoints is not available locally, a Full node automatically retrieves the historical data from a cloud-based key-value store (currently managed by MystenLabs). Note that the current key-value store implementation keeps historic transactional data only: we plan to provide support for a similar setup for retrieving the historic object versions in a future release.

Pruning policy examples
Use the examples in this section to configure your Sui Full node. You can copy the examples, and then, optionally, modify the values as appropriate for your environment.

Validator and minimal Full node
This configuration keeps disk usage to a minimum. It is suitable for most validators. A Full node with this configuration cannot answer queries that require indexing or historic data.

# Do not generate or maintain indexing of Sui data on the node
enable-index-processing: false

authority-store-pruning-config:
  # default values
  num-latest-epoch-dbs-to-retain: 3
  epoch-db-pruning-period-secs: 3600
  max-checkpoints-in-batch: 10
  max-transactions-in-batch: 1000
  # end of default values

  # Prune historic object versions as soon as possible.
  num-epochs-to-retain: 0
  # Prune historic transactions of the past epochs
  num-epochs-to-retain-for-checkpoints: 2
  periodic-compaction-threshold-days: 1
  # Smooth pruning traffic throughout an epoch
  smooth: true

Full node with indexing but no history
This setup manages secondary indexing in addition to the latest state, but aggressively prunes historic data. A Full node with this configuration:

Answers RPC queries that require indexing, like suix_getBalance().
Answers RPC queries that require historic transactions via a fallback to retrieve the data from a remote key-value store: sui_getTransactionBlock().
Cannot answer RPC queries that require historic object versions: sui_tryGetPastObject().
The showBalanceChanges filter of sui_getTransactionBlock() query relies on historic object versions, so it can't work with this configuration.
authority-store-pruning-config:
  # default values
  num-latest-epoch-dbs-to-retain: 3
  epoch-db-pruning-period-secs: 3600
  max-checkpoints-in-batch: 10
  max-transactions-in-batch: 1000
  # end of default values

  # Prune historic object versions
  num-epochs-to-retain: 0
  # Prune historic transactions of the past epochs
  num-epochs-to-retain-for-checkpoints: 2
  periodic-compaction-threshold-days: 1
  # Smooth pruning traffic throughout an epoch
  smooth: true

Full node with full object history but pruned transaction history
This configuration manages the full object history while still pruning historic transactions. A Full node with this configuration can answer all historic and indexing queries (using the transaction query fallback for transactional data), including the ones that require historic objects such as the showBalanceChanges filter of sui_getTransactionBlock().

The main caveat is that the current setup enables transaction pruner to go ahead of object pruner. The object pruner might not be able to properly clean up the objects modified by the transactions that have been already pruned. You should closely monitor the disk space growth on a Full node with this configuration.

In addition to the regular (pruned) snapshots, Mysten Labs also maintains special RocksDB snapshots with full history of object versions available for the operators using this configuration.

authority-store-pruning-config:
  # default values
  num-latest-epoch-dbs-to-retain: 3
  epoch-db-pruning-period-secs: 3600
  max-checkpoints-in-batch: 10
  max-transactions-in-batch: 1000
  # end of default values

  # No pruning of object versions (use u64::max for num of epochs)
  num-epochs-to-retain: 18446744073709551615
  # Prune historic transactions of the past epochs
  num-epochs-to-retain-for-checkpoints: 2
  periodic-compaction-threshold-days: 1
  # Smooth pruning traffic throughout an epoch
  smooth: true

  Database Snapshots
Database snapshots provide a point-in-time view of a database's store. In Sui, the database snapshot captures a running database's view of the Sui network from a particular node at the end of an epoch. While validators can enable snapshots, they are typically most valuable for Full node operators.

Snapshots of the Sui network enable Full node operators a way to bootstrap a Full node without having to execute all the transactions that occurred after genesis. You can upload snapshots to remote object stores like S3, Google Cloud Storage, Azure Blob Storage, and similar services. These services typically run the export process in the background so there is no degradation in performance for your Full node. With snapshots stored in the cloud, you're more easily able to recover quickly from catastrophic failures in your system or hardware.

To maintain a healthy Sui network, Sui encourages the Sui community to bring up additional snapshots to ensure stronger data availability across the network.

Supported snapshot types
Sui supports two types of snapshots:

RocksDB snapshots are a point-in-time view of a database store. This means that the snapshot keeps the state of the system at the moment it generates the snapshot, including non-pruned data, additional indices, and other data.
Formal snapshots are database agnostic with a minimalistic format, in other words they contain only the data necessary to restore a node to a valid state at the specified epoch, thus they have a much smaller storage footprint and are generally faster to restore from when compared to database snapshots. Formal snapshots are also supported natively by the Sui protocol. In this context, this means that we can cryptographically verify the contents of the formal snapshot against a commitment from the committee at the epoch we are restoring to. This verification happens automatically and by default during a Formal snapshot restore (unless explicitly bypassed).
INFO
Formal snapshots are not suitable for use if you are running an RPC node that does any historical data lookups. For more information on node data management, see Data Management.

You can configure a Full node snapshot to generate a state snapshot at the end of each epoch. A single Full node can generate RocksDB snapshots, Formal snapshots, or both.

Formal snapshots
Formal snapshots provide a mechanism for a node to restore to a canonical state (the state of a full pruned and compacted node at the end of an epoch) at some prior point in time without having to execute all the transactions that have occurred since genesis. Unlike existing database snapshots, these formal snapshots have the following properties:

Minimalism: Formal snapshots currently contain only the end of epoch live object set (the set of all object versions eligible for use as input objects for future transactions). Sui syncs all other critical chain information from the chain or derives it. Thus, formal snapshots contain only the necessary data required for a node to startup at epoch boundary and participate in the network.
Agnosticism: Formal snapshots are by nature agnostic to the underlying database choice or implementation of the protocol. As the live object set is protocol defined, so is the formal snapshot.
Verifiability: Formal snapshots have first-class support in the core Sui protocol. As such, they must be trustless/verifiable by the node operator upon download. To support this, the protocol signs a commitment to the live object state at end of epoch, which formal snapshots are checked against at restore time. If this verification fails, the node state is moved back to the state before the snapshot restore attempt.
Because these snapshots do not contain indexes, they are most immediately useful for validators and state sync Full nodes (SSFNs). You can upload snapshots to remote object stores like S3, Google Cloud Storage, Azure Blob Storage, and similar services. These services typically run the export process in the background so there is no degradation in performance for your Full node. With snapshots stored in the cloud, you can recover from catastrophic failures in your system or hardware more efficiently.

Restoring a Full node using snapshots
Restoring using RocksDB snapshots
To restore from a RocksDB snapshot, follow these steps:

Download the snapshot for the epoch you want to restore to your local disk. There is one snapshot per epoch in s3 bucket.

Place the snapshot into the directory that the db-config value points to in your fullnode.yaml file. For example, if the db-config value points to /opt/sui/db/authorities_db/full_node_db and you want to restore from epoch 10, then copy the snapshot to the directory with this command:

You can use the aws cli (provided you have credentials to associate with the download): aws s3 cp s3://<BUCKET_NAME>/epoch_10 /opt/sui/db/authorities_db/full_node_db/live --recursive.

An alternative is to use sui-tool to copy the files:

sui-tool download-db-snapshot --latest \
    --network <NETWORK> --snapshot-bucket <BUCKET-NAME> \
    --snapshot-bucket-type <TYPE> --path <PATH-TO-NODE-DB> \
    --num-parallel-downloads 25 \
    --skip-indexes \
    --no-sign-request

--epoch: The epoch that you want to download. Mysten Labs hosted buckets will only keep the last 90 epochs, you can check the most recent epoch on sui explorers like suivision or suiscan.
--latest: Rather than explicitly passing a epoch via --epoch, you can pass the --latest flag, which will automatically select the latest snapshot`
--network: Network to download snapshot for. Defaults to "mainnet".
--path: Path to snapshot directory on local filesystem.
--no-sign-request: If set, --snapshot-bucket and --snapshot-bucket-type are ignored, and Cloudflare R2 is used.
--snapshot-bucket: Source snapshot bucket name, eg mysten-mainnet-snapshots.
--snapshot-bucket-type: Snapshot bucket type. GCS and S3 currently supported.
--skip-indexes: Skips downloading the very large indexes/ dir, used by jsonrpc on the fullnode
The following environment variables are used if --no-sign-request is not set:

AWS: AWS_SNAPSHOT_ACCESS_KEY_ID, AWS_SNAPSHOT_SECRET_ACCESS_KEY, AWS_SNAPSHOT_REGION
GCS: GCS_SNAPSHOT_SERVICE_ACCOUNT_FILE_PATH
AZURE: AZURE_SNAPSHOT_STORAGE_ACCOUNT, AZURE_SNAPSHOT_STORAGE_ACCESS_KEY
When using sui-tool download-db-snapshot the database is copied to the location you pass to --path, in a directory named epoch_[NUM]. Move this directory to the live/ Full node database directory, for example /opt/sui/db/authorities_db/full_node_db/live.

Make sure you update the ownership of the downloaded directory to the sui user (whichever linux user you run sui-node as) sudo chown -R sui:sui /opt/sui/db/authorities_db/full_node_db/live.

Start the Sui node.

INFO
When you restore a Full node from a snapshot, write it to the path /opt/sui/db/authorities_db/full_node_db/live. To restore a Validator node, use the path /opt/sui/db/authorities_db/live.

Restoring using Formal snapshots
To restore using a Formal snapshot, use the sui-tool binary. sui-tool can be downloaded along with other sui binaries. See Install Sui for more details.

The following steps can be used to restore a node from a Formal snapshot:

If it's running, stop the node.

Run the command:

sui-tool download-formal-snapshot --latest --genesis "<PATH-TO-GENESIS-BLOB>" \
     --network <NETWORK> --snapshot-bucket <BUCKET-NAME> --snapshot-bucket-type <TYPE> \
     --path <PATH-TO-NODE-DB> --num-parallel-downloads 50 --no-sign-request


--epoch: The epoch that you want to download. Mysten Labs hosted buckets will only keep the last 90 epochs, you can check the most recent epoch on sui explorers like suivision or suiscan.
--latest: Rather than explicitly passing a epoch via --epoch, you can pass the --latest flag, which will automatically select the latest snapshot`
--genesis: The path to the location of the network's genesis.blob.
--network: Network to download snapshot for. Defaults to "mainnet".
--path: Path to snapshot directory on local filesystem.
--no-sign-request: If set, --snapshot-bucket and --snapshot-bucket-type are ignored, and Cloudflare R2 is used.
--snapshot-bucket: Source snapshot bucket name, eg mysten-mainnet-snapshots.
--snapshot-bucket-type: Snapshot bucket type. GCS and S3 currently supported.
The following environment variables are used if --no-sign-request is not set:

AWS: AWS_SNAPSHOT_ACCESS_KEY_ID, AWS_SNAPSHOT_SECRET_ACCESS_KEY, AWS_SNAPSHOT_REGION
GCS: GCS_SNAPSHOT_SERVICE_ACCOUNT_FILE_PATH
AZURE: AZURE_SNAPSHOT_STORAGE_ACCOUNT, AZURE_SNAPSHOT_STORAGE_ACCESS_KEY
Mysten Labs managed snapshots
Mysten Labs hosts two tiers of snapshot storage access. High throughput, Requester Pays enabled buckets, and free, permissionless buckets.

High throughput, Requester Pays enabled buckets:

GCS and S3 are both setup with requester pays. This means that you'll need to provide a set of valid AWS/GCP credentials when downloading from these buckets. Requester Pays means you are charged for the egress costs of pulling the snapshot data.
If you are looking for the best download speeds, we recommend using the S3 buckets with transfer acceleration enabled.
Free, permissionless buckets:

These are currently hosted on Cloudflare R2, currently only in North America, but we plan on adding more regions soon.
Since the bucket is open to the internet, there's no need to provide any cloud credentials.
Bucket Names
S3 Testnet: s3://mysten-testnet-snapshots/, s3://mysten-testnet-formal/ Mainnet: s3://mysten-mainnet-snapshots/, s3://mysten-mainnet-formal/

GCS Testnet: gs://mysten-testnet-snapshots/, gs://mysten-testnet-formal/ Mainnet: gs://mysten-mainnet-snapshots/, gs://mysten-mainnet-formal/

Mysten Managed Snapshots

Enabling snapshots
Full nodes do not take snapshots by default. To enable this feature you must apply specific configs to your Full node.

Follow these steps to change the configs for a Full node:

Stop your node, if it's running.
Open your fullnode.yaml config file and apply config updates as the following sections show.
Save the fullnode.yaml file and restart the node.
Enabling DB snapshots
Add an entry to the config file for db-checkpoint-config. Using Amazon's S3 service as an example:

db-checkpoint-config:
  perform-db-checkpoints-at-epoch-end: true
  perform-index-db-checkpoints-at-epoch-end: true
  object-store-config:
    object-store: "S3"
    bucket: "<BUCKET-NAME>"
    aws-access-key-id: “<ACCESS-KEY>”
    aws-secret-access-key: “<SHARED-KEY>”
    aws-region: "<BUCKET-REGION>"
    object-store-connection-limit: 20

object-store: The remote object store to upload snapshots. Set as Amazon's S3 service in the example.
bucket: The S3 bucket name to store the snapshots.
aws-access-key-id and aws-secret-access-key: AWS authentication information with write access to the bucket.
aws-region: Region where bucket exists.
object-store-connection-limit: Number of simultaneous connections to the object store.
Enabling Formal snapshots
Add an entry to the config file for state-snapshot-write-config. Using Amazon's S3 service as an example:

state-snapshot-write-config:
  object-store-config:
    object-store: "S3"
    bucket: "<BUCKET-NAME>"
    aws-access-key-id: “<ACCESS-KEY>”
    aws-secret-access-key: “<SHARED-KEY>”
    aws-region: "<BUCKET-REGION>"
    object-store-connection-limit: 200

The configuration settings shown in the example are specific to AWS S3, but GCS, Azure Storage, and Cloudflare R2 are all supported.

Sui Archives
A Sui archive is a history of all transaction data on Sui, trailing behind the latest checkpoint by 10 minutes. As a Sui node operator, you can write this history to an object store like S3, GCS, or similar for safe keeping. Saving this archive data is considered a best practice because Sui prunes transactions on Full nodes to remove historical transactions and their effects. Peer nodes, for example, might not catch up with all transactions and effects through synchronization if they lag behind the current epoch by more than the latest few epochs. Instead of relying on synchronization, peer nodes can fallback to downloading this information from an archive.

Sui Archival nodes (Full nodes that write to an archive) don't store historical state on local storage and don't help query historical data. They serve the purpose of enabling peer nodes to catch up to the latest checkpoint and are useful for auditing and verifying the complete history of all transactions on the network.

Create an Archival node
To start storing transaction history as an archive, you need to modify your node configuration. Open your fullnode.yaml file and add the following configuration. By default, the fullnode.yaml file is located in your ~/.sui/sui_config directory.

state-archive-write-config:
  object-store-config:
    object-store: "S3"
    bucket: "<bucket_name>"
    aws-access-key-id: "<AWS_ACCESS_KEY_ID>"
    aws-secret-access-key: "<AWS_SECRET_ACCESS_KEY>"
    aws-region: "<aws_region>"
    object-store-connection-limit: 20
  concurrency: 5
  use-for-pruning-watermark: false
state-archive-read-config:
  - object-store-config:
      object-store: "S3"
      # Use the same bucket which is being used in `state-archive-write-config`
      bucket: "<bucket_name>"
      aws-access-key-id: "<AWS_ACCESS_KEY_ID>"
      aws-secret-access-key: "<AWS_SECRET_ACCESS_KEY>"
      aws-region: "<aws_region>"
      object-store-connection-limit: 20
    concurrency: 5
    # This should be set to true in this case. Setting this to true
    # would prevent pruning of local transaction data until it is archived
    # in the bucket
    use-for-pruning-watermark: true

Set up archival fallback
To enable your node to fallback to an archive in case of lag, add this to your fullnode.yaml file:

Amazon S3
Google Cloud Storage
state-archive-read-config:
  - object-store-config:
      object-store: "S3"
      # Use mysten-testnet-archives for testnet 
      # Use mysten-mainnet-archives for mainnet
      bucket: "mysten-<testnet|mainnet>-archives"
      # Use your AWS account access key id
      aws-access-key-id: "<AWS-ACCESS-KEY-ID>"
      # Use your AWS account secret access key
      aws-secret-access-key: "<AWS-SECRET-ACCESS-KEY>"
      aws-region: "<AWS-REGION>"
      object-store-connection-limit: 20
    # How many objects to read ahead when catching up  
    concurrency: 5
    # Whether to prune local state based on latest checkpoint in archive.
    # This should stay false for most use cases
    use-for-pruning-watermark: false

Even though these buckets are publicly readable, you need to make sure to properly grant the correct policies to read them via AWS, for example:

{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Action": [
                "s3:ListBucket",
                "s3:GetObject",
            ],
            "Effect": "Allow",
            "Resource": [
                "arn:aws:s3:::mysten-mainnet-archives/*",
                "arn:aws:s3:::mysten-mainnet-archives"
            ]
        }
    ]
}


Genesis
Genesis is the initial state of the Sui blockchain. To launch a network, the initial committee of validators collaborate by providing their validator information (public keys, network addresses, and so on) to a shared workspace. After all of the initial validators have contributed their information, Sui generates the initial, unsigned genesis checkpoint (checkpoint with sequence number 0) and each validator provides their signature. Sui aggregates these signatures to form a certificate on the genesis checkpoint. Sui bundles this checkpoint, as well as the initial objects, together into a single genesis.blob file that is used to initialize the state when running the sui-node binary for both validators and Full nodes.

Genesis blob locations
The genesis.blob files for each network are in the sui-genesis repository.

See Sui Full Node for how to get the genesis.blob file for each network.

Validator Committee
A set of independent validators participate on the Sui network, each running its own instance of the Sui software on a separate machine (or a sharded cluster of machines the same entity operates). Each validator handles read and write requests sent by clients, verifying transactions and updating on-chain information.

To learn how to set up and run a Sui Validator node, including how staking and rewards work, see Sui Validator Node Configuration.

Sui uses Delegated Proof-of-Stake (DPoS) to determine which validators operate the network and their voting power. Validators are incentivized to participate in good faith via a share of transaction fees, staking rewards, and slashing stake and staking rewards in case of misbehavior.

Epochs
Operation of the Sui network is temporally partitioned into non-overlapping, approximate fixed-duration (~24-hour) epochs. During a particular epoch, the set of validators participating in the network and their voting power is fixed. At an epoch boundary, reconfiguration might occur and can change the set of validators participating in the network and their voting power. Conceptually, reconfiguration starts a new instance of the Sui protocol with the previous epoch's final state as genesis and the new set of validators as the operators. Besides validator set changes, tokenomics operations such as staking/un-staking, and distribution of staking rewards are also processed at epoch boundaries.

Quorums
A quorum is a set of validators whose combined voting power is greater than two-thirds (>2/3) of the total during a particular epoch. For example, in a Sui instance operated by four validators that all have the same voting power, any group containing three validators is a quorum.

The quorum size of >2/3 ensures Byzantine fault tolerance (BFT). A validator commits a transaction (durably store the transaction and update its internal state with the effects of the transaction) only if it is accompanied by cryptographic signatures from a quorum. Sui calls the combination of the transaction and the quorum signatures on its bytes a certificate. The policy of committing only certificates ensures Byzantine fault tolerance: if >2/3 of the validators faithfully follow the protocol, they are guaranteed to eventually agree on both the set of committed certificates and their effects.

Write requests
A validator can handle two types of write requests: transactions and certificates. At a high level, a client:

Communicates a transaction to a quorum of validators to collect the signatures required to form a certificate.
Submits a certificate to a validator to commit state changes on that validator.
Transactions
When a validator receives a transaction from a client, it first performs transaction validity checks (validity of the sender's signature). If the checks pass, the validator locks all owned-objects and signs the transaction bytes, then returns the signature to the client. The client repeats this process with multiple validators until it has collected signatures on its transaction from a quorum, thereby forming a certificate.

The process of collecting validator signatures on a transaction into a certificate and the process of submitting certificates can be performed in parallel. The client can simultaneously multicast transactions/certificates to an arbitrary number of validators. Alternatively, a client can outsource either or both of these tasks to a third-party service provider. This provider must be trusted for liveness (it can refuse to form a certificate), but not for safety (it cannot change the effects of the transaction, and does not need the user's secret key).

Certificates
After the client forms a certificate, it submits it to the validators, which perform certificate validity checks. These checks ensure the signers are validators in the current epoch, and the signatures are cryptographically valid. If the checks pass, the validators execute the transaction inside the certificate. Execution of a transaction either succeeds and commits all of its effects or aborts and has no effect other than debiting the transaction's gas input. Some reasons a transaction might abort include an explicit abort instruction, a runtime error such as division by zero, or exceeding the maximum gas budget. Whether it succeeds or aborts, the validator durably stores the certificate indexed by the hash of its inner transaction.

If a client collects a quorum of signatures on the effects of the transaction, then the client has a promise of finality. This means that transaction effects persist on the shared database and are actually committed and visible to everyone by the end of the epoch. This does not mean that the latency is a full epoch, because you can use the effects certificate to convince anyone of the transactions finality, as well as to access the effects and issue new transactions. As with transactions, you can parallelize the process of sharing a certificate with validators and (if desired) outsource to a third-party service provider.

The role of Narwhal and Bullshark
Sui takes advantage of Narwhal and Bullshark as its mempool and consensus engines. Narwhal/Bullshark (N/B) is also implemented in Sui so that when Byzantine agreement is required it uses a high-throughput DAG-based consensus to manage shared locks while execution on different shared objects is parallelized.

Narwhal enables the parallel ordering of transactions into batches that are collected into concurrently proposed blocks, and Bullshark defines an algorithm for executing the DAG that these blocks form. N/B combined builds a DAG of blocks, concurrently proposed, and creates an order between those blocks as a byproduct of the building of the DAG. But that order is overlaid on top of the causal order of Sui transactions (the "payload" of Narwhal/Bullshark here), and does not substitute for it:

N/B operates in OX, rather than XO mode (O = order, X = execute); the execution occurs after the Narwhal/Bullshark ordering.
The output of N/B is therefore a sequence of transactions, with interdependencies stored in the transaction data itself.
Consensus sequences certificates of transactions. These represent transactions that have already been presented to 2/3 of validators that checked that all their owned objects are available to be operated on and signed the transaction. Upon a certificate being sequenced, Sui sets the lock of the shared objects at the next available version to map to the execution of that certificate. So for example if you have a shared object X at version 2, and you sequence certificate T, Sui stores T -> [(X, 2)]. That is all you do when Sui reaches consensus, and as a result Sui can ingest a lot of sequenced transactions.

Now, after this is done Sui can execute all certificates that have their locks set, on one or multiple cores. Obviously, transactions for earlier versions of objects need to be processed first (causally), and that reduces the degree of concurrency. The read and write set of the transaction can be statically determined from its versioned object inputs--execution can only read/write an object that was an input to the transaction, or that was created by the transaction.

Validator Tasks
This guide focuses on running the Sui node software as a validator.

Requirements
To run a Sui Validator a machine with the following is required:

CPU: 24 physical cores (or 48 virtual cores)
Memory: 128 GB
Storage: 4 TB NVME
Network: 1 Gbps
Deployment
You can deploy Sui node in a number of ways.

There are pre-built container images available in Docker Hub.

And pre built linux/amd64 binaries available in S3 that you can can fetch using one of the following methods:

wget https://releases.sui.io/$SUI_SHA/sui-node

curl https://releases.sui.io/$SUI_SHA/sui-node -o sui-node

To build directly from source:

git clone https://github.com/MystenLabs/sui.git && cd sui
git checkout [SHA|BRANCH|TAG]
cargo build --release --bin sui-node

Configuration and guides are available for the following deployment options:

Systemd
Ansible
Docker Compose
Configuration
Sui node runs with a single configuration file provided as an argument, example:

./sui-node --config-path /opt/sui/config/validator.yaml.

See Validator for configuration templates.

Connectivity
Sui node uses the following ports by default:

protocol/port	reachability	purpose
TCP/8080	inbound	protocol/transaction interface
UDP/8081	inbound/outbound	narwhal primary interface
UDP/8082	inbound/outbound	narwhal worker interface
TCP/8083	localhost	sui -> narwhal interface
UDP/8084	inbound/outbound	peer to peer state sync interface
TCP/8443	outbound	metrics pushing
TCP/9184	localhost	metrics scraping
To run a validator successfully, it is critical that ports 8080-8084 are open as outlined, including the specific protocol (TCP/UDP).

Network Buffer
From load testing Sui validator networks, it has been determined that the default Linux network buffer sizes are too small. We recommend increasing them using one of the following two methods:

Option 1: With /etc/sysctl.d/
These settings can be added to a new sysctl file specifically for the sui-node, or appended to an existing file. Modifications made in this way will persist across system restarts.

# Create a new sysctl file for the sui-node
sudo nano /etc/sysctl.d/100-sui-node.conf

# Add these lines to the file, overwriting existing settings if necessary.
net.core.rmem_max = 104857600
net.core.wmem_max = 104857600
net.ipv4.tcp_rmem = 8192 262144 104857600
net.ipv4.tcp_wmem = 8192 262144 104857600

# Apply the settings immediately, before the next restart
sudo sysctl --system

Option 2: With sysctl command
These modifications do not persist across system restarts. Therefore, the commands should be run each time the host restarts.

sudo sysctl -w net.core.wmem_max=104857600
sudo sysctl -w net.core.rmem_max=104857600
sudo sysctl -w net.ipv4.tcp_rmem="8192 262144 104857600"
sudo sysctl -w net.ipv4.tcp_wmem="8192 262144 104857600"

Verification
To verify that the system settings have indeed been updated, check the output of the following command:

sudo sysctl -a | egrep [rw]mem

Storage
All Sui node related data is stored by default under /opt/sui/db/. This is controlled in the Sui node configuration file.

$ cat /opt/sui/config/validator.yaml | grep db-path
  db-path: /opt/sui/db/authorities_db
  db-path: /opt/sui/db/consensus_db

Ensure that you have an appropriately sized disk mounted for the database to write to.

To check the size of the local Sui node databases:
du -sh /opt/sui/db/
du -sh /opt/sui/db/authorities_db
du -sh /opt/sui/db/consensus_db

To delete the local Sui node databases:
sudo systemctl stop sui-node
sudo rm -rf /opt/sui/db/authorities_db /opt/sui/db/consensus_db

Key management
The following keys are used by Sui node:

key	scheme	purpose
protocol.key	bls12381	transactions, narwhal consensus
account.key	ed25519	controls assets for staking
network.key	ed25519	narwhal primary, sui state sync
worker.key	ed25519	validate narwhal workers
These are configured in the Sui node configuration file.

Monitoring
Metrics
Sui node exposes metrics via a local HTTP interface. These can be scraped for use in a central monitoring system as well as viewed directly from the node.

View all metrics:
curl -s http://localhost:9184/metrics

Search for a particular metric:
curl http://localhost:9184/metrics | grep <METRIC>

Sui node also pushes metrics to a central Sui metrics proxy.

Logs
Logs are controlled using the RUST_LOG environment variable.

The RUST_LOG_JSON=1 environment variable can optionally be set to enable logging in JSON structured format.

Depending on your deployment method, these are configured in the following places:

Ansible
Native systemd
Docker Compose
To view and follow the Sui node logs:

journalctl -u sui-node -f

To search for a particular match

journalctl -u sui-node -g <SEARCH_TERM>

If using Docker Compose, look at the examples in the README.
It is possible to change the logging configuration while a node is running using the admin interface.

To view the currently configured logging values:

curl localhost:1337/logging

To change the currently configured logging values:

curl localhost:1337/logging -d "info"

Dashboards
Public dashboard for network wide visibility:

Sui Testnet Validators
Software updates
When an update is required to the Sui node software the following process can be used. Follow the relevant Systemd or Docker Compose runbook depending on your deployment type. It is highly unlikely that you will want to restart with a clean database.

Systemd
Docker Compose
State sync
Checkpoints in Sui contain the permanent history of the network. They are comparable to blocks in other blockchains with one big difference being that they are lagging instead of leading. All transactions are final and executed prior to being included in a checkpoint.

These checkpoints are synchronized between validators and fullnodes via a dedicated peer to peer state sync interface.

Inter-validator state sync is always permitted however there are controls available to limit what fullnodes are allowed to sync from a specific validator.

The default and recommended max-concurrent-connections: 0 configuration does not affect inter-validator state sync, but will restrict all fullnodes from syncing. The Sui node configuration can be modified to allow a known fullnode to sync from a validator:

p2p-config:
  anemo-config:
    max-concurrent-connections: 0
  seed-peers:
    - address: <multiaddr>  # The p2p address of the fullnode
      peer-id: <peer-id>    # hex encoded network public key of the node
    - address: ...          # another permitted peer
      peer-id: ...

Chain operations
The following chain operations are executed using the sui CLI. This binary is built and provided as a release similar to sui-node, examples:

wget https://releases.sui.io/$SUI_SHA/sui
chmod +x sui

curl https://releases.sui.io/$SUI_SHA/sui -o sui
chmod +x sui

It is recommended and often required that the sui binary release/version matches that of the deployed network.

Updating on-chain metadata
You can leverage Validator Tool to perform majority of the following tasks.

An active/pending validator can update its on-chain metadata by submitting a transaction. Some metadata changes take effect immediately, including:

name
description
image url
project url
Other metadata (keys, addresses, and so on) only come into effect at the next epoch.

To update metadata, a validator makes a MoveCall transaction that interacts with the System Object. For example:

to update name to new_validator_name, use the Sui Client CLI to call sui_system::update_validator_name:
TIP
Beginning with the Sui v1.24.1 release, the --gas-budget flag is no longer required for CLI commands.

sui client call --package 0x3 --module sui_system --function update_validator_name --args 0x5 \"new_validator_name\" --gas-budget 10000


to update p2p address starting from next epoch to /ip4/192.168.1.1, use the Sui Client CLI to call sui_system::update_validator_next_epoch_p2p_address:
sui client call --package 0x3 --module sui_system --function update_validator_next_epoch_p2p_address --args 0x5 "[4, 192, 168, 1, 1]" --gas-budget 10000


See the full list of metadata update functions here.

Operation cap
To avoid touching account keys too often and allowing them to be stored off-line, validators can delegate the operation ability to another address. This address can then update the reference gas price and tallying rule on behalf of the validator.

Upon creating a Validator, an UnverifiedValidatorOperationCap is created as well and transferred to the validator address. The holder of this Cap object (short for "Capability") therefore could perform operational actions for this validator. To authorize another address to conduct these operations, a validator transfers the object to another address that they control. The transfer can be done by using Sui Client CLI: sui client transfer.

To rotate the delegatee address or revoke the authorization, the current holder of Cap transfers it to another address. In the event of compromised or lost keys, the validator could create a new Cap object to invalidate the incumbent one. This is done by calling sui_system::rotate_operation_cap:

sui client call --package 0x3 --module sui_system --function rotate_operation_cap --args 0x5 --gas-budget 10000


By default the new Cap object is transferred to the validator address, which then could be transferred to the new delegatee address. At this point, the old Cap becomes invalidated and no longer represents eligibility.

To get the current valid Cap object's ID of a validator, use the Sui Client CLI sui client objects command after setting the holder as the active address.

Updating the gas price survey quote
To update the gas price survey quote of a validator, which is used to calculate the reference gas price at the end of the epoch, the sender needs to hold a valid UnverifiedValidatorOperationCap. The sender could be the validator itself, or a trusted delegatee. To do so, call sui_system::request_set_gas_price:

sui client call --package 0x3 --module sui_system --function request_set_gas_price --args 0x5 {cap_object_id} {new_gas_price} --gas-budget 10000


Reporting/un-reporting validators
To report a validator or undo an existing reporting, the sender needs to hold a valid UnverifiedValidatorOperationCap. The sender could be the validator itself, or a trusted delegatee. To do so, call sui_system::report_validator/undo_report_validator:

sui client call --package 0x3 --module sui_system --function report_validator/undo_report_validator --args 0x5 {cap_object_id} {reportee_address} --gas-budget 10000


After a validator is reported by 2f + 1 other validators by voting power, their staking rewards will be slashed.

Joining the validator set
In order for a Sui address to join the validator set, they need to first sign up as a validator candidate by calling sui_system::request_add_validator_candidate with their metadata and initial configs:

sui client call --package 0x3 --module sui_system --function request_add_validator_candidate --args 0x5 {protocol_pubkey_bytes} {network_pubkey_bytes} {worker_pubkey_bytes} {proof_of_possession} {name} {description} {image_url} {project_url} {net_address} {p2p_address} {primary_address} {worker_address} {gas_price} {commission_rate} --gas-budget 10000


After an address becomes a validator candidate, any address (including the candidate address itself) can start staking with the candidate's staking pool. Refer to our dedicated staking FAQ on how staking works. Once a candidate's staking pool has accumulated at least sui_system::MIN_VALIDATOR_JOINING_STAKE amount of stake, the candidate can call sui_system::request_add_validator to officially add themselves to next epoch's active validator set:

sui client call --package 0x3 --module sui_system --function request_add_validator --args 0x5 --gas-budget 10000000


Leaving the validator set
To leave the validator set starting next epoch, the sender needs to be an active validator in the current epoch and should call sui_system::request_remove_validator:

sui client call --package 0x3 --module sui_system --function request_remove_validator --args 0x5 --gas-budget 10000


After the validator is removed at the next epoch change, the staking pool will become inactive and stakes can only be withdrawn from an inactive pool.

Private security fixes
There might be instances where urgent security fixes need to be rolled out before publicly announcing it's presence (issues affecting liveliness, invariants such as SUI supply, governance, and so on). To not be actively exploited, Mysten Labs will release signed security binaries incorporating such fixes with a delay in publishing the source code until a large percentage of our validators have patched the vulnerability.

This release process is different and we expect us to announce the directory for such binaries out of band. Our public key to verify these binaries would be stored here

There is also a script available that downloads all the necessary signed binaries and docker artifacts incorporating the security fixes.

Usage ./download_private.sh <directory-name>

You can also download and verify specific binaries that may not be included by the above script using the download_and_verify_private_binary.sh script.

Usage: ./download_and_verify_private_binary.sh <directory-name> <binary-name>


Node Tools
This guide focuses on using the Sui CLI validator commands.

INFO
This tool only supports pending validators and active validators at the moment.

Preparation
Make sure you have completed all the prerequisites.

Build the sui binary, which you need for the genesis ceremony. This step can be done on any machine you like. It does not have to be done on the machine on which you will run the validator.

Clone the git repo:

git clone git@github.com:MystenLabs/sui.git && cd sui

Check out the commit to use for the testnet:

git checkout testnet

Build sui binary

cargo build --bin sui

Remember the path to your binary:

export SUI_BINARY="$(pwd)/target/debug/sui"

Run the following command to set up your Sui account and CLI environment.

If this is the first time running this program, it will ask you to provide a Sui Fullnode Server URL and a meaningful environment alias. It will also generate a random key pair in sui.keystore and a config client.yaml. Swap in your validator account key if you already have one.

If you already set it up, simply make sure a. rpc is correct in client.yaml. b. active_address is correct in client.yaml. b. sui.keystore contains your account key pair.

If at this point you can't find where client.yaml or sui.keystore is or have other questions, read Sui Client CLI tutorial.

$ sui client

To test you are connected to the network and configured your config correctly, run the following command to display your validator info.

$ sui validator display-metadata

Using Sui CLI
Print help info
$ sui validator --help

Display validator metadata
$ sui validator display-metadata

or

$ sui validator display-metadata <validator-address>

to print another validator's information.

Update validator metadata
Run the following to see how to update validator metadata. Read description carefully about when the change will take effect.

$ sui validator update-metadata --help

You can update the following on-chain metadata:

name
description
image URL
project URL
network address
p2p address
primary address
worker address
protocol public key
network public key
worker public key
Notably, only the first 4 metadata listed above take effect immediately.

If you change any metadata from points 5 to 11, they will be changed only after the next epoch - for these, you'll want to restart the validator program immediately after the next epoch, with the new key files and/or updated validator.yaml config. Particularly, make sure the new address is not behind a firewall.

Run the following to see how to update each metadata.

$ sui validator update-metadata --help

Operation cap
Operation Cap allows a validator to authorizer another account to perform certain actions on behalf of this validator. Read about Operation Cap here.

The Operation Cap holder (either the valdiator itself or the delegatee) updates its Gas Price and reports validator peers with the Operation Cap.

Update gas price
To update Gas Price, run

$ sui validator update-gas-price <gas-price>

if the account itself is a validator and holds the Operation Cap. Or

$ sui validator update-gas-price --operation-cap-id <operation-cap-id> <gas-price>

if the account is a delegatee.

Report validators
To report validators peers, run

$ sui validator report-validator <reportee-address>

Add --undo-report false if it intents to undo an existing report.

Similarly, if the account is a delegatee, add --operation-cap-id <operation-cap-id> option to the command.

if the account itself is a validator and holds the Operation Cap. Or

$ sui validator update-gas-price --operation-cap-id <operation-cap-id> <gas-price>

if the account is a delegatee.

Become a validator / join committee
To become a validator candidate, first run

$ sui validator make-validator-info <name> <description> <image-url> <project-url> <host-name> <gas_price>


This will generate a validator.info file and key pair files. The output of this command includes:

Four key pair files (Read more here). ==Set their permissions with the minimal visibility (chmod 600, for example) and store them securely==. They are needed when running the validator node as covered below. a. If you follow this guide thoroughly, this key pair is actually copied from your sui.keystore file.
validator.info file that contains your validator info. Double check all information is correct.
Then run

$ sui validator become-candidate {path-to}validator.info

to submit an on-chain transaction to become a validator candidate. The parameter is the file path to the validator.info generated in the previous step. Make sure the transaction succeeded (printed in the output).

At this point you are validator candidate and can start to accept self staking and delegated staking.

If you haven't, start a fullnode now to catch up with the network. When you officially join the committee but is not fully up-to-date, you cannot make meaningful contribution to the network and may be subject to peer reporting hence face the risk of reduced staking rewards for you and your delegators.

Once you collect enough staking amount, run

$ sui validator join-committee

to become a pending validator. A pending validator will become active and join the committee starting from next epoch.

Leave committee
To leave committee, run

$ sui validator leave-committee

Then you will be removed from committee starting from next epoch.

Generate the payload to create PoP
Serialize the payload that is used to generate Proof of Possession. This is allows the signer to take the payload offline for an Authority protocol BLS keypair to sign.

$ sui validator serialize-payload-pop --account-address $ACCOUNT_ADDRESS --protocol-public-key $BLS_PUBKEY
Serialized payload: $PAYLOAD_TO_SIGN


Sui Exchange Integration Guide
This topic describes how to integrate SUI, the token native to the Sui network, into a cryptocurrency exchange. The specific requirements and processes to implement an integration vary between exchanges. Rather than provide a step-by-step guide, this topic provides information about the primary tasks necessary to complete an integration. After the guidance about how to configure an integration, you can also find information and code samples related to staking on the Sui network.

Requirements to configure a SUI integration
The requirements to configure a SUI integration include:

A Sui Full node. You can operate your own Sui Full node or use a Full node from a node operator.
Suggested hardware requirements to run a Sui Full node:
CPU: 8 physical cores / 16 vCPUs
RAM: 128 GB
Storage (SSD): 4 TB NVMe drive
For best results, run Sui Full nodes on Linux. Sui supports the Ubuntu and Debian distributions. You can also fun a Full node on macOS.

Configure a Sui Full node
You can set up and configure a Sui Full node using Docker or directly from source code in the Sui GitHub repository.

Set up Sui addresses
Sui addresses do not require on-chain initialization, you can spend from an address if it corresponds to your private key. You can derive a 32-byte Sui address by hashing the signature scheme flag byte concatenated with public key bytes flag || pubkey using the BLAKE2b (256 bits output) hashing function.

Currently, Sui address supports these signature schemes: pure Ed25519, Secp256k1, Secp256r1 and multisig. The corresponding flag bytes are 0x00, 0x01, 0x02, 0x03 respectively.

The following code sample demonstrates how to derive a Sui address in Rust:

let flag = 0x00; // 0x00 = ED25519, 0x01 = Secp256k1, 0x02 = Secp256r1, 0x03 = multiSig
// Hash the [flag, public key] bytearray using Blake2b
let mut hasher = DefaultHash::default();
hasher.update([flag]);
hasher.update(pk);
let arr = hasher.finalize();
let sui_address_string = hex::encode(arr);

Displaying addresses
Sui supports both addresses with and without a 0x prefix. Sui recommends that you always include the 0x prefix in API calls and when you display user addresses.

Track balance changes for an address
You can track balance changes by calling sui_getBalance at predefined intervals. This call returns the total balance for an address. The total includes any coin or token type, but this document focuses on SUI. You can track changes in the total balance for an address between subsequent sui_getBalance requests.

The following bash example demonstrates how to use sui_getBalance for address 0x849d63687330447431a2e76fecca4f3c10f6884ebaa9909674123c6c662612a3. If you use a network other than Devnet, replace the value for rpc with the URL to the appropriate Full node.

rpc="https://fullnode.devnet.sui.io:443"
address="0x849d63687330447431a2e76fecca4f3c10f6884ebaa9909674123c6c662612a3"
data="{\"jsonrpc\": \"2.0\", \"method\": \"sui_getBalance\", \"id\": 1, \"params\": [\"$address\"]}"
curl -X POST -H 'Content-type: application/json' --data-raw "$data" $rpc


The response is a JSON object that includes the totalBalance for the address:

{
  "jsonrpc":"2.0",
  "result":{
     "coinType":"0x2::sui::SUI",
     "coinObjectCount":40,
     "totalBalance":10000000000,
     "lockedBalance":{

     }
  },
  "id":1
}

The following example demonstrates using sui_getBalance in Rust:

use std::str::FromStr;
use sui_sdk::types::base_types::SuiAddress;
use sui_sdk::{SuiClient, SuiClientBuilder};


#[tokio::main]
async fn main() -> Result<(), anyhow::Error> {
   let sui = SuiClientBuilder::default().build(
      "https://fullnode.devnet.sui.io:443",
   ).await.unwrap();
   let address = SuiAddress::from_str("0x849d63687330447431a2e76fecca4f3c10f6884ebaa9909674123c6c662612a3")?;
   let objects = sui.read_api().get_balance(address).await?;
   println!("{:?}", objects);
   Ok(())
}


Use events to track balance changes for an address
You can also track the balance for an address by subscribing to all of the events emitted from it. Use a filter to include only the events related to SUI coins, such as when the address acquires a coin or pays for a gas fee. The following example demonstrates how to filter events for an address using bash and cURL:

rpc="https://fullnode.devnet.sui.io:443"
address="0x849d63687330447431a2e76fecca4f3c10f6884ebaa9909674123c6c662612a3"
data="{\"jsonrpc\": \"2.0\", \"id\":1, \"method\": \"sui_getEvents\", \"params\": [{\"Recipient\": {\"AddressOwner\": \"0x849d63687330447431a2e76fecca4f3c10f6884ebaa9909674123c6c662612a3\"}}, null, null, true ]}"
curl -X POST -H 'Content-type: application/json' --data-raw "$data" $rpc


The response can include a large number of events. Add pagination to the response using the nextCursor key in the request. You can determine the corresponding txDigest and eventSeq from the id field of a transaction.

You can add the txDigest value instead of the first null within the params. The second null is an integer that defines how many results (up to 1000) to return and the true means ascending order. You can use the nextCursor so the response starts from a desired point.

The id field of any transaction looks like:

"id": {
    "txDigest": "GZQN9pE3Zr9ZfLzBK1BfVCXtbjx5xKMxPSEKaHDvL3E2",
    "eventSeq": 6019
}

With this data, create a nextCursor as follows:

nextCursor : {"txDigest": "GZQN9pE3Zr9ZfLzBK1BfVCXtbjx5xKMxPSEKaHDvL3E2","eventSeq": 6019}


Blocks vs checkpoints
Sui is a DAG-based blockchain and uses checkpoints for node synchronization and global transaction ordering. Checkpoints differ from blocks in the following ways:

Sui creates checkpoints and adds finalized transactions. Note that transactions are finalized even before they are included in a checkpoint
Checkpoints do not fork, roll back, or reorganize.
Sui creates one checkpoint about every 3 seconds.
Checkpoint API operations
Sui Checkpoint API operations include:

sui_getCheckpoint - Retrieves the specified checkpoint.
sui_getLatestCheckpointSequenceNumber - Retrieves the sequence number of the most recently executed checkpoint.
sui_getCheckpoints - Retrieves a paginated list of checkpoints that occurred during the specified interval. Pending a future release.
SUI balance transfer
To transfer a specific amount of SUI between addresses, you need a SUI token object with that specific value. In Sui, everything is an object, including SUI tokens. The amount of SUI in each SUI token object varies. For example, an address could own 3 SUI tokens with different values: one of 0.1 SUI, a second of 1.0 SUI, and a third with 0.005 SUI. The total balance for the address equals the sum of the values of the individual SUI token objects, in this case, 1.105 SUI.

You can merge and split SUI token objects to create token objects with specific values. To create a SUI token worth .6 SUI, split the token worth 1 SUI into two token objects worth .6 SUI and .4 SUI.

To transfer a specific amount of SUI, you need a SUI token worth that specific amount. To get a SUI token with that specific value, you might need to split or merge existing SUI tokens. Sui supports several methods to accomplish this, including some that do not require you to manually split or merge coins.

Sui API operations for transfers
Sui supports the following API operations related to transferring SUI between addresses:

sui_transferObject Because SUI tokens are objects, you can transfer SUI tokens just like any other object. This method requires a gas token, and is useful in niche cases only.

sui_payAllSui This method accepts an array of SUI token IDs. It merges all existing tokens into one, deducts the gas fee, then sends the merged token to the recipient address.

The method is especially useful if you want to transfer all SUI from an address. To merge together all coins for an address, set the recipient as the same address. This is a native Sui method so is not considered a transaction in Sui.

sui_paySui This operation accepts an array of SUI token IDs, an array of amounts, and an array of recipient addresses.

The amounts and recipients array map one to one. Even if you use only one recipient address, you must include it for each amount in the amount array.

The operation merges all of the tokens provided into one token object and settles the gas fees. It then splits the token according to the amounts in the amounts array and sends the first token to the first recipient, the second token to the second recipient, and so on. Any remaining SUI on the token stays in the source address.

The benefits of this method include: no gas fees for merging or splitting tokens, and the abstracted token merge and split. The sui_paySui operation is a native function, so the merge and split operations are not considered Sui transactions. The gas fees for them match typical transactions on Sui.You can use this operation to split coins in your own address by setting the recipient as your own address. Note that the total value of the input coins must be greater than the total value of the amounts to send.

sui_pay This method is similar to sui_paySui, but it accepts any kind of coin or token instead of only SUI. You must include a gas token, and all of the coins or tokens must be the same type.

sui_transferSui This method accepts only one SUI token object and an amount to send to the recipient. It uses the same token for gas fees, so the amount to transfer must be strictly less than the value of the SUI token used.

Signing transactions
Refer to Sui Signatures for more details on signature validity requirements.

SUI Staking
The Sui blockchain uses a Delegated Proof-of-Stake mechanism (DPoS). This allows SUI token holders to stake their SUI tokens to any validator of their choice. When someone stakes their SUI tokens, it means those tokens are locked for the entire epoch. Users can withdraw their stake at any time, but new staking requests become active only at the start of the next epoch.

SUI holders who stake their tokens to validators earn rewards for helping secure the Sui network. Sui determines rewards for staking based on stake rewards on the network, and distributes them at the end of each epoch.

The total voting power in the Sui Network is always 10,000. The voting power of each individual validator is similar to basis points. For example, a voting power of 101 = 1.01%. Sui's quorum threshold (number of votes needed to confirm a transaction) is 6,667 (which is greater than 2/3). The voting power for a single validator is capped at 1,000 (10%) regardless of how much stake the validator has.

Staking functions
Sui supports the following API operations related to staking. You can find the source code in the sui_system module.

request_add_stake Add user stake to a validator's staking pool.
public fun request_add_stake(
   self: &mut SuiSystemState,
   stake: Coin<SUI>,
   validator_address: address,
   ctx: &mut TxContext,
) {
   validator_set::request_add_stake(
       &mut self.validators,
       validator_address,
       coin::into_balance(stake),
       option::none(),
       ctx,
   );
}

request_add_stake_mul_coin Add user stake to a validator's staking pool using multiple coins.
public fun request_add_stake_mul_coin(
   self: &mut SuiSystemState,
   delegate_stakes: vector<Coin<SUI>>,
   stake_amount: option::Option<u64>,
   validator_address: address,
   ctx: &mut TxContext,
) {
   let balance = extract_coin_balance(delegate_stakes, stake_amount, ctx);
   validator_set::request_add_stake(&mut self.validators, validator_address, balance, option::none(), ctx);
}


request_add_stake_with_locked_coin Add user stake to a validator's staking pool using a locked SUI coin.
public fun request_add_stake_with_locked_coin(
   self: &mut SuiSystemState,
   stake: LockedCoin<SUI>,
   validator_address: address,
   ctx: &mut TxContext,
) {
   let (balance, lock) = locked_coin::into_balance(stake);
   validator_set::request_add_stake(&mut self.validators, validator_address, balance, option::some(lock), ctx);
}


request_withdraw_stake Withdraw some portion of a user stake from a validator's staking pool.
public fun request_withdraw_stake(
   self: &mut SuiSystemState,
   delegation: &mut Delegation,
   staked_sui: &mut StakedSui,
   principal_withdraw_amount: u64,
   ctx: &mut TxContext,
) {
   validator_set::request_withdraw_stake(
       &mut self.validators,
       delegation,
       staked_sui,
       principal_withdraw_amount,
       ctx,
   );
}